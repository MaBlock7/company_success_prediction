{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-03-07 22:33:58.647\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mconfig\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m11\u001b[0m - \u001b[1mPROJ_ROOT path is: /Users/manuelbolz/Documents/git/for_work/company_success_prediction\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import ast\n",
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "from pocketknife.database import connect_database, read_from_database\n",
    "from config import EXTERNAL_DATA_DIR, PROCESSED_DATA_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOAD DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# db queries\n",
    "query_shab = \"\"\"\n",
    "    SELECT\n",
    "        ehraid,\n",
    "        shab_id,\n",
    "        shab_date,\n",
    "        registry_office_canton,\n",
    "        message AS message_raw\n",
    "    FROM zefix.shab\n",
    "\"\"\"\n",
    "\n",
    "query_shab_mutation = \"\"\"\n",
    "    SELECT * \n",
    "    FROM zefix.shab_mutation\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with connect_database() as con:\n",
    "    raw_shab = read_from_database(con, query_shab)\n",
    "    raw_shab_mutation = read_from_database(con, query_shab_mutation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "LANGUAGE = 'it'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_shab_messages = pd.read_csv(EXTERNAL_DATA_DIR / f'final_{LANGUAGE}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_shab_messages['parsed_variables'] = parsed_shab_messages.parsed_variables.fillna('{}')\n",
    "parsed_shab_messages['parsed_variables'] = parsed_shab_messages.parsed_variables.apply(ast.literal_eval)\n",
    "parsed_shab_messages['parsed_variables'] = parsed_shab_messages.parsed_variables.fillna({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>shab_id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>parsed_variables</th>\n",
       "      <th>main_group</th>\n",
       "      <th>text_slices</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2636071</td>\n",
       "      <td>BEGINNING</td>\n",
       "      <td>{}</td>\n",
       "      <td>undetermined</td>\n",
       "      <td>[BFC REI AG , Balzers , succursale di Mendrisi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2636071</td>\n",
       "      <td>capitale sociale della sede principale</td>\n",
       "      <td>{'capital_new': ['CHF 50'000.00'], 'capital_un...</td>\n",
       "      <td>capital and legal changes</td>\n",
       "      <td>[CHF 50'000.00 diviso in 500 azioni nominative...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2636071</td>\n",
       "      <td>numero di identificazione della sede principale</td>\n",
       "      <td>{'id_new': ['FL-0002.487.430-2'], 'id_until_no...</td>\n",
       "      <td>firm and address changes</td>\n",
       "      <td>[FL-0002.487.430-2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2636071</td>\n",
       "      <td>nuova natura giuridica della sede principale</td>\n",
       "      <td>{'legal_form_deleted': [''], 'legal_form_until...</td>\n",
       "      <td>capital and legal changes</td>\n",
       "      <td>[Società anonima di diritto lussemburghese . S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2636071</td>\n",
       "      <td>nuove osservazioni della sede principale</td>\n",
       "      <td>{}</td>\n",
       "      <td>undetermined</td>\n",
       "      <td>[Iscritta il 29.10.2014 al Fürstentum Liechten...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   shab_id                                          keyword  \\\n",
       "0  2636071                                        BEGINNING   \n",
       "1  2636071           capitale sociale della sede principale   \n",
       "2  2636071  numero di identificazione della sede principale   \n",
       "3  2636071     nuova natura giuridica della sede principale   \n",
       "4  2636071         nuove osservazioni della sede principale   \n",
       "\n",
       "                                    parsed_variables  \\\n",
       "0                                                 {}   \n",
       "1  {'capital_new': ['CHF 50'000.00'], 'capital_un...   \n",
       "2  {'id_new': ['FL-0002.487.430-2'], 'id_until_no...   \n",
       "3  {'legal_form_deleted': [''], 'legal_form_until...   \n",
       "4                                                 {}   \n",
       "\n",
       "                  main_group  \\\n",
       "0               undetermined   \n",
       "1  capital and legal changes   \n",
       "2   firm and address changes   \n",
       "3  capital and legal changes   \n",
       "4               undetermined   \n",
       "\n",
       "                                         text_slices  \n",
       "0  [BFC REI AG , Balzers , succursale di Mendrisi...  \n",
       "1  [CHF 50'000.00 diviso in 500 azioni nominative...  \n",
       "2                                [FL-0002.487.430-2]  \n",
       "3  [Società anonima di diritto lussemburghese . S...  \n",
       "4  [Iscritta il 29.10.2014 al Fürstentum Liechten...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parsed_shab_messages['text_slice'] = parsed_shab_messages['text_slice'].fillna('[]')\n",
    "parsed_shab_messages['text_slices'] = parsed_shab_messages['text_slice'].apply(ast.literal_eval)\n",
    "parsed_shab_messages = parsed_shab_messages.drop(columns=['text_slice'])\n",
    "parsed_shab_messages.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1647629\n",
      "2464967\n"
     ]
    }
   ],
   "source": [
    "print(parsed_shab_messages['shab_id'].nunique())\n",
    "print(raw_shab['shab_id'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2457792"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1625920\n",
    "2457792"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out the companies where the shab entries have been parsed\n",
    "raw_shab = raw_shab[raw_shab.shab_id.isin(parsed_shab_messages['shab_id'].unique())].copy()\n",
    "raw_shab_mutation = raw_shab_mutation[raw_shab_mutation.shab_id.isin(parsed_shab_messages['shab_id'].unique())].copy()\n",
    "raw_shab_mutation_grouped = (\n",
    "    raw_shab_mutation\n",
    "    .groupby('shab_id')\n",
    "    .agg(codes=pd.NamedAgg(column='description', aggfunc=lambda x: [v for v in x]))\n",
    "    .reset_index()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge all the dataframes\n",
    "shab_merged = (\n",
    "    raw_shab\n",
    "    .merge(raw_shab_mutation_grouped, on='shab_id', how='left')\n",
    "    .merge(parsed_shab_messages, on='shab_id', how='left')\n",
    ")\n",
    "\n",
    "# Sort values in the correct temporal order\n",
    "shab_merged = shab_merged.sort_values(['ehraid', 'shab_date', 'shab_id'], ascending=[True, True, True]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shab_merged_temp = shab_merged[shab_merged.ehraid.isin([905876, 905843, 905844])]\n",
    "shab_merged_temp = shab_merged_temp.sort_values(['ehraid', 'shab_date', 'shab_id'], ascending=[True, True, True]).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_raw_json_history(df: pd.DataFrame) -> dict:\n",
    "    json_structure = defaultdict(lambda: {'history': []})\n",
    "    for _, row in df.iterrows():\n",
    "        # Extract the fields to identify a company and its entries\n",
    "        ehraid = row['ehraid']\n",
    "        shab_date = row['shab_date'] if isinstance(row['shab_date'], str) else row['shab_date'].strftime('%Y-%d-%m')\n",
    "        shab_id = row['shab_id']\n",
    "        main_group = row['main_group']\n",
    "        keyword = row['keyword']\n",
    "\n",
    "        # Extract main information\n",
    "        message_info = {\n",
    "            'registry_office_canton': row['registry_office_canton'],\n",
    "            'codes': row['codes'],\n",
    "            'message_raw': row['message_raw'],\n",
    "            'extracted_content': {\n",
    "                main_group: {\n",
    "                    keyword: {\n",
    "                        'text_slices': row['text_slices'],\n",
    "                        'variables': row['parsed_variables']\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "\n",
    "        # Search if shab_date already exists in the history\n",
    "        date_entry = next((entry for entry in json_structure[ehraid]['history'] if shab_date in entry), None)\n",
    "\n",
    "        if date_entry is None:\n",
    "            # If the date does not exist, create a new entry\n",
    "            date_entry = {shab_date: {shab_id: message_info}}\n",
    "            json_structure[ehraid]['history'].append(date_entry)\n",
    "        else:\n",
    "            # If the date exists, check if the shab_id already exists\n",
    "            id_entry = date_entry[shab_date].get(shab_id, None)\n",
    "            if id_entry is None:\n",
    "                # If the shab_id does not exists, we can simply add it to the shab_date\n",
    "                date_entry[shab_date][shab_id] = message_info\n",
    "            else:\n",
    "                # If the shab_id exists, we need to check if the main_group already exists\n",
    "                main_group_entry = date_entry[shab_date][shab_id]['extracted_content'].get(main_group, None)\n",
    "                if main_group_entry is None:\n",
    "                    # If it does not exist, we add it to the extracted content\n",
    "                    date_entry[shab_date][shab_id]['extracted_content'][main_group] = message_info['extracted_content'][main_group]\n",
    "                else:\n",
    "                    # If it does, we add the keyword to the main_group, since a keyword can only appear once within the main_group\n",
    "                    date_entry[shab_date][shab_id]['extracted_content'][main_group][keyword] = message_info['extracted_content'][main_group][keyword]      \n",
    "\n",
    "    return dict(json_structure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_json = create_raw_json_history(shab_merged)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CREATE REGISTERED PEOPLE AND FIRMS TABLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_people = shab_merged[shab_merged.main_group == 'natural persons and legal entities'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure only the expected fields are there\n",
    "def validate_person_and_firms(x: dict):    \n",
    "    schema = {'firms': [], 'people': []}\n",
    "    for firm in x.get('firms', []):\n",
    "        if isinstance(firm, dict):\n",
    "            schema['firms'].append({\n",
    "                'firm_name': firm.get('firm_name'),\n",
    "                'firm_uid': firm.get('id'),\n",
    "                'firm_seat': firm.get('location'),\n",
    "                'firm_type': firm.get('type'),\n",
    "                'firm_shares': firm.get('shares')\n",
    "            })\n",
    "    for person in x.get('people', []):\n",
    "        if isinstance(person, dict):\n",
    "            schema['people'].append({\n",
    "                'first_name': person.get('first_name'),\n",
    "                'last_name': person.get('last_name'),\n",
    "                'hometown': person.get('hometown'),\n",
    "                'place_of_residence': person.get('place_of_residence'),\n",
    "                'nationality': person.get('nationality'),\n",
    "                'job_title': person.get('job_title'),\n",
    "                'authorization': person.get('authorization'),\n",
    "                'shares': person.get('shares')\n",
    "            })\n",
    "    return schema\n",
    "\n",
    "df_people['validated_variables'] = df_people['parsed_variables'].apply(validate_person_and_firms)  \n",
    "df_people['firms'] = df_people['validated_variables'].apply(lambda x: x.get('firms', []))\n",
    "df_people['people'] = df_people['validated_variables'].apply(lambda x: x.get('people', []))\n",
    "\n",
    "# Split individual firm dictionaries into individual rows\n",
    "df_firms_exploded = df_people.explode(column=['firms']).dropna()\n",
    "df_people_exploded = df_people.explode(column=['people']).dropna()\n",
    "\n",
    "# Create individual columns from the dictionary\n",
    "df_firms_norm = pd.json_normalize(\n",
    "    df_firms_exploded['firms'],\n",
    "    errors='raise'\n",
    ")\n",
    "df_firms_concat = pd.concat([df_firms_exploded[['ehraid', 'message_raw', 'shab_date', 'shab_id', 'codes', 'keyword']].reset_index(drop=True), df_firms_norm], axis=1)\n",
    "\n",
    "df_people_norm = pd.json_normalize(\n",
    "    df_people_exploded['people'],\n",
    "    errors='raise'\n",
    ")\n",
    "df_people_concat = pd.concat([df_people_exploded[['ehraid', 'message_raw', 'shab_date', 'shab_id', 'codes', 'keyword']].reset_index(drop=True), df_people_norm], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ehraid</th>\n",
       "      <th>message_raw</th>\n",
       "      <th>shab_date</th>\n",
       "      <th>shab_id</th>\n",
       "      <th>codes</th>\n",
       "      <th>keyword</th>\n",
       "      <th>first_name</th>\n",
       "      <th>last_name</th>\n",
       "      <th>hometown</th>\n",
       "      <th>place_of_residence</th>\n",
       "      <th>nationality</th>\n",
       "      <th>job_title</th>\n",
       "      <th>authorization</th>\n",
       "      <th>shares</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>AA-Annoncen Agentur AG, in Basel, CHE-102.721....</td>\n",
       "      <td>2019-09-06</td>\n",
       "      <td>1004711015</td>\n",
       "      <td>[aenderungorgane]</td>\n",
       "      <td>ausgeschiedene personen und erloschene untersc...</td>\n",
       "      <td>Philippe</td>\n",
       "      <td>Nappez</td>\n",
       "      <td>Grandfontaine</td>\n",
       "      <td>Binningen</td>\n",
       "      <td>CH</td>\n",
       "      <td>Mitglied des Verwaltungsrates</td>\n",
       "      <td>mit Kollektivunterschrift zu zweien</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>AA-Annoncen Agentur AG, in Basel, CHE-102.721....</td>\n",
       "      <td>2019-09-06</td>\n",
       "      <td>1004711015</td>\n",
       "      <td>[aenderungorgane]</td>\n",
       "      <td>eingetragene personen neu oder mutierend</td>\n",
       "      <td>Daniel</td>\n",
       "      <td>Ebneter</td>\n",
       "      <td>Häggenschwil</td>\n",
       "      <td>Rheinfelden</td>\n",
       "      <td>CH</td>\n",
       "      <td>Mitglied des Verwaltungsrates</td>\n",
       "      <td>mit Kollektivunterschrift zu zweien</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>AA-Annoncen Agentur AG, in Basel, CHE-102.721....</td>\n",
       "      <td>2020-02-07</td>\n",
       "      <td>1004825123</td>\n",
       "      <td>[status, status.aufl, status.aufl.liq, aenderu...</td>\n",
       "      <td>eingetragene personen neu oder mutierend</td>\n",
       "      <td>Gabriella</td>\n",
       "      <td>Karger Travella</td>\n",
       "      <td>Basel</td>\n",
       "      <td>Basel</td>\n",
       "      <td>CH</td>\n",
       "      <td>Mitglied des Verwaltungsrates</td>\n",
       "      <td>mit Kollektivunterschrift zu zweien</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>AA-Annoncen Agentur AG, in Basel, CHE-102.721....</td>\n",
       "      <td>2020-02-07</td>\n",
       "      <td>1004825123</td>\n",
       "      <td>[status, status.aufl, status.aufl.liq, aenderu...</td>\n",
       "      <td>eingetragene personen neu oder mutierend</td>\n",
       "      <td>Julien</td>\n",
       "      <td>Orsini</td>\n",
       "      <td>Basel</td>\n",
       "      <td>Reinach ( BL )</td>\n",
       "      <td>CH</td>\n",
       "      <td>Liquidator</td>\n",
       "      <td>mit Einzelunterschrift</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15</td>\n",
       "      <td>AAA EDV Software AG, in Aarau, CHE-106.307.377...</td>\n",
       "      <td>2022-04-19</td>\n",
       "      <td>1005453034</td>\n",
       "      <td>[aenderungorgane]</td>\n",
       "      <td>eingetragene personen neu oder mutierend</td>\n",
       "      <td>Urs</td>\n",
       "      <td>Antener</td>\n",
       "      <td>Eggiwil</td>\n",
       "      <td>Sarnen</td>\n",
       "      <td>CH</td>\n",
       "      <td>Präsident des Verwaltungsrates</td>\n",
       "      <td>mit Einzelunterschrift</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2148376</th>\n",
       "      <td>1682041</td>\n",
       "      <td>LA Capital AG, in Beromünster, CHE-343.494.505...</td>\n",
       "      <td>2025-03-04</td>\n",
       "      <td>1006272425</td>\n",
       "      <td>[status, status.neu]</td>\n",
       "      <td>eingetragene personen</td>\n",
       "      <td>Andreas</td>\n",
       "      <td>Tresch</td>\n",
       "      <td>Silenen</td>\n",
       "      <td>Beromünster</td>\n",
       "      <td>CH</td>\n",
       "      <td>Präsident des Verwaltungsrates</td>\n",
       "      <td>mit Einzelunterschrift</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2148377</th>\n",
       "      <td>1682041</td>\n",
       "      <td>LA Capital AG, in Beromünster, CHE-343.494.505...</td>\n",
       "      <td>2025-03-04</td>\n",
       "      <td>1006272425</td>\n",
       "      <td>[status, status.neu]</td>\n",
       "      <td>eingetragene personen</td>\n",
       "      <td>Leila</td>\n",
       "      <td>Tresch</td>\n",
       "      <td>Malters</td>\n",
       "      <td>Beromünster</td>\n",
       "      <td>CH</td>\n",
       "      <td>Mitglied des Verwaltungsrates</td>\n",
       "      <td>mit Einzelunterschrift</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2148378</th>\n",
       "      <td>1682042</td>\n",
       "      <td>Mentor Gerüst GmbH, in Wauwil, CHE-483.874.731...</td>\n",
       "      <td>2025-03-04</td>\n",
       "      <td>1006272426</td>\n",
       "      <td>[status, status.neu]</td>\n",
       "      <td>eingetragene personen</td>\n",
       "      <td>Mentor</td>\n",
       "      <td>Berisha</td>\n",
       "      <td>Sursee</td>\n",
       "      <td>Wauwil</td>\n",
       "      <td>CH</td>\n",
       "      <td>Gesellschafter und Geschäftsführer</td>\n",
       "      <td>mit Einzelunterschrift</td>\n",
       "      <td>mit 20 Stammanteilen zu je CHF 1000.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2148379</th>\n",
       "      <td>1682043</td>\n",
       "      <td>REINIGUNG - SARACENO, in Rickenbach (LU), CHE-...</td>\n",
       "      <td>2025-03-04</td>\n",
       "      <td>1006272427</td>\n",
       "      <td>[status, status.neu]</td>\n",
       "      <td>eingetragene personen</td>\n",
       "      <td>Mirko</td>\n",
       "      <td>Saraceno</td>\n",
       "      <td></td>\n",
       "      <td>Rickenbach ( LU )</td>\n",
       "      <td>italienischer Staatsangehöriger</td>\n",
       "      <td>Inhaber</td>\n",
       "      <td>mit Einzelunterschrift</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2148380</th>\n",
       "      <td>1682044</td>\n",
       "      <td>swiss-immo point gmbh, in Beromünster, CHE-306...</td>\n",
       "      <td>2025-03-04</td>\n",
       "      <td>1006272428</td>\n",
       "      <td>[status, status.neu]</td>\n",
       "      <td>eingetragene personen</td>\n",
       "      <td>Richard</td>\n",
       "      <td>Gehrlach</td>\n",
       "      <td>Kreuzlingen</td>\n",
       "      <td>Beromünster</td>\n",
       "      <td>CH</td>\n",
       "      <td>Gesellschafter und Geschäftsführer</td>\n",
       "      <td>mit Einzelunterschrift</td>\n",
       "      <td>mit 20 Stammanteilen zu je CHF 1000.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2148381 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          ehraid                                        message_raw  \\\n",
       "0              2  AA-Annoncen Agentur AG, in Basel, CHE-102.721....   \n",
       "1              2  AA-Annoncen Agentur AG, in Basel, CHE-102.721....   \n",
       "2              2  AA-Annoncen Agentur AG, in Basel, CHE-102.721....   \n",
       "3              2  AA-Annoncen Agentur AG, in Basel, CHE-102.721....   \n",
       "4             15  AAA EDV Software AG, in Aarau, CHE-106.307.377...   \n",
       "...          ...                                                ...   \n",
       "2148376  1682041  LA Capital AG, in Beromünster, CHE-343.494.505...   \n",
       "2148377  1682041  LA Capital AG, in Beromünster, CHE-343.494.505...   \n",
       "2148378  1682042  Mentor Gerüst GmbH, in Wauwil, CHE-483.874.731...   \n",
       "2148379  1682043  REINIGUNG - SARACENO, in Rickenbach (LU), CHE-...   \n",
       "2148380  1682044  swiss-immo point gmbh, in Beromünster, CHE-306...   \n",
       "\n",
       "          shab_date     shab_id  \\\n",
       "0        2019-09-06  1004711015   \n",
       "1        2019-09-06  1004711015   \n",
       "2        2020-02-07  1004825123   \n",
       "3        2020-02-07  1004825123   \n",
       "4        2022-04-19  1005453034   \n",
       "...             ...         ...   \n",
       "2148376  2025-03-04  1006272425   \n",
       "2148377  2025-03-04  1006272425   \n",
       "2148378  2025-03-04  1006272426   \n",
       "2148379  2025-03-04  1006272427   \n",
       "2148380  2025-03-04  1006272428   \n",
       "\n",
       "                                                     codes  \\\n",
       "0                                        [aenderungorgane]   \n",
       "1                                        [aenderungorgane]   \n",
       "2        [status, status.aufl, status.aufl.liq, aenderu...   \n",
       "3        [status, status.aufl, status.aufl.liq, aenderu...   \n",
       "4                                        [aenderungorgane]   \n",
       "...                                                    ...   \n",
       "2148376                               [status, status.neu]   \n",
       "2148377                               [status, status.neu]   \n",
       "2148378                               [status, status.neu]   \n",
       "2148379                               [status, status.neu]   \n",
       "2148380                               [status, status.neu]   \n",
       "\n",
       "                                                   keyword first_name  \\\n",
       "0        ausgeschiedene personen und erloschene untersc...   Philippe   \n",
       "1                 eingetragene personen neu oder mutierend     Daniel   \n",
       "2                 eingetragene personen neu oder mutierend  Gabriella   \n",
       "3                 eingetragene personen neu oder mutierend     Julien   \n",
       "4                 eingetragene personen neu oder mutierend        Urs   \n",
       "...                                                    ...        ...   \n",
       "2148376                              eingetragene personen    Andreas   \n",
       "2148377                              eingetragene personen      Leila   \n",
       "2148378                              eingetragene personen     Mentor   \n",
       "2148379                              eingetragene personen      Mirko   \n",
       "2148380                              eingetragene personen    Richard   \n",
       "\n",
       "               last_name       hometown place_of_residence  \\\n",
       "0                 Nappez  Grandfontaine          Binningen   \n",
       "1                Ebneter   Häggenschwil        Rheinfelden   \n",
       "2        Karger Travella          Basel              Basel   \n",
       "3                 Orsini          Basel     Reinach ( BL )   \n",
       "4                Antener        Eggiwil             Sarnen   \n",
       "...                  ...            ...                ...   \n",
       "2148376           Tresch        Silenen        Beromünster   \n",
       "2148377           Tresch        Malters        Beromünster   \n",
       "2148378          Berisha         Sursee             Wauwil   \n",
       "2148379         Saraceno                 Rickenbach ( LU )   \n",
       "2148380         Gehrlach    Kreuzlingen        Beromünster   \n",
       "\n",
       "                             nationality                           job_title  \\\n",
       "0                                     CH       Mitglied des Verwaltungsrates   \n",
       "1                                     CH       Mitglied des Verwaltungsrates   \n",
       "2                                     CH       Mitglied des Verwaltungsrates   \n",
       "3                                     CH                          Liquidator   \n",
       "4                                     CH      Präsident des Verwaltungsrates   \n",
       "...                                  ...                                 ...   \n",
       "2148376                               CH      Präsident des Verwaltungsrates   \n",
       "2148377                               CH       Mitglied des Verwaltungsrates   \n",
       "2148378                               CH  Gesellschafter und Geschäftsführer   \n",
       "2148379  italienischer Staatsangehöriger                             Inhaber   \n",
       "2148380                               CH  Gesellschafter und Geschäftsführer   \n",
       "\n",
       "                               authorization  \\\n",
       "0        mit Kollektivunterschrift zu zweien   \n",
       "1        mit Kollektivunterschrift zu zweien   \n",
       "2        mit Kollektivunterschrift zu zweien   \n",
       "3                     mit Einzelunterschrift   \n",
       "4                     mit Einzelunterschrift   \n",
       "...                                      ...   \n",
       "2148376               mit Einzelunterschrift   \n",
       "2148377               mit Einzelunterschrift   \n",
       "2148378               mit Einzelunterschrift   \n",
       "2148379               mit Einzelunterschrift   \n",
       "2148380               mit Einzelunterschrift   \n",
       "\n",
       "                                         shares  \n",
       "0                                                \n",
       "1                                                \n",
       "2                                                \n",
       "3                                                \n",
       "4                                                \n",
       "...                                         ...  \n",
       "2148376                                          \n",
       "2148377                                          \n",
       "2148378  mit 20 Stammanteilen zu je CHF 1000.00  \n",
       "2148379                                          \n",
       "2148380  mit 20 Stammanteilen zu je CHF 1000.00  \n",
       "\n",
       "[2148381 rows x 14 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_people_concat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add Gender and Nationality to the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import spacy\n",
    "from unidecode import unidecode\n",
    "from zefix_processing.country_mapping import german2alpha2, french2alpha2, italian2alpha2\n",
    "from zefix_processing.gender_mapping import german2gender, french2gender, italian2gender\n",
    "\n",
    "nlp_models = {\n",
    "    \"de\": spacy.load(\"de_core_news_sm\"),\n",
    "    \"fr\": spacy.load(\"fr_core_news_sm\"),\n",
    "    \"it\": spacy.load(\"it_core_news_sm\")\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_words(string: str) -> str:\n",
    "    replacements = {\n",
    "        'ä': 'ae',\n",
    "        'ö': 'oe',\n",
    "        'ü': 'ue'\n",
    "    }\n",
    "    for char, replacement in replacements.items():\n",
    "        string = string.replace(char, replacement)\n",
    "    \n",
    "    return unidecode(string.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "nationality_mapping = {\n",
    "    'de': {normalize_words(k): v for k, v in german2alpha2.items()},\n",
    "    'fr': {normalize_words(k): v for k, v in french2alpha2.items()},\n",
    "    'it': {normalize_words(k): v for k, v in italian2alpha2.items()}\n",
    "}\n",
    "\n",
    "gender_mapping = {\n",
    "    'de': {normalize_words(k): v for k, v in german2gender.items()},\n",
    "    'fr': {normalize_words(k): v for k, v in french2gender.items()},\n",
    "    'it': {normalize_words(k): v for k, v in italian2gender.items()},\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean the hometown, place of residence, and nationality column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries_containing_and = [\n",
    "    'bosnie et herzégovine',\n",
    "    'svalbard et île jan mayen',\n",
    "    'îles turques et caïques',\n",
    "    'géorgie du sud et îles sandwich du sud',\n",
    "    'bonaire, saint eustatius et saba',\n",
    "    'terres australes et antarctiques françaises',\n",
    "    'de são tomé e príncipe',\n",
    "    'serbo e montenegrino',\n",
    "    'serba e montenegrina',\n",
    "    'di saint christopher e nevis',\n",
    "    'de são tomé e príncipe'\n",
    "]\n",
    "\n",
    "# 1. Split multiple nationalities into individual columns\n",
    "def clean_location(language: str, string: str) -> str:\n",
    "    mapping = {\n",
    "        'de': ['von', 'in'],\n",
    "        'fr': ['de', 'du', \"d'\", 'des', 'à'],\n",
    "        'it': ['da', \"d'\", 'in']\n",
    "    }\n",
    "    for word in mapping[language]:\n",
    "        string = re.sub(rf'\\b{word}\\b', '', string)\n",
    "    return string.strip()\n",
    "\n",
    "def split_locations(df: pd.DataFrame, orig_col: str = 'nationality'):\n",
    "    loc_split = df[orig_col].str.split(r'\\sund\\s|\\set\\s|\\se\\s', regex=True, expand=True)\n",
    "    loc_split.columns = [f'{orig_col}_{i+1}' for i in range(loc_split.shape[1])]\n",
    "    loc_split.fillna('', inplace=True)\n",
    "    df = pd.concat([df, loc_split], axis=1)\n",
    "    return df.drop(columns=[orig_col])\n",
    "\n",
    "df_people_concat['hometown'] = df_people_concat['hometown'].apply(lambda x: clean_location(LANGUAGE, x))\n",
    "df_people_concat['place_of_residence'] = df_people_concat['place_of_residence'].apply(lambda x: clean_location(LANGUAGE, x))\n",
    "df_people_concat['nationality'] = df_people_concat['nationality'].apply(lambda x: clean_location(LANGUAGE, x))\n",
    "\n",
    "# First, split the hometown and place of residence column\n",
    "df_people_concat = split_locations(df_people_concat, 'hometown')\n",
    "df_people_concat = split_locations(df_people_concat, 'place_of_residence')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Move nationalities that are in the wrong column\n",
    "def contains_target_word(text):\n",
    "    pattern = r'\\bstaatsangehoerige\\b|\\bcittadina\\b|\\bressortissante\\b|\\bcitoyenne\\b|\\bstaatsangehoeriger\\b|\\bcittadino\\b|\\bressortissant\\b|\\bcitoyen\\b'\n",
    "    return bool(re.search(pattern, text))\n",
    "\n",
    "def move_nationalities(language: str, entries: list[str], nat: str, country_names: set[str]):\n",
    "    \"\"\"\n",
    "    Checks if any of the hometown columns contains a country name\n",
    "    \"\"\"\n",
    "    mapping = {\n",
    "        'de': 'und',\n",
    "        'fr': 'et',\n",
    "        'it': 'e'\n",
    "    }\n",
    "    nat_norm = normalize_words(nat)\n",
    "    for i, entry in enumerate(entries):\n",
    "        if entry:\n",
    "            entry_norm = normalize_words(entry)\n",
    "            if entry_norm in country_names or contains_target_word(entry_norm):\n",
    "                if not re.match(rf'\\b{entry_norm}\\b', nat_norm):\n",
    "                    nat = f\"{nat} {mapping.get(language, ' und ')} {entry}\" if nat else entry\n",
    "                entries[i] = ''\n",
    "            else:\n",
    "                # If the name is not a country name and the nationality does not include Swiss yet,\n",
    "                # we want to add 'CH' to the nationalities, since the hometown is with high probability a Swiss municipality\n",
    "                if 'CH' not in nat:\n",
    "                    nat = f\"{nat} {mapping.get(language, ' und ')} CH\" if nat else 'CH'\n",
    "    return entries + [nat]\n",
    "\n",
    "countries_norm = french2alpha2.keys()\n",
    "hometown_cols = [col for col in df_people_concat.columns if 'hometown' in col]\n",
    "result_cols = hometown_cols + ['nationality']\n",
    "df_people_concat[result_cols] = df_people_concat.apply(lambda x: pd.Series(move_nationalities(LANGUAGE, [x[col] for col in hometown_cols], x['nationality'], countries_norm)), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally, split the nationality column\n",
    "df_people_concat = split_locations(df_people_concat, 'nationality')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean the authorization and shares column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def switch_auth_and_shares(language: str, auth: str, shares: str):\n",
    "    \"\"\"\n",
    "    Checks if any of the hometown columns contains a country name\n",
    "    \"\"\"\n",
    "    keyword_mapping = {\n",
    "        'de': 'unterschrift',\n",
    "        'fr': 'signature',\n",
    "        'it': 'firma'\n",
    "    }\n",
    "    and_mapping = {\n",
    "        'de': 'und',\n",
    "        'fr': 'et',\n",
    "        'it': 'e'\n",
    "    }\n",
    "\n",
    "    # Base Case: no value in both\n",
    "    if not (auth or shares):\n",
    "        return [auth, shares]  # no switch\n",
    "    \n",
    "    match_auth = re.search(r'\\bchf\\b', auth.lower()) if auth else None\n",
    "    match_shares = re.search(keyword_mapping[language], shares.lower()) if shares else None\n",
    "\n",
    "    # Case 0: no match in both\n",
    "    if not (match_auth or match_shares):\n",
    "        return [auth, shares]  # no switch\n",
    "\n",
    "    # Case 1: match in auth and no match in shares\n",
    "    elif match_auth and not match_shares:\n",
    "        if shares:\n",
    "            return ['', f\"{auth} {and_mapping[language]} {shares}\"]  # Add auth infront of shares\n",
    "        else:\n",
    "            return ['', auth]  # switch columns: auth, share\n",
    "    \n",
    "    # Case 2: match in shares and no value in auth\n",
    "    elif match_shares and not match_auth:\n",
    "        if shares:\n",
    "            return [f\"{auth} {and_mapping[language]} {shares}\", '']  # Add shares after auth\n",
    "        else:\n",
    "            return [shares, '']  # switch columns: auth, share\n",
    "    \n",
    "    # Case 3: match in auth and shares\n",
    "    elif match_auth and not match_shares:\n",
    "        return [shares, auth]  # switch both\n",
    "    \n",
    "    else:\n",
    "        return [auth, shares]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_people_concat[['authorization', 'shares']] = df_people_concat.apply(lambda x: pd.Series(switch_auth_and_shares(LANGUAGE, x['authorization'], x['shares'])), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize the nationality and add the iso-3166-1 alpha 2 codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_country(language: str, nationality: str, mapping: dict) -> str:\n",
    "    if nationality:\n",
    "        if language == 'de':\n",
    "            nationality = nationality.split()[0].strip()\n",
    "        else:\n",
    "            nationality = nationality.split()[-1].strip()\n",
    "        return mapping[language].get(nationality)\n",
    "    return ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "nat_cols = [col for col in df_people_concat.columns if re.match(r'^nationality\\_\\d{1}$', col)]\n",
    "for nat_col in nat_cols:\n",
    "    df_people_concat[f\"{nat_col}_norm\"] = df_people_concat[nat_col].fillna('').apply(normalize_words)\n",
    "    df_people_concat[f'{nat_col}_iso_3166_1_alpha_2'] = df_people_concat[f\"{nat_col}_norm\"].apply(lambda x: map_country(LANGUAGE, x, nationality_mapping))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find gendered job titles and/or determine gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "gendered_endings = {\n",
    "    'de': {\n",
    "        'female': ['in'],\n",
    "        'male': [],  # no specific ending for male words in German\n",
    "    },\n",
    "    'fr': {\n",
    "        'female': ['euse', 'ienne', 'onne', 'ane', 'trice', 'esse'],\n",
    "        'male': ['eur', 'ien', 'on', 'an'],\n",
    "    },\n",
    "    'it': {\n",
    "        'female': ['a', 'trice', 'essa'],\n",
    "        'male': ['o', 'ore']\n",
    "    }   \n",
    "}\n",
    "\n",
    "\n",
    "def extract_nouns(text: str, language: str) -> list:\n",
    "    \"\"\"\n",
    "    Extracts nouns from a given text using spaCy for German, French, and Italian.\n",
    "    \"\"\"\n",
    "    nlp = nlp_models[language]\n",
    "    return [token.text for token in nlp(text) if token.pos_ == 'NOUN']\n",
    "\n",
    "\n",
    "def create_gendered_job_names(language: str, df: pd.DataFrame, col: str = 'job_title_norm') -> tuple[list]:\n",
    "    nouns = set([title.lower() for title in df[col].unique() for title in extract_nouns(title, language)])\n",
    "       \n",
    "    female_words = []\n",
    "    male_words = []\n",
    "    undetermined = []\n",
    "\n",
    "    for word in nouns:\n",
    "        if any(word.endswith(ending) for ending in gendered_endings[language]['female']):\n",
    "            female_words.append(word)\n",
    "        elif any(word.endswith(ending) for ending in gendered_endings[language]['male']):\n",
    "            male_words.append(word)\n",
    "        else:\n",
    "            undetermined.append(word)\n",
    "\n",
    "    if language == 'de':\n",
    "        for word in female_words:\n",
    "            male_version = word.removesuffix('in')\n",
    "            if male_version in undetermined:\n",
    "                male_words.append(male_version)\n",
    "        \n",
    "    undetermined = [w for w in undetermined if w not in male_words]\n",
    "\n",
    "    return female_words, male_words, undetermined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize job title\n",
    "df_people_concat['job_title_norm'] = df_people_concat['job_title'].apply(normalize_words)\n",
    "df_people_concat['job_title_norm'] = df_people_concat['job_title_norm'].str.replace(r'[^a-zA-Z]', ' ', regex=True).apply(lambda x: ' '.join(x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "CREATE_GENDERED_WORDS = False\n",
    "\n",
    "if CREATE_GENDERED_WORDS:\n",
    "    female_words, male_words, undetermined = create_gendered_job_names('fr', df_people_concat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_names(name: str) -> str:\n",
    "    name = re.sub(r' genannt | dit | dite | detto | detta ', ' ', name)\n",
    "    name = re.sub(r'\\(.*?\\)', '', name)\n",
    "    name = re.sub(r'\\[.*?\\]', '', name)\n",
    "    name = re.sub(r'[^\\w\\s\\-.]', '', name)\n",
    "    name = re.sub(r'\\b\\d+\\b', '', name)\n",
    "    name = re.sub(r'\\b\\w{1,4}\\.(?=\\s|$)', '', name)\n",
    "    return ' '.join(name.strip().split())\n",
    "\n",
    "\n",
    "def prepare_country_code(code: str) -> str:\n",
    "    code = code if code != 'XK' else 'RS'  # gender API does not support Kosovo (XK)\n",
    "    return code if len(code) <= 2 else None\n",
    "\n",
    "\n",
    "def determine_gender(\n",
    "    mapping: dict,\n",
    "    nationalities: list[str],\n",
    "    job_title: str\n",
    ") -> str|None:\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    # Try to infer gender via nationality\n",
    "    for nationality in nationalities:\n",
    "        if re.search(r'\\bstaatsangehoeriger\\b|\\bcittadino\\b|\\bressortissant\\b|\\bcitoyen\\b', nationality):\n",
    "            return 'm'\n",
    "        elif re.search(r'\\bstaatsangehoerige\\b|\\bcittadina\\b|\\bressortissante\\b|\\bcitoyenne\\b', nationality):\n",
    "            return 'f'\n",
    "\n",
    "    # Try to infer gender via job title\n",
    "    genders = [mapping[w] for w in mapping.keys() if re.match(rf'\\b{w}\\b', job_title)]\n",
    "    if genders:\n",
    "        # Check if list only contains one gender\n",
    "        if genders.count(genders[0]) == len(genders):\n",
    "            return genders[0]\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "nat_norm_cols = [col for col in df_people_concat.columns if re.match(r'\\bnationality_\\d{1}_norm\\b', col)]\n",
    "df_people_concat['gender'] = df_people_concat.apply(lambda x: determine_gender(gender_mapping[LANGUAGE], [x[col] for col in nat_norm_cols], x['job_title_norm']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ehraid</th>\n",
       "      <th>message_raw</th>\n",
       "      <th>shab_date</th>\n",
       "      <th>shab_id</th>\n",
       "      <th>codes</th>\n",
       "      <th>keyword</th>\n",
       "      <th>first_name</th>\n",
       "      <th>last_name</th>\n",
       "      <th>job_title</th>\n",
       "      <th>authorization</th>\n",
       "      <th>...</th>\n",
       "      <th>nationality_1</th>\n",
       "      <th>nationality_2</th>\n",
       "      <th>nationality_3</th>\n",
       "      <th>nationality_4</th>\n",
       "      <th>nationality_1_iso_3166_1_alpha_2</th>\n",
       "      <th>nationality_2_iso_3166_1_alpha_2</th>\n",
       "      <th>nationality_3_iso_3166_1_alpha_2</th>\n",
       "      <th>nationality_4_norm</th>\n",
       "      <th>nationality_4_iso_3166_1_alpha_2</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>AA-Annoncen Agentur AG, in Basel, CHE-102.721....</td>\n",
       "      <td>2019-09-06</td>\n",
       "      <td>1004711015</td>\n",
       "      <td>[aenderungorgane]</td>\n",
       "      <td>ausgeschiedene personen und erloschene untersc...</td>\n",
       "      <td>Philippe</td>\n",
       "      <td>Nappez</td>\n",
       "      <td>Mitglied des Verwaltungsrates</td>\n",
       "      <td>mit Kollektivunterschrift zu zweien</td>\n",
       "      <td>...</td>\n",
       "      <td>CH</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>CH</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>AA-Annoncen Agentur AG, in Basel, CHE-102.721....</td>\n",
       "      <td>2019-09-06</td>\n",
       "      <td>1004711015</td>\n",
       "      <td>[aenderungorgane]</td>\n",
       "      <td>eingetragene personen neu oder mutierend</td>\n",
       "      <td>Daniel</td>\n",
       "      <td>Ebneter</td>\n",
       "      <td>Mitglied des Verwaltungsrates</td>\n",
       "      <td>mit Kollektivunterschrift zu zweien</td>\n",
       "      <td>...</td>\n",
       "      <td>CH</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>CH</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>AA-Annoncen Agentur AG, in Basel, CHE-102.721....</td>\n",
       "      <td>2020-02-07</td>\n",
       "      <td>1004825123</td>\n",
       "      <td>[status, status.aufl, status.aufl.liq, aenderu...</td>\n",
       "      <td>eingetragene personen neu oder mutierend</td>\n",
       "      <td>Gabriella</td>\n",
       "      <td>Karger Travella</td>\n",
       "      <td>Mitglied des Verwaltungsrates</td>\n",
       "      <td>mit Kollektivunterschrift zu zweien</td>\n",
       "      <td>...</td>\n",
       "      <td>CH</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>CH</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>AA-Annoncen Agentur AG, in Basel, CHE-102.721....</td>\n",
       "      <td>2020-02-07</td>\n",
       "      <td>1004825123</td>\n",
       "      <td>[status, status.aufl, status.aufl.liq, aenderu...</td>\n",
       "      <td>eingetragene personen neu oder mutierend</td>\n",
       "      <td>Julien</td>\n",
       "      <td>Orsini</td>\n",
       "      <td>Liquidator</td>\n",
       "      <td>mit Einzelunterschrift</td>\n",
       "      <td>...</td>\n",
       "      <td>CH</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>CH</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15</td>\n",
       "      <td>AAA EDV Software AG, in Aarau, CHE-106.307.377...</td>\n",
       "      <td>2022-04-19</td>\n",
       "      <td>1005453034</td>\n",
       "      <td>[aenderungorgane]</td>\n",
       "      <td>eingetragene personen neu oder mutierend</td>\n",
       "      <td>Urs</td>\n",
       "      <td>Antener</td>\n",
       "      <td>Präsident des Verwaltungsrates</td>\n",
       "      <td>mit Einzelunterschrift</td>\n",
       "      <td>...</td>\n",
       "      <td>CH</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>CH</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ehraid                                        message_raw   shab_date  \\\n",
       "0       2  AA-Annoncen Agentur AG, in Basel, CHE-102.721....  2019-09-06   \n",
       "1       2  AA-Annoncen Agentur AG, in Basel, CHE-102.721....  2019-09-06   \n",
       "2       2  AA-Annoncen Agentur AG, in Basel, CHE-102.721....  2020-02-07   \n",
       "3       2  AA-Annoncen Agentur AG, in Basel, CHE-102.721....  2020-02-07   \n",
       "4      15  AAA EDV Software AG, in Aarau, CHE-106.307.377...  2022-04-19   \n",
       "\n",
       "      shab_id                                              codes  \\\n",
       "0  1004711015                                  [aenderungorgane]   \n",
       "1  1004711015                                  [aenderungorgane]   \n",
       "2  1004825123  [status, status.aufl, status.aufl.liq, aenderu...   \n",
       "3  1004825123  [status, status.aufl, status.aufl.liq, aenderu...   \n",
       "4  1005453034                                  [aenderungorgane]   \n",
       "\n",
       "                                             keyword first_name  \\\n",
       "0  ausgeschiedene personen und erloschene untersc...   Philippe   \n",
       "1           eingetragene personen neu oder mutierend     Daniel   \n",
       "2           eingetragene personen neu oder mutierend  Gabriella   \n",
       "3           eingetragene personen neu oder mutierend     Julien   \n",
       "4           eingetragene personen neu oder mutierend        Urs   \n",
       "\n",
       "         last_name                       job_title  \\\n",
       "0           Nappez   Mitglied des Verwaltungsrates   \n",
       "1          Ebneter   Mitglied des Verwaltungsrates   \n",
       "2  Karger Travella   Mitglied des Verwaltungsrates   \n",
       "3           Orsini                      Liquidator   \n",
       "4          Antener  Präsident des Verwaltungsrates   \n",
       "\n",
       "                         authorization  ... nationality_1 nationality_2  \\\n",
       "0  mit Kollektivunterschrift zu zweien  ...            CH                 \n",
       "1  mit Kollektivunterschrift zu zweien  ...            CH                 \n",
       "2  mit Kollektivunterschrift zu zweien  ...            CH                 \n",
       "3               mit Einzelunterschrift  ...            CH                 \n",
       "4               mit Einzelunterschrift  ...            CH                 \n",
       "\n",
       "  nationality_3 nationality_4 nationality_1_iso_3166_1_alpha_2  \\\n",
       "0                                                           CH   \n",
       "1                                                           CH   \n",
       "2                                                           CH   \n",
       "3                                                           CH   \n",
       "4                                                           CH   \n",
       "\n",
       "  nationality_2_iso_3166_1_alpha_2 nationality_3_iso_3166_1_alpha_2  \\\n",
       "0                                                                     \n",
       "1                                                                     \n",
       "2                                                                     \n",
       "3                                                                     \n",
       "4                                                                     \n",
       "\n",
       "  nationality_4_norm nationality_4_iso_3166_1_alpha_2 gender  \n",
       "0                                                       None  \n",
       "1                                                       None  \n",
       "2                                                       None  \n",
       "3                                                          m  \n",
       "4                                                          m  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_upload = df_people_concat.drop(columns=['nationality_1_norm', 'nationality_2_norm', 'nationality_3_norm', 'job_title_norm'])\n",
    "df_upload.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_upload.to_csv(PROCESSED_DATA_DIR / f'people_and_firms_{LANGUAGE}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['undetermined', 'natural persons and legal entities', 'purpose',\n",
       "       'firm and address changes', 'capital and legal changes',\n",
       "       'mergers and separations'], dtype=object)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shab_merged.main_group.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CREATE HISTORICAL PURPOSE FRAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "purpose_df = shab_merged[shab_merged.main_group == 'purpose'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['nuovo scopo', 'nuovo scopo della sede principale',\n",
       "       'nuovo scopo della succursale'], dtype=object)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "purpose_df.keyword.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "purpose_lists = [l for l in purpose_df.text_slices if l and len(l) > 1]\n",
    "assert len(purpose_lists) == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "purpose_df['purpose_raw'] = [l[0] if l else '' for l in purpose_df['text_slices']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "purpose_df['branch'] = [int('succursale' in keyword) for keyword in purpose_df['keyword']]\n",
    "purpose_df['main_seat'] = [int('principale' in keyword) for keyword in purpose_df['keyword']]\n",
    "purpose_df['founding_purpose'] = [int('status.neu' in codes) for codes in purpose_df['codes']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "purpose_df = purpose_df.drop(columns=['registry_office_canton', 'message_raw', 'parsed_variables', 'main_group', 'text_slices'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ehraid</th>\n",
       "      <th>shab_id</th>\n",
       "      <th>shab_date</th>\n",
       "      <th>codes</th>\n",
       "      <th>keyword</th>\n",
       "      <th>purpose_raw</th>\n",
       "      <th>branch</th>\n",
       "      <th>main_seat</th>\n",
       "      <th>founding_purpose</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>157</td>\n",
       "      <td>3204479</td>\n",
       "      <td>2016-12-06</td>\n",
       "      <td>[zweckaenderung, aenderungorgane]</td>\n",
       "      <td>nuovo scopo</td>\n",
       "      <td>La società si propone la progettazione , la pr...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>441</td>\n",
       "      <td>1005401458</td>\n",
       "      <td>2022-02-09</td>\n",
       "      <td>[zweckaenderung, aenderungorgane]</td>\n",
       "      <td>nuovo scopo</td>\n",
       "      <td>L'acquisto , la vendita , la costruzione , la ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>441</td>\n",
       "      <td>1005905406</td>\n",
       "      <td>2023-12-08</td>\n",
       "      <td>[zweckaenderung]</td>\n",
       "      <td>nuovo scopo</td>\n",
       "      <td>L'acquisto , la vendita , la costruzione , la ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>441</td>\n",
       "      <td>1005956417</td>\n",
       "      <td>2024-02-08</td>\n",
       "      <td>[zweckaenderung]</td>\n",
       "      <td>nuovo scopo</td>\n",
       "      <td>L'acquisto , la vendita , la costruzione , la ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>1038</td>\n",
       "      <td>1005214878</td>\n",
       "      <td>2021-06-11</td>\n",
       "      <td>[zweckaenderung]</td>\n",
       "      <td>nuovo scopo</td>\n",
       "      <td>La società ha per scopo l'importazione , l'esp...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>545499</th>\n",
       "      <td>1681756</td>\n",
       "      <td>1006271807</td>\n",
       "      <td>2025-03-03</td>\n",
       "      <td>[status, status.neu]</td>\n",
       "      <td>nuovo scopo</td>\n",
       "      <td>Lo scopo della società è : sviluppo , progetta...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>545505</th>\n",
       "      <td>1681757</td>\n",
       "      <td>1006271809</td>\n",
       "      <td>2025-03-03</td>\n",
       "      <td>[status, status.neu]</td>\n",
       "      <td>nuovo scopo</td>\n",
       "      <td>La gestione di bar , tea room , ristoranti e e...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>545509</th>\n",
       "      <td>1681758</td>\n",
       "      <td>1006271810</td>\n",
       "      <td>2025-03-03</td>\n",
       "      <td>[status, status.neu]</td>\n",
       "      <td>nuovo scopo</td>\n",
       "      <td>Gestione cure del benessere personale unitamen...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>545517</th>\n",
       "      <td>1681777</td>\n",
       "      <td>1006271808</td>\n",
       "      <td>2025-03-03</td>\n",
       "      <td>[status, status.neu, vermoegenstransfer]</td>\n",
       "      <td>nuovo scopo</td>\n",
       "      <td>La società ha per scopo la gestione di centri ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>545525</th>\n",
       "      <td>1681847</td>\n",
       "      <td>1006272844</td>\n",
       "      <td>2025-03-04</td>\n",
       "      <td>[status, status.neu]</td>\n",
       "      <td>nuovo scopo</td>\n",
       "      <td>L'organizzazione e gestione di catering . La s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>31978 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         ehraid     shab_id   shab_date  \\\n",
       "2           157     3204479  2016-12-06   \n",
       "48          441  1005401458  2022-02-09   \n",
       "60          441  1005905406  2023-12-08   \n",
       "63          441  1005956417  2024-02-08   \n",
       "194        1038  1005214878  2021-06-11   \n",
       "...         ...         ...         ...   \n",
       "545499  1681756  1006271807  2025-03-03   \n",
       "545505  1681757  1006271809  2025-03-03   \n",
       "545509  1681758  1006271810  2025-03-03   \n",
       "545517  1681777  1006271808  2025-03-03   \n",
       "545525  1681847  1006272844  2025-03-04   \n",
       "\n",
       "                                           codes      keyword  \\\n",
       "2              [zweckaenderung, aenderungorgane]  nuovo scopo   \n",
       "48             [zweckaenderung, aenderungorgane]  nuovo scopo   \n",
       "60                              [zweckaenderung]  nuovo scopo   \n",
       "63                              [zweckaenderung]  nuovo scopo   \n",
       "194                             [zweckaenderung]  nuovo scopo   \n",
       "...                                          ...          ...   \n",
       "545499                      [status, status.neu]  nuovo scopo   \n",
       "545505                      [status, status.neu]  nuovo scopo   \n",
       "545509                      [status, status.neu]  nuovo scopo   \n",
       "545517  [status, status.neu, vermoegenstransfer]  nuovo scopo   \n",
       "545525                      [status, status.neu]  nuovo scopo   \n",
       "\n",
       "                                              purpose_raw  branch  main_seat  \\\n",
       "2       La società si propone la progettazione , la pr...       0          0   \n",
       "48      L'acquisto , la vendita , la costruzione , la ...       0          0   \n",
       "60      L'acquisto , la vendita , la costruzione , la ...       0          0   \n",
       "63      L'acquisto , la vendita , la costruzione , la ...       0          0   \n",
       "194     La società ha per scopo l'importazione , l'esp...       0          0   \n",
       "...                                                   ...     ...        ...   \n",
       "545499  Lo scopo della società è : sviluppo , progetta...       0          0   \n",
       "545505  La gestione di bar , tea room , ristoranti e e...       0          0   \n",
       "545509  Gestione cure del benessere personale unitamen...       0          0   \n",
       "545517  La società ha per scopo la gestione di centri ...       0          0   \n",
       "545525  L'organizzazione e gestione di catering . La s...       0          0   \n",
       "\n",
       "        founding_purpose  \n",
       "2                      0  \n",
       "48                     0  \n",
       "60                     0  \n",
       "63                     0  \n",
       "194                    0  \n",
       "...                  ...  \n",
       "545499                 1  \n",
       "545505                 1  \n",
       "545509                 1  \n",
       "545517                 1  \n",
       "545525                 1  \n",
       "\n",
       "[31978 rows x 9 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "purpose_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PROCESS HISTORICAL FIRM CHANGES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "firm_changes_df = shab_merged[shab_merged.main_group == 'firm and address changes'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['statuti modificati', 'nuovo recapito', 'altri indirizzi',\n",
       "       'indirizzo della liquidazione', 'nuova ditta', 'nuova sede',\n",
       "       'nuova succursale', 'statuti originari', 'nuovo indirizzo postale',\n",
       "       'nuova sede principale',\n",
       "       'numero di identificazione della sede principale',\n",
       "       'data dello statuto',\n",
       "       'nuovo nome della ditta della sede principale', 'sede principale',\n",
       "       'atto pubblico modificato', 'nuova ide', 'succursale radiata',\n",
       "       'atto pubblico originario', 'inizio'], dtype=object)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "firm_changes_df.keyword.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "firm_name_df = firm_changes_df[firm_changes_df['keyword'] == 'nuova ditta']\n",
    "firm_address_df = firm_changes_df[firm_changes_df['keyword'].isin(['nuovo recapito', 'altri indirizzi', 'indirizzo della liquidazione', 'nuovo indirizzo postale'])]\n",
    "firm_seat_df = firm_changes_df[firm_changes_df['keyword'].isin(['nuova sede', 'nuova sede principale', 'sede principale'])]\n",
    "branches_df = firm_changes_df[firm_changes_df['keyword'].isin(['nuova succursale', 'succursale radiata'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ehraid</th>\n",
       "      <th>shab_id</th>\n",
       "      <th>shab_date</th>\n",
       "      <th>registry_office_canton</th>\n",
       "      <th>message_raw</th>\n",
       "      <th>codes</th>\n",
       "      <th>keyword</th>\n",
       "      <th>parsed_variables</th>\n",
       "      <th>main_group</th>\n",
       "      <th>text_slices</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>1311</td>\n",
       "      <td>2707803</td>\n",
       "      <td>2016-03-07</td>\n",
       "      <td>TI</td>\n",
       "      <td>Adelheid AG, finora in Samedan, CHE-101.463.26...</td>\n",
       "      <td>[zweckaenderung, adressaenderung, aenderungorg...</td>\n",
       "      <td>nuova succursale</td>\n",
       "      <td>{'branches_until_now': [], 'branches_new': [],...</td>\n",
       "      <td>firm and address changes</td>\n",
       "      <td>[[ radiati : Lugano ]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2060</th>\n",
       "      <td>8433</td>\n",
       "      <td>1005483263</td>\n",
       "      <td>2022-05-27</td>\n",
       "      <td>TI</td>\n",
       "      <td>ARGOR-HERAEUS SA, in Mendrisio, CHE-102.670.49...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>nuova succursale</td>\n",
       "      <td>{'branches_until_now': [], 'branches_new': [{'...</td>\n",
       "      <td>firm and address changes</td>\n",
       "      <td>[Yverdon-les-Bains ( CHE-389.686.914 )]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2960</th>\n",
       "      <td>10845</td>\n",
       "      <td>2883205</td>\n",
       "      <td>2016-06-10</td>\n",
       "      <td>TI</td>\n",
       "      <td>Audio-Video G + M AG, in Lamone, CHE-106.048.0...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>nuova succursale</td>\n",
       "      <td>{'branches_until_now': [{'location': 'Yverdon-...</td>\n",
       "      <td>firm and address changes</td>\n",
       "      <td>[Yverdon-les-Bains ( CHE-279.466.641 ) [ finor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4098</th>\n",
       "      <td>14130</td>\n",
       "      <td>3794931</td>\n",
       "      <td>2017-10-06</td>\n",
       "      <td>GR</td>\n",
       "      <td>Barella SA, in Mesocco, CHE-101.430.409, socie...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>nuova succursale</td>\n",
       "      <td>{'branches_until_now': [], 'branches_new': [{'...</td>\n",
       "      <td>firm and address changes</td>\n",
       "      <td>[Roveredo ( GR ) ( CHE-279.082.542 )]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4108</th>\n",
       "      <td>14130</td>\n",
       "      <td>1005730560</td>\n",
       "      <td>2023-04-24</td>\n",
       "      <td>GR</td>\n",
       "      <td>Barella SA, in Mesocco, CHE-101.430.409, socie...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>nuova succursale</td>\n",
       "      <td>{'branches_until_now': [], 'branches_new': [],...</td>\n",
       "      <td>firm and address changes</td>\n",
       "      <td>[[ radiati : Roveredo ( GR ) ( CHE-279.082.542...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>531406</th>\n",
       "      <td>1631773</td>\n",
       "      <td>1006217211</td>\n",
       "      <td>2024-12-27</td>\n",
       "      <td>TI</td>\n",
       "      <td>Studio ICARA SA, in Lugano, CHE-461.344.790, s...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>nuova succursale</td>\n",
       "      <td>{'branches_until_now': [], 'branches_new': [{'...</td>\n",
       "      <td>firm and address changes</td>\n",
       "      <td>[Mendrisio ( CHE-145.530.944 )]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>531580</th>\n",
       "      <td>1632745</td>\n",
       "      <td>1006018052</td>\n",
       "      <td>2024-04-25</td>\n",
       "      <td>TI</td>\n",
       "      <td>MC Grecof SA, in Lugano, CHE-160.298.683, soci...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>nuova succursale</td>\n",
       "      <td>{'branches_until_now': [], 'branches_new': [{'...</td>\n",
       "      <td>firm and address changes</td>\n",
       "      <td>[Diepoldsau ( CHE-109.795.820 )]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>540646</th>\n",
       "      <td>1663701</td>\n",
       "      <td>1006234069</td>\n",
       "      <td>2025-01-21</td>\n",
       "      <td>GR</td>\n",
       "      <td>SEF Associati GmbH, in St. Moritz, CHE-462.298...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>nuova succursale</td>\n",
       "      <td>{'branches_until_now': [], 'branches_new': [{'...</td>\n",
       "      <td>firm and address changes</td>\n",
       "      <td>[Zug ( CHE-135.660.396 )]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>542027</th>\n",
       "      <td>1668815</td>\n",
       "      <td>1006229074</td>\n",
       "      <td>2025-01-15</td>\n",
       "      <td>TI</td>\n",
       "      <td>Yamamay Suisse SA, in Lugano, CHE-316.062.103,...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>nuova succursale</td>\n",
       "      <td>{'branches_until_now': [], 'branches_new': [{'...</td>\n",
       "      <td>firm and address changes</td>\n",
       "      <td>[Collina d'Oro ( CHE-342.328.896 )]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>544679</th>\n",
       "      <td>1678351</td>\n",
       "      <td>1006265499</td>\n",
       "      <td>2025-02-24</td>\n",
       "      <td>TI</td>\n",
       "      <td>Angelo Investment Service Sagl, in Massagno, C...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>nuova succursale</td>\n",
       "      <td>{'branches_until_now': [], 'branches_new': [{'...</td>\n",
       "      <td>firm and address changes</td>\n",
       "      <td>[Bellinzona ( CHE-403.877.941 )]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>759 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         ehraid     shab_id   shab_date registry_office_canton  \\\n",
       "224        1311     2707803  2016-03-07                     TI   \n",
       "2060       8433  1005483263  2022-05-27                     TI   \n",
       "2960      10845     2883205  2016-06-10                     TI   \n",
       "4098      14130     3794931  2017-10-06                     GR   \n",
       "4108      14130  1005730560  2023-04-24                     GR   \n",
       "...         ...         ...         ...                    ...   \n",
       "531406  1631773  1006217211  2024-12-27                     TI   \n",
       "531580  1632745  1006018052  2024-04-25                     TI   \n",
       "540646  1663701  1006234069  2025-01-21                     GR   \n",
       "542027  1668815  1006229074  2025-01-15                     TI   \n",
       "544679  1678351  1006265499  2025-02-24                     TI   \n",
       "\n",
       "                                              message_raw  \\\n",
       "224     Adelheid AG, finora in Samedan, CHE-101.463.26...   \n",
       "2060    ARGOR-HERAEUS SA, in Mendrisio, CHE-102.670.49...   \n",
       "2960    Audio-Video G + M AG, in Lamone, CHE-106.048.0...   \n",
       "4098    Barella SA, in Mesocco, CHE-101.430.409, socie...   \n",
       "4108    Barella SA, in Mesocco, CHE-101.430.409, socie...   \n",
       "...                                                   ...   \n",
       "531406  Studio ICARA SA, in Lugano, CHE-461.344.790, s...   \n",
       "531580  MC Grecof SA, in Lugano, CHE-160.298.683, soci...   \n",
       "540646  SEF Associati GmbH, in St. Moritz, CHE-462.298...   \n",
       "542027  Yamamay Suisse SA, in Lugano, CHE-316.062.103,...   \n",
       "544679  Angelo Investment Service Sagl, in Massagno, C...   \n",
       "\n",
       "                                                    codes           keyword  \\\n",
       "224     [zweckaenderung, adressaenderung, aenderungorg...  nuova succursale   \n",
       "2060                                                  NaN  nuova succursale   \n",
       "2960                                                  NaN  nuova succursale   \n",
       "4098                                                  NaN  nuova succursale   \n",
       "4108                                                  NaN  nuova succursale   \n",
       "...                                                   ...               ...   \n",
       "531406                                                NaN  nuova succursale   \n",
       "531580                                                NaN  nuova succursale   \n",
       "540646                                                NaN  nuova succursale   \n",
       "542027                                                NaN  nuova succursale   \n",
       "544679                                                NaN  nuova succursale   \n",
       "\n",
       "                                         parsed_variables  \\\n",
       "224     {'branches_until_now': [], 'branches_new': [],...   \n",
       "2060    {'branches_until_now': [], 'branches_new': [{'...   \n",
       "2960    {'branches_until_now': [{'location': 'Yverdon-...   \n",
       "4098    {'branches_until_now': [], 'branches_new': [{'...   \n",
       "4108    {'branches_until_now': [], 'branches_new': [],...   \n",
       "...                                                   ...   \n",
       "531406  {'branches_until_now': [], 'branches_new': [{'...   \n",
       "531580  {'branches_until_now': [], 'branches_new': [{'...   \n",
       "540646  {'branches_until_now': [], 'branches_new': [{'...   \n",
       "542027  {'branches_until_now': [], 'branches_new': [{'...   \n",
       "544679  {'branches_until_now': [], 'branches_new': [{'...   \n",
       "\n",
       "                      main_group  \\\n",
       "224     firm and address changes   \n",
       "2060    firm and address changes   \n",
       "2960    firm and address changes   \n",
       "4098    firm and address changes   \n",
       "4108    firm and address changes   \n",
       "...                          ...   \n",
       "531406  firm and address changes   \n",
       "531580  firm and address changes   \n",
       "540646  firm and address changes   \n",
       "542027  firm and address changes   \n",
       "544679  firm and address changes   \n",
       "\n",
       "                                              text_slices  \n",
       "224                                [[ radiati : Lugano ]]  \n",
       "2060              [Yverdon-les-Bains ( CHE-389.686.914 )]  \n",
       "2960    [Yverdon-les-Bains ( CHE-279.466.641 ) [ finor...  \n",
       "4098                [Roveredo ( GR ) ( CHE-279.082.542 )]  \n",
       "4108    [[ radiati : Roveredo ( GR ) ( CHE-279.082.542...  \n",
       "...                                                   ...  \n",
       "531406                    [Mendrisio ( CHE-145.530.944 )]  \n",
       "531580                   [Diepoldsau ( CHE-109.795.820 )]  \n",
       "540646                          [Zug ( CHE-135.660.396 )]  \n",
       "542027                [Collina d'Oro ( CHE-342.328.896 )]  \n",
       "544679                   [Bellinzona ( CHE-403.877.941 )]  \n",
       "\n",
       "[759 rows x 10 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "branches_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PROCESS CAPITAL CHANGES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "capital_changes = shab_merged[shab_merged.main_group == 'capital and legal changes'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correct wrong values like '446.001.000.00'\n",
    "def correct_number(number_str: str) -> str:\n",
    "    parts = number_str.rsplit('.', 1)\n",
    "    return parts[0].replace('.', '') + '.' + parts[1] if len(parts) > 1 else parts[0].replace('.', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shab_ids = [[], []]\n",
    "keywords = [[], []]\n",
    "main_groups = [[], []]\n",
    "\n",
    "capital_new = []\n",
    "capital_until_now = []\n",
    "num_shares_new = []\n",
    "val_shares_new = []\n",
    "typ_shares_new = []\n",
    "\n",
    "for i, row in capital_changes.iterrows():\n",
    "    shab_id = row['shab_id']\n",
    "    keyword = row['keyword']\n",
    "    main_group = row['main_group']\n",
    "\n",
    "    parsed_variables = row['parsed_variables']\n",
    "    cap_new = parsed_variables.get('capital_new', [])\n",
    "    cap_unt = parsed_variables.get('capital_until_now', [])\n",
    "    srs_new = parsed_variables.get('shares_new', [])\n",
    "\n",
    "    if cap_new or cap_unt:\n",
    "        capital_new.append(cap_new[0] if len(cap_new) > 0 else None)\n",
    "        capital_until_now.append(cap_unt[0] if len(cap_unt) > 0 else None)\n",
    "        shab_ids[0].append(shab_id)\n",
    "        keywords[0].append(keyword)\n",
    "        main_groups[0].append(main_group)\n",
    "    if srs_new:\n",
    "        for s in srs_new:\n",
    "            num_shares_new.append(s.get('number'))\n",
    "            val_shares_new.append(s.get('value'))\n",
    "            typ_shares_new.append(s.get('type'))\n",
    "            shab_ids[1].append(shab_id)\n",
    "            keywords[1].append(keyword)\n",
    "            main_groups[1].append(main_group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap_new = pd.DataFrame({\n",
    "    'shab_id': shab_ids[0],\n",
    "    'keyword': keywords[0],\n",
    "    'main_group': main_groups[0],\n",
    "    'capital_new': capital_new,\n",
    "    'capital_until_now': capital_until_now})\n",
    "\n",
    "cap_new['capital_new'] = cap_new['capital_new'].fillna('').str.replace(\"'\", \"\", regex=False)\n",
    "cap_new['capital_until_now'] = cap_new['capital_until_now'].fillna('').str.replace(\"'\", \"\", regex=False)\n",
    "\n",
    "# Extract Währung\n",
    "cap_new['currency_new'] = cap_new['capital_new'].str.extract(r'^([^\\d\\s]+)')\n",
    "cap_new['currency_new'] = cap_new['currency_new'].fillna('')\n",
    "\n",
    "cap_new['currency_until_now'] = cap_new['capital_until_now'].str.extract(r'^([^\\d\\s]+)')\n",
    "cap_new['currency_until_now'] = cap_new['currency_until_now'].fillna('')\n",
    "\n",
    "# Extract Kapital\n",
    "cap_new['capital_new'] = cap_new['capital_new'].str.extract(r'([\\d.,]+)').astype(str)\n",
    "cap_new['capital_until_now'] = cap_new['capital_until_now'].str.extract(r'([\\d.,]+)').astype(str)\n",
    "\n",
    "# Apply correction to remove unneccessary punctuations\n",
    "cap_new['capital_new'] = cap_new['capital_new'].apply(correct_number)\n",
    "cap_new['capital_until_now'] = cap_new['capital_until_now'].apply(correct_number)\n",
    "\n",
    "cap_new['capital_new'] = [v.replace(',', '.') if not '.' in v else v.replace(',', '') for v in cap_new['capital_new']]\n",
    "cap_new.loc[cap_new['capital_new'] == '.', 'capital_new'] = np.nan\n",
    "\n",
    "cap_new['capital_until_now'] = [v.replace(',', '.') if not '.' in v else v.replace(',', '') for v in cap_new['capital_until_now']]\n",
    "cap_new.loc[cap_new['capital_until_now'] == '.', 'capital_until_now'] = np.nan\n",
    "\n",
    "# Ensure correct types\n",
    "cap_new['capital_new'] = cap_new['capital_new'].astype(float)\n",
    "cap_new['capital_until_now'] = cap_new['capital_until_now'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stocks_new = pd.DataFrame({\n",
    "    'shab_id': shab_ids[1],\n",
    "    'keyword': keywords[1],\n",
    "    'hauptkategorie': main_groups[1],\n",
    "    'num_shares_new': num_shares_new,\n",
    "    'val_shares_new': val_shares_new,\n",
    "    'typ_shares_new': typ_shares_new,})\n",
    "\n",
    "stocks_new['val_shares_new'] = stocks_new['val_shares_new'].fillna('').str.replace(\"'\", \"\", regex=False)\n",
    "\n",
    "# Extract Währung\n",
    "stocks_new['currency_shares_new'] = stocks_new['val_shares_new'].str.extract(r'^([^\\d\\s]+)')\n",
    "stocks_new['currency_shares_new'] = stocks_new['currency_shares_new'].fillna('')\n",
    "\n",
    "# Extract number of Stocks, etc.\n",
    "stocks_new['val_shares_new'] = stocks_new['val_shares_new'].str.extract(r'([\\d.,]+)').astype(str)\n",
    "\n",
    "# Apply correction to remove unneccessary punctuations\n",
    "stocks_new['val_shares_new'] = stocks_new['val_shares_new'].apply(correct_number)\n",
    "stocks_new['val_shares_new'] = [v.replace(',', '.') if not '.' in v else v.replace(',', '') for v in stocks_new['val_shares_new']]\n",
    "stocks_new.loc[stocks_new['val_shares_new'] == '.', 'val_shares_new'] = np.nan\n",
    "\n",
    "# Ensure correct types\n",
    "stocks_new['val_shares_new'] = stocks_new['val_shares_new'].astype(float)\n",
    "stocks_new['num_shares_new'] = stocks_new['num_shares_new'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate total value of the capital by multiplying the number of shares with their individual value\n",
    "stocks_new['value_total'] = stocks_new['num_shares_new'] * stocks_new['val_shares_new']\n",
    "\n",
    "# Calculate new capital for shab ids where kapital_neu variable is not given, but scheine_neu is\n",
    "missing_ids = set(stocks_new.shab_id).difference(set(cap_new.shab_id))\n",
    "stocks_new_missing = stocks_new[stocks_new.shab_id.isin(missing_ids)]\n",
    "\n",
    "cap_new_missing = stocks_new_missing.groupby(['shab_id', 'keyword', 'main_group']).agg(\n",
    "    capital_new=pd.NamedAgg(column='value_total', aggfunc='sum'),\n",
    "    currency_new=pd.NamedAgg(column='currency_shares_new', aggfunc=lambda x: list(set([currency for currency in x if currency != ''])))).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if there are mixed currencies\n",
    "assert len([cur_set for cur_set in cap_new_missing['currency_new'] if len(cur_set) > 1]) == 0\n",
    "\n",
    "cap_new_missing['currency_new'] = [v[0] if len(v) > 0 else '' for v in cap_new_missing['currency_new']]\n",
    "cap_new_missing['currency_until_now'] = ''\n",
    "cap_new_missing['capital_new'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the two dataframes to get all capital changes\n",
    "cap_new_concat = pd.concat([cap_new, cap_new_missing])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap_new_concat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap_new_concat.to_csv(EXTERNAL_DATA_DIR / 'capital_changes.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PROCESS MERGERS AND ACQUISIITONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mergers_and_acquisitions = shab_merged[shab_merged.main_group == 'mergers and separations'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shab_ids = []\n",
    "keywords = []\n",
    "main_groups = []\n",
    "text_passages = []\n",
    "\n",
    "contract_dates = []\n",
    "bilanzdaten = []\n",
    "\n",
    "firm_taken_over = []\n",
    "location_taken_over = []\n",
    "id_taken_over = []\n",
    "assets_taken_over = []\n",
    "liabilities_taken_over = []\n",
    "\n",
    "for i, row in mergers_and_acquisitions.iterrows():\n",
    "    shab_id = row['shab_id']\n",
    "    keyword = row['keyword']\n",
    "    main_group = row['main_group']\n",
    "    text_passage = row['text_slice']\n",
    "\n",
    "    parsed_variables = row['parsed_variables']\n",
    "\n",
    "    if parsed_variables:\n",
    "        contract_date = parsed_variables.get('contract_date', [])\n",
    "        bilanzdatum = parsed_variables.get('bilanzdatum', [])\n",
    "        firms_taken_over = parsed_variables.get('firms_taken_over', [])\n",
    "        for firm in firms_taken_over:\n",
    "            firm_name = firm.get('firm_name', '')\n",
    "            location = firm.get('location', '')\n",
    "            id = firm.get('id', '')\n",
    "            capital_taken_over = firm.get('capital_taken_over', {})\n",
    "            assets = capital_taken_over.get('aktiven', '') if capital_taken_over else ''\n",
    "            liabilities = capital_taken_over.get('passiven', '') if capital_taken_over else ''\n",
    "\n",
    "            contract_dates.append(contract_date[0] if len(contract_date) > 0 else '')\n",
    "            bilanzdaten.append(bilanzdatum[0] if len(bilanzdatum) > 0 else '')\n",
    "            firm_taken_over.append(firm_name)\n",
    "            location_taken_over.append(location)\n",
    "            id_taken_over.append(id)\n",
    "            assets_taken_over.append(assets)\n",
    "            liabilities_taken_over.append(liabilities)\n",
    "            shab_ids.append(shab_id)\n",
    "            keywords.append(keyword)\n",
    "            main_groups.append(main_group)\n",
    "            text_passages.append(text_passage)\n",
    "    else:\n",
    "        firm_taken_over.append('')\n",
    "        location_taken_over.append('')\n",
    "        id_taken_over.append('')\n",
    "        assets_taken_over.append('')\n",
    "        liabilities_taken_over.append('')\n",
    "        shab_ids.append(shab_id)\n",
    "        keywords.append(keyword)\n",
    "        main_groups.append(main_group)\n",
    "        text_passages.append(text_passage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(shab_ids) == len(keywords) == len(main_groups) == len(firm_taken_over) == len(location_taken_over) == len(id_taken_over) == len(assets_taken_over) == len(liabilities_taken_over)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_mergers = pd.DataFrame({\n",
    "    'shab_id': shab_ids,\n",
    "    'keyword': keywords,\n",
    "    'hauptkategorie': main_groups,\n",
    "    'texte': text_passages,\n",
    "    'firm_taken_over': firm_taken_over,\n",
    "    'location_taken_over': location_taken_over,\n",
    "    'id_taken_over': id_taken_over,\n",
    "    'assets_taken_over': assets_taken_over,\n",
    "    'liabilities_taken_over': liabilities_taken_over\n",
    "})\n",
    "\n",
    "processed_mergers['assets_taken_over'] = processed_mergers['assets_taken_over'].fillna('').str.replace(\"'\", \"\", regex=False)\n",
    "processed_mergers['liabilities_taken_over'] = processed_mergers['liabilities_taken_over'].fillna('').str.replace(\"'\", \"\", regex=False)\n",
    "\n",
    "# Extract Währung of Aktiven/Passiven\n",
    "processed_mergers['currency_assets_taken_over'] = processed_mergers['assets_taken_over'].str.extract(r'^([^\\d\\s]+)')\n",
    "processed_mergers['currency_assets_taken_over'] = processed_mergers['currency_assets_taken_over'].fillna('')\n",
    "\n",
    "processed_mergers['currency_liabilities_taken_over'] = processed_mergers['liabilities_taken_over'].str.extract(r'^([^\\d\\s]+)')\n",
    "processed_mergers['currency_liabilities_taken_over'] = processed_mergers['currency_liabilities_taken_over'].fillna('')\n",
    "\n",
    "# Extract value of Aktiven/Passiven\n",
    "processed_mergers['assets_taken_over'] = processed_mergers['assets_taken_over'].str.extract(r'([\\d.,]+)').astype(str)\n",
    "\n",
    "processed_mergers['liabilities_taken_over'] = processed_mergers['liabilities_taken_over'].str.extract(r'([\\d.,]+)').astype(str)\n",
    "\n",
    "# Apply correction to remove unneccessary punctuations\n",
    "processed_mergers['assets_taken_over'] = processed_mergers['assets_taken_over'].apply(correct_number)\n",
    "processed_mergers['assets_taken_over'] = [v.replace(',', '.') if not '.' in v else v.replace(',', '') for v in processed_mergers['assets_taken_over']]\n",
    "\n",
    "processed_mergers['liabilities_taken_over'] = processed_mergers['liabilities_taken_over'].apply(correct_number)\n",
    "processed_mergers['liabilities_taken_over'] = [v.replace(',', '.') if not '.' in v else v.replace(',', '') for v in processed_mergers['liabilities_taken_over']]\n",
    "\n",
    "# Ensure correct types\n",
    "processed_mergers['assets_taken_over'] = processed_mergers['assets_taken_over'].astype(float)\n",
    "processed_mergers['liabilities_taken_over'] = processed_mergers['liabilities_taken_over'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_mergers.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_mergers.to_csv(EXTERNAL_DATA_DIR / 'merger_sizes.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
