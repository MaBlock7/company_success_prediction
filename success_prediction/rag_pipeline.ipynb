{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import json\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "from ftlangdetect import detect\n",
    "\n",
    "from success_prediction.rag_components.embeddings import EmbeddingCreator\n",
    "from success_prediction.rag_components.cleanup import MarkdownCleaner\n",
    "from success_prediction.vector_db.utils import DatabaseClient\n",
    "\n",
    "from success_prediction.config import RAW_DATA_DIR, PROCESSED_DATA_DIR\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_batches(list_object: list, batch_size: int) -> list:\n",
    "    length = len(list_object)\n",
    "    for idx in range(0, length, batch_size):\n",
    "        yield list_object[idx:min(idx + batch_size, length)]\n",
    "\n",
    "\n",
    "def load_raw_file(file_path: Path):\n",
    "    with open(file_path, 'r') as f:\n",
    "        return json.load(f)\n",
    "\n",
    "\n",
    "def store_links(file_path: Path, data: dict):\n",
    "    with open(file_path, 'w', encoding='utf-8') as f:\n",
    "        return json.dump(data, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "\n",
    "def structure_links(\n",
    "    ehraid: int,\n",
    "    links: list[dict],\n",
    "    email_addresses: set(),\n",
    "    social_media: dict\n",
    ") -> dict:\n",
    "    for link in links:\n",
    "        base_domain = link.get('base_domain')\n",
    "        if '@' in link.get('text'):\n",
    "            email_addresses[ehraid]['emails'].add(link['text'])\n",
    "        elif base_domain == \"linkedin.com\":\n",
    "            social_media[ehraid]['linkedin'].add(link['href'])\n",
    "        elif base_domain == \"instagram.com\":\n",
    "            social_media[ehraid]['instagram'].add(link['href'])\n",
    "        elif base_domain == \"facebook.com\":\n",
    "            social_media[ehraid]['facebook'].add(link['href'])\n",
    "        elif base_domain == \"tiktok.com\":\n",
    "            social_media[ehraid]['tiktok'].add(link['href'])\n",
    "        elif base_domain == \"youtube.com\":\n",
    "            social_media[ehraid]['youtube'].add(link['href'])\n",
    "        elif base_domain == \"x.com\":\n",
    "            social_media[ehraid]['x'].add(link['href'])\n",
    "    return email_addresses, social_media\n",
    "            \n",
    "\n",
    "async def run_pipeline(idx: int, file_path: Path):\n",
    "\n",
    "    raw_json = load_raw_file(file_path)\n",
    "    processed_files = []\n",
    "    email_addresses = {}\n",
    "    social_media = {}\n",
    "    for ehraid, urls in tqdm(raw_json.items()):\n",
    "        email_addresses[ehraid] = {'emails': set()}\n",
    "        social_media[ehraid] = {\n",
    "            'linkedin': set(),\n",
    "            'instagram': set(),\n",
    "            'facebook': set(),\n",
    "            'tiktok': set(),\n",
    "            'youtube': set(),\n",
    "            'x': set(),\n",
    "        }\n",
    "        for url, attributes in urls.items():\n",
    "            markdown = attributes.get('markdown')\n",
    "\n",
    "            if not markdown:\n",
    "                continue\n",
    "\n",
    "            date = attributes['date']\n",
    "            external_links = attributes['links']['external']\n",
    "            markdown_clean = cleaner.clean(markdown)\n",
    "            markdown_chunks = embedding_creator.chunk(markdown_clean)\n",
    "\n",
    "            language = detect(text=markdown_clean)\n",
    "\n",
    "            embeddings = embedding_creator.embed(markdown_chunks)\n",
    "\n",
    "            processed_files.append(\n",
    "                {\n",
    "                    'ehraid': [int(ehraid)] * len(embeddings),\n",
    "                    'url': [str(url)] * len(embeddings),\n",
    "                    'date': [date] * len(embeddings),\n",
    "                    'text': markdown_chunks,\n",
    "                    'language': [language] * len(embeddings),\n",
    "                    'embedding': embeddings,\n",
    "                }\n",
    "            )\n",
    "            email_addresses, social_media = structure_links(ehraid, external_links, email_addresses, social_media)\n",
    "\n",
    "    db_client.insert_data(data=processed_files)\n",
    "\n",
    "    store_links(PROCESSED_DATA_DIR / f'emails_{idx}.json', email_addresses)\n",
    "    store_links(PROCESSED_DATA_DIR / f'social_media_{idx}.json', social_media)\n",
    "\n",
    "\n",
    "async def main(raw_files: list[Path], batch_size: int = 32_000):\n",
    "    for batch in create_batches(raw_files, batch_size):\n",
    "        tasks = []\n",
    "        for i, file in enumerate(batch):\n",
    "            tasks.append(run_pipeline(i, file))\n",
    "        await asyncio.gather(*tasks)\n",
    "    \n",
    "    \n",
    "if __name__ == '__main__':\n",
    "\n",
    "    cleaner = MarkdownCleaner()\n",
    "    embedding_creator = EmbeddingCreator(model_name='intfloat/multilingual-e5-large-instruct')\n",
    "\n",
    "    init_args = {'dim': 1024}\n",
    "    db_client = DatabaseClient(**init_args)\n",
    "    db_client.setup_database()\n",
    "    \n",
    "    raw_files = [file for file in Path(RAW_DATA_DIR).iterdir() if file.endswith('.json')]\n",
    "    \n",
    "    asyncio.run(main())\n",
    "    await main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
