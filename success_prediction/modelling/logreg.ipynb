{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-06-19 15:45:14.240\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msuccess_prediction.config\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m11\u001b[0m - \u001b[1mPROJ_ROOT path is: /Users/manuelbolz/Documents/git/for_work/company_success_prediction\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import ast\n",
    "import joblib\n",
    "import pickle\n",
    "import warnings\n",
    "from collections import Counter\n",
    "from pathlib import Path\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import optuna\n",
    "from optuna.distributions import IntDistribution, FloatDistribution, CategoricalDistribution\n",
    "from optuna.integration import OptunaSearchCV\n",
    "\n",
    "from pocketknife.database import connect_database, read_from_database\n",
    "\n",
    "from scipy.stats import t, ttest_1samp\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score, f1_score\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, OrdinalEncoder\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from success_prediction.modelling.config import (\n",
    "    ALL_BINARY_FEATURE_COLS, ALL_CATEGORICAL_FEATURE_COLS, ALL_CONTINUOUS_FEATURE_COLS, \n",
    "    FOUNDING_WEBSITE_FEATURE_COLS, CURRENT_WEBSITE_FEATURE_COLS, TARGET_COLS\n",
    ")\n",
    "from success_prediction.config import RAW_DATA_DIR, PROCESSED_DATA_DIR, MODELS_DIR\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"sklearn.preprocessing._encoders\")\n",
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=optuna.exceptions.ExperimentalWarning)\n",
    "\n",
    "optuna.logging.set_verbosity(optuna.logging.ERROR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# READ COMPANY SAMPLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ly/6qys5jn501gbqmkkkgmvpf0h0000gn/T/ipykernel_51288/59758968.py:1: DtypeWarning: Columns (41,43,157,164) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  company_sample = pd.read_csv(RAW_DATA_DIR / 'company_sample' / 'until_2020' / '2020_sample_encoded_features.csv')\n"
     ]
    }
   ],
   "source": [
    "company_sample = pd.read_csv(RAW_DATA_DIR / 'company_sample' / 'until_2020' / '2020_sample_encoded_features.csv')\n",
    "\n",
    "all_feature_df = company_sample[TARGET_COLS + ALL_BINARY_FEATURE_COLS + ALL_CATEGORICAL_FEATURE_COLS + ALL_CONTINUOUS_FEATURE_COLS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target_inv_exit</th>\n",
       "      <th>target_acquisition</th>\n",
       "      <th>target_non_gov_investment</th>\n",
       "      <th>target_inno_subsidy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>target_inv_exit</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.032101</td>\n",
       "      <td>-0.017236</td>\n",
       "      <td>-0.019113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>target_acquisition</th>\n",
       "      <td>-0.032101</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.001043</td>\n",
       "      <td>-0.004808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>target_non_gov_investment</th>\n",
       "      <td>-0.017236</td>\n",
       "      <td>-0.001043</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.348525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>target_inno_subsidy</th>\n",
       "      <td>-0.019113</td>\n",
       "      <td>-0.004808</td>\n",
       "      <td>0.348525</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           target_inv_exit  target_acquisition  \\\n",
       "target_inv_exit                   1.000000           -0.032101   \n",
       "target_acquisition               -0.032101            1.000000   \n",
       "target_non_gov_investment        -0.017236           -0.001043   \n",
       "target_inno_subsidy              -0.019113           -0.004808   \n",
       "\n",
       "                           target_non_gov_investment  target_inno_subsidy  \n",
       "target_inv_exit                            -0.017236            -0.019113  \n",
       "target_acquisition                         -0.001043            -0.004808  \n",
       "target_non_gov_investment                   1.000000             0.348525  \n",
       "target_inno_subsidy                         0.348525             1.000000  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_feature_df[TARGET_COLS].corr(method='pearson')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target_inv_exit</th>\n",
       "      <th>current_vp_w</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>target_inv_exit</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.064871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>current_vp_w</th>\n",
       "      <td>-0.064871</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 target_inv_exit  current_vp_w\n",
       "target_inv_exit         1.000000     -0.064871\n",
       "current_vp_w           -0.064871      1.000000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "company_sample[['target_inv_exit', 'current_vp_w']].corr(method='pearson')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handle missing values in base features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_missing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>district_id</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>canton_id</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>urban_rural</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>typology_9c</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>typology_25c</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>founding_dominant_language</th>\n",
       "      <td>60987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>current_dominant_language</th>\n",
       "      <td>64720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>firm_name_length</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>population</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>founding_mean_text_len</th>\n",
       "      <td>60987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>founding_n_internal_links_mean</th>\n",
       "      <td>60987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>founding_n_external_links_mean</th>\n",
       "      <td>60987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>founding_n_languages</th>\n",
       "      <td>60987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>founding_pr_sdg_similarity</th>\n",
       "      <td>70866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>founding_pr_w_sdg_similarity</th>\n",
       "      <td>70866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>founding_pr_w_red_sdg_similarity</th>\n",
       "      <td>70866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>founding_doc2vec_diff</th>\n",
       "      <td>71093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>founding_lp</th>\n",
       "      <td>70866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>founding_lp_w</th>\n",
       "      <td>70866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>founding_lp_w_red</th>\n",
       "      <td>70866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>founding_vp</th>\n",
       "      <td>70866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>founding_vp_w</th>\n",
       "      <td>70866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>founding_vp_w_red</th>\n",
       "      <td>70866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>current_mean_text_len</th>\n",
       "      <td>64720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>current_n_internal_links_mean</th>\n",
       "      <td>64720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>current_n_external_links_mean</th>\n",
       "      <td>64720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>current_n_languages</th>\n",
       "      <td>64720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>current_pr_sdg_similarity</th>\n",
       "      <td>70772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>current_pr_w_sdg_similarity</th>\n",
       "      <td>70772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>current_pr_w_red_sdg_similarity</th>\n",
       "      <td>70772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>current_doc2vec_diff</th>\n",
       "      <td>70901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>current_lp</th>\n",
       "      <td>70772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>current_lp_w</th>\n",
       "      <td>70772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>current_lp_w_red</th>\n",
       "      <td>70772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>current_vp</th>\n",
       "      <td>70772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>current_vp_w</th>\n",
       "      <td>70772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>current_vp_w_red</th>\n",
       "      <td>70772</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  n_missing\n",
       "district_id                               3\n",
       "canton_id                                 3\n",
       "urban_rural                               3\n",
       "typology_9c                               3\n",
       "typology_25c                              3\n",
       "founding_dominant_language            60987\n",
       "current_dominant_language             64720\n",
       "firm_name_length                          1\n",
       "population                                6\n",
       "founding_mean_text_len                60987\n",
       "founding_n_internal_links_mean        60987\n",
       "founding_n_external_links_mean        60987\n",
       "founding_n_languages                  60987\n",
       "founding_pr_sdg_similarity            70866\n",
       "founding_pr_w_sdg_similarity          70866\n",
       "founding_pr_w_red_sdg_similarity      70866\n",
       "founding_doc2vec_diff                 71093\n",
       "founding_lp                           70866\n",
       "founding_lp_w                         70866\n",
       "founding_lp_w_red                     70866\n",
       "founding_vp                           70866\n",
       "founding_vp_w                         70866\n",
       "founding_vp_w_red                     70866\n",
       "current_mean_text_len                 64720\n",
       "current_n_internal_links_mean         64720\n",
       "current_n_external_links_mean         64720\n",
       "current_n_languages                   64720\n",
       "current_pr_sdg_similarity             70772\n",
       "current_pr_w_sdg_similarity           70772\n",
       "current_pr_w_red_sdg_similarity       70772\n",
       "current_doc2vec_diff                  70901\n",
       "current_lp                            70772\n",
       "current_lp_w                          70772\n",
       "current_lp_w_red                      70772\n",
       "current_vp                            70772\n",
       "current_vp_w                          70772\n",
       "current_vp_w_red                      70772"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_df = all_feature_df.isna().sum().loc[lambda x: x > 0].to_frame('n_missing')\n",
    "missing_df[missing_df['n_missing'] > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the row with missing firm name length\n",
    "all_feature_df = all_feature_df[all_feature_df['firm_name_length'].notna()]\n",
    "\n",
    "# Fill missing population with 0\n",
    "all_feature_df['population'] = all_feature_df['population'].fillna(0)\n",
    "\n",
    "# Keep the following collumns as missings since they are in locations not belonging to any canton, missing is correct in this case\n",
    "for col in ['district_id', 'canton_id', 'urban_rural', 'typology_9c', 'typology_25c']:\n",
    "    all_feature_df[col] = all_feature_df[col].fillna(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in ALL_BINARY_FEATURE_COLS + TARGET_COLS:\n",
    "    if col in all_feature_df.columns:\n",
    "        all_feature_df[col] = all_feature_df[col].astype('int8')\n",
    "\n",
    "for col in ALL_CONTINUOUS_FEATURE_COLS:\n",
    "    if col in all_feature_df.columns:\n",
    "        all_feature_df[col] = all_feature_df[col].astype('float32')\n",
    "\n",
    "for col in ALL_CATEGORICAL_FEATURE_COLS:\n",
    "    if col in all_feature_df.columns:\n",
    "        all_feature_df[col] = all_feature_df[col].astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LogReg Features\n",
    "\n",
    "For logistic regression, the features listed below are included.\n",
    "- High-cardinality categorical features are removed and the remaining one-hot encoded.\n",
    "- Continuous features are scaled using StandardScaler().\n",
    "- Binary features are used as is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOGREG_BINARY_FEATURES = [\n",
    "    'firm_name_swiss_ref',\n",
    "    'firm_name_holding_ref',\n",
    "    'firm_name_geog_ref',\n",
    "    'firm_name_founder_match',\n",
    "    'firm_name_male_match',\n",
    "    'firm_name_female_match',\n",
    "    'bps_geographic_term',\n",
    "    'bps_male_name',\n",
    "    'bps_female_name',\n",
    "]\n",
    "\n",
    "# < 30 categories and not strongly correlated\n",
    "LOGREG_LOW_CAT_FEATURES = [\n",
    "    'founding_legal_form',\n",
    "    'section_1_label',\n",
    "    'typology_9c',\n",
    "    'canton_id',\n",
    "    'bps_length_quantiles_5',\n",
    "    'founding_dominant_language',\n",
    "    'current_dominant_language',\n",
    "]\n",
    "\n",
    "LOGREG_HIGH_CAT_FEATURES = []  # No features with high cardinality\n",
    "\n",
    "LOGREG_CONTINUOUS_FEATURES = [  \n",
    "    'capital_chf',\n",
    "    'firm_name_length',\n",
    "    'population',\n",
    "    'n_firms_within_10m',\n",
    "    'n_firms_within_2.5km',\n",
    "    'n_founders',\n",
    "    'n_inscribed_firms',\n",
    "    'n_distinct_nationalities',\n",
    "    'pct_female_founders',\n",
    "    'pct_foreign_founders',\n",
    "    'pct_dr_titles',\n",
    "    'pct_founders_same_residence',\n",
    "    'pct_founders_with_prior_founding',\n",
    "    'n_dissolved_firms',\n",
    "    'n_existing_firms',\n",
    "    'bps_mean_word_length',\n",
    "    'bps_lix',\n",
    "    'bps_min_word_freq_norm',\n",
    "    'bps_max_word_freq_norm',\n",
    "    'bps_freq_ratio_norm',\n",
    "    'founding_mean_text_len',\n",
    "    'founding_n_internal_links_mean',\n",
    "    'founding_n_external_links_mean',\n",
    "    'founding_n_languages',\n",
    "    'founding_pr_sdg_similarity',\n",
    "    'founding_pr_w_sdg_similarity',\n",
    "    'founding_pr_w_red_sdg_similarity',\n",
    "    'founding_doc2vec_diff',\n",
    "    'founding_lp',\n",
    "    'founding_lp_w',\n",
    "    'founding_lp_w_red',\n",
    "    'founding_vp',\n",
    "    'founding_vp_w',\n",
    "    'founding_vp_w_red',\n",
    "    'current_mean_text_len',\n",
    "    'current_n_internal_links_mean',\n",
    "    'current_n_external_links_mean',\n",
    "    'current_n_languages',\n",
    "    'current_pr_sdg_similarity',\n",
    "    'current_pr_w_sdg_similarity',\n",
    "    'current_pr_w_red_sdg_similarity',\n",
    "    'current_doc2vec_diff',\n",
    "    'current_lp',\n",
    "    'current_lp_w',\n",
    "    'current_lp_w_red',\n",
    "    'current_vp',\n",
    "    'current_vp_w',\n",
    "    'current_vp_w_red',\n",
    "    'days_of_prior_observations',\n",
    "    'prediction_1_score',\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RandomForest Features\n",
    "\n",
    "For RF, the features listed below are included.\n",
    "- All included categorical features are encoded using an ordinal encoding.\n",
    "- Binary and categorical are used as is (unscaled)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "RF_BINARY_FEATURES = [\n",
    "    'firm_name_swiss_ref',\n",
    "    'firm_name_holding_ref',\n",
    "    'firm_name_geog_ref',\n",
    "    'firm_name_founder_match',\n",
    "    'firm_name_male_match',\n",
    "    'firm_name_female_match',\n",
    "    'bps_geographic_term',\n",
    "    'bps_male_name',\n",
    "    'bps_female_name',\n",
    "]\n",
    "\n",
    "# < 30 categories\n",
    "RF_LOW_CAT_FEATURES = [\n",
    "    'founding_legal_form',\n",
    "    'section_1_label',\n",
    "    'section_2_label',\n",
    "    'section_3_label',\n",
    "    'canton_id',\n",
    "    'urban_rural',\n",
    "    'typology_9c',\n",
    "    'founding_dominant_language',\n",
    "    'current_dominant_language',\n",
    "]\n",
    "\n",
    "RF_HIGH_CAT_FEATURES = [\n",
    "    'division_1_label',\n",
    "    'group_1_label',\n",
    "    'class_1_label',\n",
    "    'division_2_label',\n",
    "    'group_2_label',\n",
    "    'class_2_label',\n",
    "    'division_3_label',\n",
    "    'group_3_label',\n",
    "    'class_3_label',\n",
    "    'founding_bfs_code',\n",
    "    'district_id',\n",
    "]\n",
    "\n",
    "RF_CONTINUOUS_FEATURES = [\n",
    "    'capital_chf',\n",
    "    'firm_name_length',\n",
    "    'latitude',\n",
    "    'longitude',\n",
    "    'population',\n",
    "    'n_firms_within_10m',\n",
    "    'n_firms_within_1km',\n",
    "    'n_firms_within_2.5km',\n",
    "    'n_firms_within_10km',\n",
    "    'n_founders',\n",
    "    'n_inscribed_firms',\n",
    "    'n_distinct_nationalities',\n",
    "    'pct_female_founders',\n",
    "    'pct_foreign_founders',\n",
    "    'pct_dr_titles',\n",
    "    'pct_founders_same_residence',\n",
    "    'pct_founders_with_prior_founding',\n",
    "    'n_dissolved_firms',\n",
    "    'n_existing_firms',\n",
    "    'bps_length',\n",
    "    'bps_mean_word_length',\n",
    "    'bps_lix',\n",
    "    'bps_min_word_freq_norm',\n",
    "    'bps_max_word_freq_norm',\n",
    "    'bps_freq_ratio_norm',\n",
    "    'founding_mean_text_len',\n",
    "    'founding_n_internal_links_mean',\n",
    "    'founding_n_external_links_mean',\n",
    "    'founding_n_languages',\n",
    "    'founding_pr_sdg_similarity',\n",
    "    'founding_pr_w_sdg_similarity',\n",
    "    'founding_pr_w_red_sdg_similarity',\n",
    "    'founding_doc2vec_diff',\n",
    "    'founding_lp',\n",
    "    'founding_lp_w',\n",
    "    'founding_lp_w_red',\n",
    "    'founding_vp',\n",
    "    'founding_vp_w',\n",
    "    'founding_vp_w_red',\n",
    "    'current_mean_text_len',\n",
    "    'current_n_internal_links_mean',\n",
    "    'current_n_external_links_mean',\n",
    "    'current_n_languages',\n",
    "    'current_pr_sdg_similarity',\n",
    "    'current_pr_w_sdg_similarity',\n",
    "    'current_pr_w_red_sdg_similarity',\n",
    "    'current_doc2vec_diff',\n",
    "    'current_lp',\n",
    "    'current_lp_w',\n",
    "    'current_lp_w_red',\n",
    "    'current_vp',\n",
    "    'current_vp_w',\n",
    "    'current_vp_w_red',\n",
    "    'days_of_prior_observations',\n",
    "    'prediction_1_score',\n",
    "    'prediction_2_score',\n",
    "    'prediction_3_score',\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost Features\n",
    "\n",
    "For XGBoost, the features listed below are included.\n",
    "- Low-cardinality categorical features are one-hot encoded.\n",
    "- High-cardinality categorical features are encoded using ordinal encoding.\n",
    "- Binary and continuous features are included as is (unscaled)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "XGB_BINARY_FEATURES = [\n",
    "    'firm_name_swiss_ref',\n",
    "    'firm_name_holding_ref',\n",
    "    'firm_name_geog_ref',\n",
    "    'firm_name_founder_match',\n",
    "    'firm_name_male_match',\n",
    "    'firm_name_female_match',\n",
    "    'bps_geographic_term',\n",
    "    'bps_male_name',\n",
    "    'bps_female_name',\n",
    "]\n",
    "\n",
    "XGB_LOW_CAT_FEATURES = [\n",
    "    'founding_legal_form',\n",
    "    'section_1_label',  # Top 3 NOGA Levels\n",
    "    'section_2_label',\n",
    "    'section_3_label',\n",
    "    'urban_rural',  # Cat\n",
    "    'typology_9c',  # Cat\n",
    "    'founding_dominant_language',\n",
    "    'current_dominant_language',\n",
    "]\n",
    "\n",
    "XGB_HIGH_CAT_FEATURES = [\n",
    "    'division_1_label',\n",
    "    'group_1_label',\n",
    "    'class_1_label',\n",
    "\n",
    "    'division_2_label',\n",
    "    'group_2_label',\n",
    "    'class_2_label',\n",
    "\n",
    "    'division_3_label',\n",
    "    'group_3_label',\n",
    "    'class_3_label',\n",
    "\n",
    "    'founding_bfs_code',\n",
    "    'district_id',\n",
    "    'canton_id',\n",
    "\n",
    "    'typology_25c',  # Cat\n",
    "]\n",
    "\n",
    "XGB_CONTINUOUS_FEATURES = [  \n",
    "    'capital_chf',\n",
    "    'firm_name_length',\n",
    "    'latitude',\n",
    "    'longitude',\n",
    "    'population',\n",
    "    'n_firms_within_10m',\n",
    "    'n_firms_within_1km',\n",
    "    'n_firms_within_2.5km',\n",
    "    'n_firms_within_10km',\n",
    "    'n_founders',\n",
    "    'n_inscribed_firms',\n",
    "    'n_distinct_nationalities',\n",
    "    'pct_female_founders',\n",
    "    'pct_foreign_founders',\n",
    "    'pct_dr_titles',\n",
    "    'pct_founders_same_residence',\n",
    "    'pct_founders_with_prior_founding',\n",
    "    'n_dissolved_firms',\n",
    "    'n_existing_firms',\n",
    "    'bps_length',\n",
    "    'bps_mean_word_length',\n",
    "    'bps_lix',\n",
    "    'bps_min_word_freq_norm',\n",
    "    'bps_max_word_freq_norm',\n",
    "    'bps_freq_ratio_norm',\n",
    "    'founding_mean_text_len',\n",
    "    'founding_n_internal_links_mean',\n",
    "    'founding_n_external_links_mean',\n",
    "    'founding_n_languages',\n",
    "    'founding_pr_sdg_similarity',\n",
    "    'founding_pr_w_sdg_similarity',\n",
    "    'founding_pr_w_red_sdg_similarity',\n",
    "    'founding_doc2vec_diff',\n",
    "    'founding_lp',\n",
    "    'founding_lp_w',\n",
    "    'founding_lp_w_red',\n",
    "    'founding_vp',\n",
    "    'founding_vp_w',\n",
    "    'founding_vp_w_red',\n",
    "    'current_mean_text_len',\n",
    "    'current_n_internal_links_mean',\n",
    "    'current_n_external_links_mean',\n",
    "    'current_n_languages',\n",
    "    'current_pr_sdg_similarity',\n",
    "    'current_pr_w_sdg_similarity',\n",
    "    'current_pr_w_red_sdg_similarity',\n",
    "    'current_doc2vec_diff',\n",
    "    'current_lp',\n",
    "    'current_lp_w',\n",
    "    'current_lp_w_red',\n",
    "    'current_vp',\n",
    "    'current_vp_w',\n",
    "    'current_vp_w_red',\n",
    "    'days_of_prior_observations',\n",
    "    'prediction_1_score',\n",
    "    'prediction_2_score',\n",
    "    'prediction_3_score',\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL TRAINING AND EVALUATION CLASS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelEvaluation:\n",
    "\n",
    "    def __init__(self, target_vars: list[str], model_specs: dict, random_state: int = 42):\n",
    "        \"\"\"\n",
    "        target_vars: list of target column names\n",
    "        model_specs: dict with keys as model names, values as dicts with:\n",
    "                     - 'model': a scikit-learn estimator class or a callable returning an instance\n",
    "                     - 'param_grid': dict of hyperparameter grid for grid search\n",
    "        Example:\n",
    "        model_specs = {\n",
    "            'logreg': {'model': LogisticRegression, 'param_grid': {...}},\n",
    "            'rf': {'model': RandomForestClassifier, 'param_grid': {...}}\n",
    "        }\n",
    "        \"\"\"\n",
    "        self.target_vars = target_vars\n",
    "        self.model_specs = model_specs\n",
    "        self.random_state = random_state\n",
    "        self.best_params = {m: {t: None for t in target_vars} for m in model_specs}\n",
    "        self.selected_features = {m: {t: None for t in target_vars} for m in model_specs}\n",
    "        self.best_models = {m: {t: None for t in target_vars} for m in model_specs}\n",
    "        self.production_models = {m: {t: None for t in target_vars} for m in model_specs}\n",
    "        self.metrics_report = {m: {t: None for t in target_vars} for m in model_specs}\n",
    "        \n",
    "        for model_name, spec in self.model_specs.items():\n",
    "            self._assert_feature_lists_mutually_exclusive(spec['features'])\n",
    "\n",
    "    def _assert_feature_lists_mutually_exclusive(self, features_dict):\n",
    "        all_features = []\n",
    "        for name, feature_list in features_dict.items():\n",
    "            all_features.extend(feature_list)\n",
    "        if len(all_features) != len(set(all_features)):\n",
    "            duplicates = [item for item, count in Counter(all_features).items() if count > 1]\n",
    "            raise ValueError(f\"Duplicate features detected: {duplicates}\")\n",
    "\n",
    "    def _assert_all_features_present(self, features_dict):\n",
    "        all_features = []\n",
    "        for name, feature_list in features_dict.items():\n",
    "            all_features.extend(feature_list)\n",
    "        missing_features = [feature for feature in all_features if feature not in self.feature_cols]\n",
    "        if missing_features:\n",
    "            raise ValueError(f\"Missing features detected: {missing_features}\")\n",
    "        \n",
    "    def load_data(self, df: pd.DataFrame):\n",
    "        self.df = df.copy()\n",
    "        self.feature_cols = [col for col in df.columns if col not in self.target_vars]\n",
    "        for model_name, spec in self.model_specs.items():\n",
    "            self._assert_all_features_present(spec['features'])\n",
    "\n",
    "    def load_best_params(self, file_path: Path, model_names: list[str], target_vars: list[str]):\n",
    "        with open(file_path, 'rb') as f:\n",
    "            all_params = pickle.load(f)\n",
    "        self.best_params = {\n",
    "            m: {t: all_params[m][t] for t in target_vars}\n",
    "            for m in model_names\n",
    "        }\n",
    "\n",
    "    def load_best_features(self, file_path: Path, model_names: list[str], target_vars: list[str], additional_features: list = []):\n",
    "        with open(file_path, 'rb') as f:\n",
    "            all_features = pickle.load(f)\n",
    "        self.selected_features = {\n",
    "            m: {t: all_features[m][t] + additional_features for t in target_vars}\n",
    "            for m in model_names\n",
    "        }\n",
    "\n",
    "    def _get_feature_importances(self, model):\n",
    "        \"\"\"Return feature importances as a pandas Series, sorted descending.\"\"\"\n",
    "        # Tree-based models\n",
    "        if hasattr(model, \"feature_importances_\"):\n",
    "            return model.feature_importances_\n",
    "        # Linear models (coefficients)\n",
    "        elif hasattr(model, \"coef_\"):\n",
    "            return np.abs(model.coef_).flatten()\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    def _add_class_weights_to_fit_params(self, fit_params, ModelClass, model_name, y):\n",
    "        \n",
    "        if not self.model_specs[model_name]['account_for_class_weights']:\n",
    "            return fit_params\n",
    "\n",
    "        if model_name == 'xgb':\n",
    "            classes = np.unique(y)\n",
    "            n_pos = np.sum(y == classes[1])\n",
    "            n_neg = np.sum(y == classes[0])\n",
    "            fit_params['scale_pos_weight'] = n_neg / n_pos if n_pos > 0 else 1.0\n",
    "\n",
    "        elif hasattr(ModelClass(), 'class_weight'):\n",
    "            fit_params['class_weight'] = 'balanced'\n",
    "\n",
    "        return fit_params\n",
    "\n",
    "    def _build_preprocessor(self, preprocessor_steps: list[tuple], model_name: str, target: str, best_features: bool = False):\n",
    "        steps = []\n",
    "        for name, transformer in preprocessor_steps:\n",
    "            features = self.model_specs[model_name]['features'][name]\n",
    "            if best_features:\n",
    "                features = [col for col in features if col in self.selected_features[model_name][target]]\n",
    "            steps.append((name, transformer, features))\n",
    "        return ColumnTransformer(steps)\n",
    "\n",
    "    def nested_cv_with_feature_selection(\n",
    "        self,\n",
    "        k_outer: int = 5,\n",
    "        k_inner: int = 3,\n",
    "        min_features_to_select: int = 10,\n",
    "        scoring: str = \"average_precision\"\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Perform feature selection (RFECV) using cross-validation without hyperparameter tuning.\n",
    "\n",
    "        Saves the most frequently selected features across outer folds.\n",
    "        \"\"\"\n",
    "        print(\"Starting nested CV with feature selection...\")\n",
    "\n",
    "        for model_name, spec in tqdm(self.model_specs.items(), desc=\"Models\"):\n",
    "\n",
    "            ModelClass = spec['model']\n",
    "\n",
    "            for target in tqdm(self.target_vars, desc=f\"{model_name} targets\", leave=False):\n",
    "                print(f\"Model: {model_name} | Target: {target}\")\n",
    "\n",
    "                preprocessor = self._build_preprocessor(spec['preprocessor_steps'], model_name, target)\n",
    "\n",
    "                X = self.df[self.feature_cols]\n",
    "                y = self.df[target]\n",
    "\n",
    "                outer_skf = StratifiedKFold(n_splits=k_outer, shuffle=True, random_state=self.random_state)\n",
    "\n",
    "                selected_feature_masks = []\n",
    "\n",
    "                for train_idx, _ in tqdm(list(outer_skf.split(X, y)), desc=\"Outer folds\", leave=False):\n",
    "                    X_train, y_train = X.iloc[train_idx], y.iloc[train_idx]\n",
    "\n",
    "                    X_train_proc = preprocessor.fit_transform(X_train)\n",
    "\n",
    "                    fit_params = self._add_class_weights_to_fit_params(spec['fit_params'], ModelClass, model_name, y_train)\n",
    "                    model = ModelClass(**fit_params)\n",
    "                    \n",
    "                    inner_skf = StratifiedKFold(n_splits=k_inner, shuffle=True, random_state=self.random_state)\n",
    "                    rfecv = RFECV(\n",
    "                        estimator=model,\n",
    "                        step=1,\n",
    "                        min_features_to_select=min_features_to_select,\n",
    "                        cv=inner_skf,\n",
    "                        scoring=scoring,\n",
    "                        n_jobs=-1\n",
    "                    )\n",
    "\n",
    "                    rfecv.fit(X_train_proc, y_train)\n",
    "                    selected_feature_masks.append(rfecv.support_)\n",
    "\n",
    "                # Aggregate selected features across folds\n",
    "                selected_feature_masks = np.array(selected_feature_masks)\n",
    "                mean_mask = selected_feature_masks.mean(axis=0)\n",
    "                threshold = 0.6  # at least 60% of folds must have selected a feature\n",
    "                final_mask = mean_mask >= threshold\n",
    "                final_features = np.array(self.feature_cols)[final_mask].tolist()\n",
    "\n",
    "                self.selected_features[model_name][target] = final_features\n",
    "                print(f\"[{model_name}/{target}] Selected {len(final_features)} features: {final_features}\")\n",
    "\n",
    "    def nested_cv_with_hyperparam_search(\n",
    "        self,\n",
    "        out_folder: Path,\n",
    "        k_outer: int = 5,\n",
    "        k_inner: int = 3,\n",
    "        best_features: bool = False,\n",
    "        n_trials: int = 200,\n",
    "        scoring: str = 'average_precision'\n",
    "    ) -> None:\n",
    "        \n",
    "        if best_features and not self.selected_features:\n",
    "            raise ValueError('To use the best features execure find_best_feature_subset first!')\n",
    "\n",
    "        print(\"Starting nested CV with hyperparameter search...\")\n",
    "\n",
    "        for model_name, spec in tqdm(self.model_specs.items(), desc=\"Models\"):\n",
    "\n",
    "            ModelClass = spec['model']\n",
    "            param_grid = spec['param_grid']\n",
    "\n",
    "            for target in tqdm(self.target_vars, desc=f\"{model_name} targets\", leave=False):\n",
    "                print(f\"[STARTED] Model: {model_name} | Target: {target}\")\n",
    "\n",
    "                # Initialize preprocessor with the specified feature columns from the model specs\n",
    "                preprocessor = self._build_preprocessor(\n",
    "                    spec['preprocessor_steps'], model_name, target, best_features\n",
    "                )\n",
    "\n",
    "                X = self.df[self.feature_cols]  # Always select all features, dropping of unspecified features is handled by the preprocessor\n",
    "                y = self.df[target]\n",
    "\n",
    "                outer_skf = StratifiedKFold(n_splits=k_outer, shuffle=True, random_state=self.random_state)\n",
    "                \n",
    "                outer_metrics = {'roc_auc': [], 'pr_auc': [], 'f1_macro': []}\n",
    "                inner_best_scores = []\n",
    "                inner_best_params = []\n",
    "                \n",
    "                # Outer loop over k_outer folds\n",
    "                for train_idx, test_idx in tqdm(list(outer_skf.split(X, y)), desc=\"Outer folds\", leave=False):\n",
    "                    \n",
    "                    # Init data of the current outer fold\n",
    "                    X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "                    y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "                    \n",
    "                    X_train_proc = preprocessor.fit_transform(X_train)\n",
    "                    X_test_proc = preprocessor.transform(X_test)\n",
    "\n",
    "                    # Only include relevant fit_params for this model\n",
    "                    fit_params = self._add_class_weights_to_fit_params(spec['fit_params'], ModelClass, model_name, y_train)\n",
    "                    model = ModelClass(**fit_params)\n",
    "\n",
    "                    # Set up inner grid search loop for k_inner folds\n",
    "                    inner_skf = StratifiedKFold(n_splits=k_inner, shuffle=True, random_state=self.random_state)\n",
    "                    if spec['search_type'] == 'grid':\n",
    "                        searcher = GridSearchCV(\n",
    "                            estimator=model,\n",
    "                            param_grid=param_grid,\n",
    "                            cv=inner_skf,\n",
    "                            scoring=scoring,  # Because highly imbalanced data\n",
    "                            n_jobs=-1\n",
    "                        )\n",
    "                    elif spec['search_type'] == 'optuna':\n",
    "                        searcher = OptunaSearchCV(\n",
    "                            estimator=model,\n",
    "                            param_distributions=param_grid,\n",
    "                            cv=inner_skf,\n",
    "                            scoring=scoring,\n",
    "                            n_trials=n_trials,\n",
    "                            n_jobs=-1,\n",
    "                            random_state=self.random_state,\n",
    "                            verbose=0,\n",
    "                        )\n",
    "                    elif spec['search_type'] is None:\n",
    "                        pass\n",
    "                    else:\n",
    "                        raise ValueError(\"search_type must be 'grid' or 'optuna'\")\n",
    "\n",
    "                    if spec['search_type'] is None:\n",
    "                        best_params = {}\n",
    "                    else:\n",
    "                        # Determine best hyperparameters of this fold using only the training data and not testing\n",
    "                        # training data is then again split into k_inner folds\n",
    "                        searcher.fit(X_train_proc, y_train)\n",
    "\n",
    "                        best_params = searcher.best_params_\n",
    "                        # Select and store best hyperparam config determined on the training data\n",
    "                        inner_best_scores.append(searcher.best_score_)\n",
    "                        inner_best_params.append(best_params)\n",
    "                    \n",
    "                    # Refit model with full training data to estimate auc and feature importance of the outer fold\n",
    "                    temp_fit_params = {**fit_params, 'n_jobs': -1}  # For training without CV set to -1\n",
    "                    params = dict(best_params, **temp_fit_params)\n",
    "                    best_model = ModelClass(**params)\n",
    "                    best_model.fit(X_train_proc, y_train)\n",
    "                    y_pred = best_model.predict(X_test_proc)\n",
    "                    y_pred_proba = best_model.predict_proba(X_test_proc)[:, 1]\n",
    "                    \n",
    "                    outer_metrics['roc_auc'].append(roc_auc_score(y_test, y_pred_proba))\n",
    "                    outer_metrics['pr_auc'].append(average_precision_score(y_test, y_pred_proba))\n",
    "                    outer_metrics['f1_macro'].append(f1_score(y_test, y_pred, average=\"macro\"))\n",
    "\n",
    "                if spec['search_type'] is None:\n",
    "                    overall_lambda_star = {}  # No tuned hyperparams\n",
    "                else:\n",
    "                    # Select hyperparameters from the inner folds that achieved the highest score\n",
    "                    best_idx = np.argmax(inner_best_scores)\n",
    "                    overall_lambda_star = inner_best_params[best_idx]\n",
    "\n",
    "                # Set class weights again based on the full data\n",
    "                fit_params = self._add_class_weights_to_fit_params(spec['fit_params'], ModelClass, model_name, y)\n",
    "\n",
    "                # Retrain final model on all data\n",
    "                temp_fit_params = {**fit_params, 'n_jobs': -1}  # For training without CV set to -1\n",
    "                best_params = dict(overall_lambda_star, **temp_fit_params)\n",
    "                production_model = ModelClass(**best_params)\n",
    "                \n",
    "                X_proc = preprocessor.fit_transform(X)\n",
    "                production_model.fit(X_proc, y)\n",
    "\n",
    "                # Store production model\n",
    "                self.best_models[model_name][target] = production_model\n",
    "\n",
    "                # Store best hyperparameters\n",
    "                self.best_params[model_name][target] = overall_lambda_star\n",
    "\n",
    "                # Store metrics report for the avg performance of the model on the current target\n",
    "                self.metrics_report[model_name][target] = {\n",
    "                    'mean_roc_auc': np.mean(outer_metrics['roc_auc']),\n",
    "                    'std_roc_auc': np.std(outer_metrics['roc_auc']),\n",
    "                    'all_roc_auc': outer_metrics['roc_auc'],\n",
    "                    'mean_pr_auc': np.mean(outer_metrics['pr_auc']),\n",
    "                    'std_pr_auc': np.std(outer_metrics['pr_auc']),\n",
    "                    'all_pr_auc': outer_metrics['pr_auc'],\n",
    "                    'mean_f1_macro': np.mean(outer_metrics['f1_macro']),\n",
    "                    'std_f1_macro': np.std(outer_metrics['f1_macro']),\n",
    "                    'all_f1_macro': outer_metrics['f1_macro'],\n",
    "                    'best_params': overall_lambda_star,\n",
    "                }\n",
    "                print(f\"[FINISHED] Model: {model_name} | Target: {target} | Mean ROC-AUC: {np.mean(outer_metrics['roc_auc']):.4f} | Mean PR-AUC: {np.mean(outer_metrics['pr_auc']):.4f}\")\n",
    "\n",
    "        self._save_models_and_reports(out_folder)\n",
    "\n",
    "    def _save_models_and_reports(self, out_folder: Path):\n",
    "        \"\"\"Retrains model on the full dataset and stores production ready model with additional performance reports\n",
    "        from the k-fold CV evaluations.\"\"\"\n",
    "\n",
    "        out_folder.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        # Save best models stored in self.best_models[model_name][target]\n",
    "        models_dir = out_folder / 'trained_models'\n",
    "        models_dir.mkdir(exist_ok=True)\n",
    "        for model_name, targets in self.best_models.items():\n",
    "            for target, model in targets.items():\n",
    "                model_path = models_dir / f'{model_name}_{target}.joblib'\n",
    "                joblib.dump(model, model_path)\n",
    "                print(f\"Saved model for {model_name}/{target} to {model_path}\")\n",
    "\n",
    "        # Save metrics report as csv file\n",
    "        summary_rows = []\n",
    "        for model_name, model_results in self.metrics_report.items():\n",
    "            for target, d in model_results.items():\n",
    "                summary_rows.append({\n",
    "                    'model': model_name,\n",
    "                    'target': target,\n",
    "                    'mean_roc_auc': d['mean_roc_auc'],\n",
    "                    'std_roc_auc': d['std_roc_auc'],\n",
    "                    'all_roc_auc': str(d['all_roc_auc']),\n",
    "                    'mean_pr_auc': d['mean_pr_auc'],\n",
    "                    'std_pr_auc': d['std_pr_auc'],\n",
    "                    'all_pr_auc': str(d['all_pr_auc']),\n",
    "                    'mean_f1_macro': d['mean_f1_macro'],\n",
    "                    'std_f1_macro': d['std_f1_macro'],\n",
    "                    'all_f1_macro': str(d['all_f1_macro']),\n",
    "                    'best_params': str(d['best_params']),\n",
    "                })\n",
    "        pd.DataFrame(summary_rows).to_csv(out_folder / 'cv_metrics_report.csv', index=False)\n",
    "        print(f\"Saved metrics summary to {str(out_folder / 'cv_metrics_report.csv')}\")\n",
    "\n",
    "        # Save hyperparameters\n",
    "        best_params_path = out_folder / 'best_hyperparameters.pkl'\n",
    "        with open(best_params_path, 'wb') as f:\n",
    "            pickle.dump(self.best_params, f)\n",
    "        print(f\"Saved best hyperparameters to {best_params_path}\")\n",
    "\n",
    "        # Save best feature set\n",
    "        best_features_path = out_folder / 'best_features.pkl'\n",
    "        with open(best_features_path, 'wb') as f:\n",
    "            pickle.dump(self.selected_features, f)\n",
    "        print(f\"Saved best features to {best_features_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global params\n",
    "RANDOM_STATE = 42\n",
    "WEBSITE_FEATURE_COLS = FOUNDING_WEBSITE_FEATURE_COLS + CURRENT_WEBSITE_FEATURE_COLS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment A: Reproducability experiment and model evaluation on the full data set without website data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Config for replication study using only baseline features\n",
    "MODEL_SPECS = {\n",
    "    'vanilla_logreg': {\n",
    "        'model': LogisticRegression,\n",
    "        'preprocessor_steps': [\n",
    "            ('categorical_low_card', OneHotEncoder(drop='first', sparse_output=False, handle_unknown='ignore')),\n",
    "            ('continuous', StandardScaler()),\n",
    "            ('binary', 'passthrough'),\n",
    "        ],\n",
    "        'features': {\n",
    "            'binary': [f for f in LOGREG_BINARY_FEATURES if f not in WEBSITE_FEATURE_COLS],\n",
    "            'categorical_low_card': [f for f in LOGREG_LOW_CAT_FEATURES if f not in WEBSITE_FEATURE_COLS],\n",
    "            'categorical_high_card': [f for f in LOGREG_HIGH_CAT_FEATURES if f not in WEBSITE_FEATURE_COLS],  # empty\n",
    "            'continuous': [f for f in LOGREG_CONTINUOUS_FEATURES if f not in WEBSITE_FEATURE_COLS],\n",
    "        },\n",
    "        'fit_params': {\n",
    "            'random_state': RANDOM_STATE,\n",
    "            'n_jobs': 1,  # Avoid thread thrashing, so model n_jobs should be set to 1 because Grid Search CV and Feature Selection is set to -1\n",
    "            'max_iter': 10_000,\n",
    "            'solver': 'saga',  # Fixed for computational efficiency\n",
    "        },\n",
    "        'param_grid': {},  # No hyperparams for vanilla LogReg\n",
    "        'search_type': None,\n",
    "        'account_for_class_weights': True\n",
    "    },\n",
    "    'logreg': {\n",
    "        'model': LogisticRegression,\n",
    "        'preprocessor_steps': [\n",
    "            ('categorical_low_card', OneHotEncoder(drop='first', sparse_output=False, handle_unknown='ignore')),\n",
    "            ('continuous', StandardScaler()),\n",
    "            ('binary', 'passthrough'),\n",
    "        ],\n",
    "        'features': {\n",
    "            'binary': [f for f in LOGREG_BINARY_FEATURES if f not in WEBSITE_FEATURE_COLS],\n",
    "            'categorical_low_card': [f for f in LOGREG_LOW_CAT_FEATURES if f not in WEBSITE_FEATURE_COLS],\n",
    "            'categorical_high_card': [f for f in LOGREG_HIGH_CAT_FEATURES if f not in WEBSITE_FEATURE_COLS],  # empty\n",
    "            'continuous': [f for f in LOGREG_CONTINUOUS_FEATURES if f not in WEBSITE_FEATURE_COLS],\n",
    "        },\n",
    "        'fit_params': {\n",
    "            'random_state': RANDOM_STATE,\n",
    "            'n_jobs': 1,  # Avoid thread thrashing, so model n_jobs should be set to 1 because Grid Search CV and Feature Selection is set to -1\n",
    "            'max_iter': 10_000,\n",
    "            'solver': 'saga',  # Fixed for computational efficiency\n",
    "        },\n",
    "        'param_grid': {\n",
    "            'penalty': ['l1', 'l2'],  # Test Lasso and Ridge regularization\n",
    "            'C': [0.01, 0.1, 1, 10, 100],\n",
    "        },\n",
    "        'search_type': 'grid',\n",
    "        'account_for_class_weights': True\n",
    "    },\n",
    "    'rf': {\n",
    "        'model': RandomForestClassifier,\n",
    "        'preprocessor_steps': [\n",
    "            ('categorical_low_card', OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)),\n",
    "            ('categorical_high_card', OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)),\n",
    "            ('continuous', 'passthrough'),\n",
    "            ('binary', 'passthrough'),\n",
    "        ],\n",
    "        'features': {\n",
    "            'binary': [f for f in RF_BINARY_FEATURES if f not in WEBSITE_FEATURE_COLS],\n",
    "            'categorical_low_card': [f for f in RF_LOW_CAT_FEATURES if f not in WEBSITE_FEATURE_COLS],\n",
    "            'categorical_high_card': [f for f in RF_HIGH_CAT_FEATURES if f not in WEBSITE_FEATURE_COLS],\n",
    "            'continuous': [f for f in RF_CONTINUOUS_FEATURES if f not in WEBSITE_FEATURE_COLS],\n",
    "        },\n",
    "        'fit_params': {\n",
    "            'random_state': RANDOM_STATE,\n",
    "            'n_jobs': 1,\n",
    "        },\n",
    "        'param_grid': {\n",
    "            'n_estimators': IntDistribution(100, 400, step=50),\n",
    "            'max_depth':  CategoricalDistribution([None, 10, 20, 30]),\n",
    "            'min_samples_split': IntDistribution(2, 20),\n",
    "            'min_samples_leaf': IntDistribution(1, 10),\n",
    "            'max_features': CategoricalDistribution(['sqrt', 'log2', 0.5]),\n",
    "        },\n",
    "        'search_type': 'optuna',\n",
    "        'account_for_class_weights': True\n",
    "    },\n",
    "    'xgb': {\n",
    "        'model': XGBClassifier,\n",
    "        'preprocessor_steps': [\n",
    "            ('categorical_low_card', OneHotEncoder(drop='first', sparse_output=False, handle_unknown='ignore')),\n",
    "            ('categorical_high_card', OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)),\n",
    "            ('continuous', 'passthrough'),\n",
    "            ('binary', 'passthrough'),\n",
    "        ],\n",
    "        'features': {\n",
    "            'binary': [f for f in XGB_BINARY_FEATURES if f not in WEBSITE_FEATURE_COLS],\n",
    "            'categorical_low_card': [f for f in XGB_LOW_CAT_FEATURES if f not in WEBSITE_FEATURE_COLS],\n",
    "            'categorical_high_card': [f for f in XGB_HIGH_CAT_FEATURES if f not in WEBSITE_FEATURE_COLS],\n",
    "            'continuous': [f for f in XGB_CONTINUOUS_FEATURES if f not in WEBSITE_FEATURE_COLS],\n",
    "        },\n",
    "        'fit_params': {\n",
    "            'random_state': RANDOM_STATE,\n",
    "            'n_jobs': 1,\n",
    "            'objective': 'binary:logistic',\n",
    "            'verbosity': 0,\n",
    "            'booster': 'gbtree',\n",
    "            'tree_method': 'hist',\n",
    "            'use_label_encoder': False,\n",
    "            'eval_metric': 'aucpr',\n",
    "        },\n",
    "        'param_grid': {\n",
    "            'max_depth': IntDistribution(3, 10),\n",
    "            'min_child_weight': IntDistribution(1, 10),\n",
    "            'gamma': FloatDistribution(0, 5.0),\n",
    "            'subsample': FloatDistribution(0.5, 1.0),\n",
    "            'colsample_bytree': FloatDistribution(0.5, 1.0),\n",
    "            'learning_rate': FloatDistribution(0.005, 0.1, log=True),\n",
    "            'n_estimators': IntDistribution(100, 400, step=50),\n",
    "            'reg_alpha': FloatDistribution(0, 5.0),  # L1 regularization\n",
    "            'reg_lambda': FloatDistribution(1.0, 10.0),  # L2 regularization\n",
    "            'max_delta_step': IntDistribution(0, 10),\n",
    "        },\n",
    "        'search_type': 'optuna',\n",
    "        'account_for_class_weights': True\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting nested CV with hyperparameter search...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ad3fa6475734136841f1a14b7ef8c6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Models:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "393dfe89901749f29709ad6ddfce53fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vanilla_logreg targets:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[STARTED] Model: vanilla_logreg | Target: target_inv_exit\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1cd7c60447aa4597835fb46e540bf7fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Outer folds:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FINISHED] Model: vanilla_logreg | Target: target_inv_exit | Mean ROC-AUC: 0.6897 | Mean PR-AUC: 0.2643\n",
      "[STARTED] Model: vanilla_logreg | Target: target_acquisition\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dcbc7fd1b9b74d46b93ac9865437662b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Outer folds:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FINISHED] Model: vanilla_logreg | Target: target_acquisition | Mean ROC-AUC: 0.7769 | Mean PR-AUC: 0.0328\n",
      "[STARTED] Model: vanilla_logreg | Target: target_non_gov_investment\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff18b05bfe4a40cd80cbe62bec55414b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Outer folds:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FINISHED] Model: vanilla_logreg | Target: target_non_gov_investment | Mean ROC-AUC: 0.9084 | Mean PR-AUC: 0.0766\n",
      "[STARTED] Model: vanilla_logreg | Target: target_inno_subsidy\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb0bb33c757a4eabb3681308cacdc191",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Outer folds:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FINISHED] Model: vanilla_logreg | Target: target_inno_subsidy | Mean ROC-AUC: 0.8603 | Mean PR-AUC: 0.0600\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a616ef789ca14fac830bcabd573e98fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "logreg targets:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[STARTED] Model: logreg | Target: target_inv_exit\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "040b8d168c994a0a834857d0021b07f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Outer folds:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FINISHED] Model: logreg | Target: target_inv_exit | Mean ROC-AUC: 0.6883 | Mean PR-AUC: 0.2648\n",
      "[STARTED] Model: logreg | Target: target_acquisition\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bff0e7a1a9f24941b121bf11794b4f64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Outer folds:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/manuelbolz/Documents/git/for_work/company_success_prediction/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/manuelbolz/Documents/git/for_work/company_success_prediction/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/manuelbolz/Documents/git/for_work/company_success_prediction/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/manuelbolz/Documents/git/for_work/company_success_prediction/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/manuelbolz/Documents/git/for_work/company_success_prediction/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/manuelbolz/Documents/git/for_work/company_success_prediction/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/manuelbolz/Documents/git/for_work/company_success_prediction/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/manuelbolz/Documents/git/for_work/company_success_prediction/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/manuelbolz/Documents/git/for_work/company_success_prediction/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/manuelbolz/Documents/git/for_work/company_success_prediction/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/manuelbolz/Documents/git/for_work/company_success_prediction/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/manuelbolz/Documents/git/for_work/company_success_prediction/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/manuelbolz/Documents/git/for_work/company_success_prediction/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/manuelbolz/Documents/git/for_work/company_success_prediction/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/manuelbolz/Documents/git/for_work/company_success_prediction/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/manuelbolz/Documents/git/for_work/company_success_prediction/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/manuelbolz/Documents/git/for_work/company_success_prediction/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/manuelbolz/Documents/git/for_work/company_success_prediction/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/manuelbolz/Documents/git/for_work/company_success_prediction/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/manuelbolz/Documents/git/for_work/company_success_prediction/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/manuelbolz/Documents/git/for_work/company_success_prediction/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/manuelbolz/Documents/git/for_work/company_success_prediction/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/manuelbolz/Documents/git/for_work/company_success_prediction/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/manuelbolz/Documents/git/for_work/company_success_prediction/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/manuelbolz/Documents/git/for_work/company_success_prediction/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/manuelbolz/Documents/git/for_work/company_success_prediction/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/manuelbolz/Documents/git/for_work/company_success_prediction/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/manuelbolz/Documents/git/for_work/company_success_prediction/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/manuelbolz/Documents/git/for_work/company_success_prediction/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/manuelbolz/Documents/git/for_work/company_success_prediction/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/manuelbolz/Documents/git/for_work/company_success_prediction/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/manuelbolz/Documents/git/for_work/company_success_prediction/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/manuelbolz/Documents/git/for_work/company_success_prediction/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/manuelbolz/Documents/git/for_work/company_success_prediction/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/manuelbolz/Documents/git/for_work/company_success_prediction/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/manuelbolz/Documents/git/for_work/company_success_prediction/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/manuelbolz/Documents/git/for_work/company_success_prediction/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/manuelbolz/Documents/git/for_work/company_success_prediction/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/manuelbolz/Documents/git/for_work/company_success_prediction/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/manuelbolz/Documents/git/for_work/company_success_prediction/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/manuelbolz/Documents/git/for_work/company_success_prediction/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/manuelbolz/Documents/git/for_work/company_success_prediction/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/manuelbolz/Documents/git/for_work/company_success_prediction/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/manuelbolz/Documents/git/for_work/company_success_prediction/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/manuelbolz/Documents/git/for_work/company_success_prediction/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/manuelbolz/Documents/git/for_work/company_success_prediction/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/manuelbolz/Documents/git/for_work/company_success_prediction/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/manuelbolz/Documents/git/for_work/company_success_prediction/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/manuelbolz/Documents/git/for_work/company_success_prediction/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/manuelbolz/Documents/git/for_work/company_success_prediction/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/manuelbolz/Documents/git/for_work/company_success_prediction/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/manuelbolz/Documents/git/for_work/company_success_prediction/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/manuelbolz/Documents/git/for_work/company_success_prediction/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/manuelbolz/Documents/git/for_work/company_success_prediction/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FINISHED] Model: logreg | Target: target_acquisition | Mean ROC-AUC: 0.7857 | Mean PR-AUC: 0.0325\n",
      "[STARTED] Model: logreg | Target: target_non_gov_investment\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "359bd01c119f439289310e34cf5e6553",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Outer folds:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/manuelbolz/Documents/git/for_work/company_success_prediction/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/manuelbolz/Documents/git/for_work/company_success_prediction/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/manuelbolz/Documents/git/for_work/company_success_prediction/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/manuelbolz/Documents/git/for_work/company_success_prediction/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/manuelbolz/Documents/git/for_work/company_success_prediction/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/manuelbolz/Documents/git/for_work/company_success_prediction/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/manuelbolz/Documents/git/for_work/company_success_prediction/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/manuelbolz/Documents/git/for_work/company_success_prediction/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/manuelbolz/Documents/git/for_work/company_success_prediction/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/manuelbolz/Documents/git/for_work/company_success_prediction/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/manuelbolz/Documents/git/for_work/company_success_prediction/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/manuelbolz/Documents/git/for_work/company_success_prediction/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/manuelbolz/Documents/git/for_work/company_success_prediction/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/manuelbolz/Documents/git/for_work/company_success_prediction/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/manuelbolz/Documents/git/for_work/company_success_prediction/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/manuelbolz/Documents/git/for_work/company_success_prediction/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/manuelbolz/Documents/git/for_work/company_success_prediction/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/manuelbolz/Documents/git/for_work/company_success_prediction/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/manuelbolz/Documents/git/for_work/company_success_prediction/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/manuelbolz/Documents/git/for_work/company_success_prediction/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FINISHED] Model: logreg | Target: target_non_gov_investment | Mean ROC-AUC: 0.9108 | Mean PR-AUC: 0.0788\n",
      "[STARTED] Model: logreg | Target: target_inno_subsidy\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c7a9a0e2c934b38b7f575740969a190",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Outer folds:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/manuelbolz/Documents/git/for_work/company_success_prediction/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/manuelbolz/Documents/git/for_work/company_success_prediction/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/manuelbolz/Documents/git/for_work/company_success_prediction/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/manuelbolz/Documents/git/for_work/company_success_prediction/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/manuelbolz/Documents/git/for_work/company_success_prediction/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/manuelbolz/Documents/git/for_work/company_success_prediction/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/manuelbolz/Documents/git/for_work/company_success_prediction/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/manuelbolz/Documents/git/for_work/company_success_prediction/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/manuelbolz/Documents/git/for_work/company_success_prediction/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/manuelbolz/Documents/git/for_work/company_success_prediction/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/manuelbolz/Documents/git/for_work/company_success_prediction/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/manuelbolz/Documents/git/for_work/company_success_prediction/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/manuelbolz/Documents/git/for_work/company_success_prediction/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/manuelbolz/Documents/git/for_work/company_success_prediction/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/manuelbolz/Documents/git/for_work/company_success_prediction/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/manuelbolz/Documents/git/for_work/company_success_prediction/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/manuelbolz/Documents/git/for_work/company_success_prediction/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/manuelbolz/Documents/git/for_work/company_success_prediction/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/manuelbolz/Documents/git/for_work/company_success_prediction/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/manuelbolz/Documents/git/for_work/company_success_prediction/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/manuelbolz/Documents/git/for_work/company_success_prediction/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/manuelbolz/Documents/git/for_work/company_success_prediction/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/manuelbolz/Documents/git/for_work/company_success_prediction/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/manuelbolz/Documents/git/for_work/company_success_prediction/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/manuelbolz/Documents/git/for_work/company_success_prediction/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/manuelbolz/Documents/git/for_work/company_success_prediction/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/manuelbolz/Documents/git/for_work/company_success_prediction/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/manuelbolz/Documents/git/for_work/company_success_prediction/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/manuelbolz/Documents/git/for_work/company_success_prediction/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/manuelbolz/Documents/git/for_work/company_success_prediction/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/manuelbolz/Documents/git/for_work/company_success_prediction/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/manuelbolz/Documents/git/for_work/company_success_prediction/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/manuelbolz/Documents/git/for_work/company_success_prediction/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/manuelbolz/Documents/git/for_work/company_success_prediction/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/manuelbolz/Documents/git/for_work/company_success_prediction/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/manuelbolz/Documents/git/for_work/company_success_prediction/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/manuelbolz/Documents/git/for_work/company_success_prediction/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/manuelbolz/Documents/git/for_work/company_success_prediction/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FINISHED] Model: logreg | Target: target_inno_subsidy | Mean ROC-AUC: 0.8629 | Mean PR-AUC: 0.0613\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e213ed85ac1c432f81f818494e71acf7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "rf targets:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[STARTED] Model: rf | Target: target_inv_exit\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1245df1b44ec4bb88fac4f1a8ae13a61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Outer folds:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FINISHED] Model: rf | Target: target_inv_exit | Mean ROC-AUC: 0.7060 | Mean PR-AUC: 0.2914\n",
      "[STARTED] Model: rf | Target: target_acquisition\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc8e85bb26f149f7872dae358c3c58eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Outer folds:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FINISHED] Model: rf | Target: target_acquisition | Mean ROC-AUC: 0.7830 | Mean PR-AUC: 0.0724\n",
      "[STARTED] Model: rf | Target: target_non_gov_investment\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75a51859f099438295428ed725d8c14e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Outer folds:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FINISHED] Model: rf | Target: target_non_gov_investment | Mean ROC-AUC: 0.9113 | Mean PR-AUC: 0.1576\n",
      "[STARTED] Model: rf | Target: target_inno_subsidy\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "705e26af0cc04a099fa2221d34369553",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Outer folds:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FINISHED] Model: rf | Target: target_inno_subsidy | Mean ROC-AUC: 0.8719 | Mean PR-AUC: 0.1130\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d7b6a9f22a743abba10a9d0dbba7bae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "xgb targets:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[STARTED] Model: xgb | Target: target_inv_exit\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac8b49ac66e34defa90ff77911dd1301",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Outer folds:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FINISHED] Model: xgb | Target: target_inv_exit | Mean ROC-AUC: 0.7096 | Mean PR-AUC: 0.2932\n",
      "[STARTED] Model: xgb | Target: target_acquisition\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5992426d9a334cdbba5043bb10a98860",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Outer folds:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FINISHED] Model: xgb | Target: target_acquisition | Mean ROC-AUC: 0.7626 | Mean PR-AUC: 0.0751\n",
      "[STARTED] Model: xgb | Target: target_non_gov_investment\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfff72390afa494699459bcc57ef1c1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Outer folds:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FINISHED] Model: xgb | Target: target_non_gov_investment | Mean ROC-AUC: 0.9267 | Mean PR-AUC: 0.1672\n",
      "[STARTED] Model: xgb | Target: target_inno_subsidy\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d781da7b4a4942bb8be0700c5e377ae3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Outer folds:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FINISHED] Model: xgb | Target: target_inno_subsidy | Mean ROC-AUC: 0.8783 | Mean PR-AUC: 0.1201\n",
      "Saved model for vanilla_logreg/target_inv_exit to /Users/manuelbolz/Documents/git/for_work/company_success_prediction/models/experiment_A/trained_models/vanilla_logreg_target_inv_exit.joblib\n",
      "Saved model for vanilla_logreg/target_acquisition to /Users/manuelbolz/Documents/git/for_work/company_success_prediction/models/experiment_A/trained_models/vanilla_logreg_target_acquisition.joblib\n",
      "Saved model for vanilla_logreg/target_non_gov_investment to /Users/manuelbolz/Documents/git/for_work/company_success_prediction/models/experiment_A/trained_models/vanilla_logreg_target_non_gov_investment.joblib\n",
      "Saved model for vanilla_logreg/target_inno_subsidy to /Users/manuelbolz/Documents/git/for_work/company_success_prediction/models/experiment_A/trained_models/vanilla_logreg_target_inno_subsidy.joblib\n",
      "Saved model for logreg/target_inv_exit to /Users/manuelbolz/Documents/git/for_work/company_success_prediction/models/experiment_A/trained_models/logreg_target_inv_exit.joblib\n",
      "Saved model for logreg/target_acquisition to /Users/manuelbolz/Documents/git/for_work/company_success_prediction/models/experiment_A/trained_models/logreg_target_acquisition.joblib\n",
      "Saved model for logreg/target_non_gov_investment to /Users/manuelbolz/Documents/git/for_work/company_success_prediction/models/experiment_A/trained_models/logreg_target_non_gov_investment.joblib\n",
      "Saved model for logreg/target_inno_subsidy to /Users/manuelbolz/Documents/git/for_work/company_success_prediction/models/experiment_A/trained_models/logreg_target_inno_subsidy.joblib\n",
      "Saved model for rf/target_inv_exit to /Users/manuelbolz/Documents/git/for_work/company_success_prediction/models/experiment_A/trained_models/rf_target_inv_exit.joblib\n",
      "Saved model for rf/target_acquisition to /Users/manuelbolz/Documents/git/for_work/company_success_prediction/models/experiment_A/trained_models/rf_target_acquisition.joblib\n",
      "Saved model for rf/target_non_gov_investment to /Users/manuelbolz/Documents/git/for_work/company_success_prediction/models/experiment_A/trained_models/rf_target_non_gov_investment.joblib\n",
      "Saved model for rf/target_inno_subsidy to /Users/manuelbolz/Documents/git/for_work/company_success_prediction/models/experiment_A/trained_models/rf_target_inno_subsidy.joblib\n",
      "Saved model for xgb/target_inv_exit to /Users/manuelbolz/Documents/git/for_work/company_success_prediction/models/experiment_A/trained_models/xgb_target_inv_exit.joblib\n",
      "Saved model for xgb/target_acquisition to /Users/manuelbolz/Documents/git/for_work/company_success_prediction/models/experiment_A/trained_models/xgb_target_acquisition.joblib\n",
      "Saved model for xgb/target_non_gov_investment to /Users/manuelbolz/Documents/git/for_work/company_success_prediction/models/experiment_A/trained_models/xgb_target_non_gov_investment.joblib\n",
      "Saved model for xgb/target_inno_subsidy to /Users/manuelbolz/Documents/git/for_work/company_success_prediction/models/experiment_A/trained_models/xgb_target_inno_subsidy.joblib\n",
      "Saved metrics summary to /Users/manuelbolz/Documents/git/for_work/company_success_prediction/models/experiment_A/cv_metrics_report.csv\n",
      "Saved best hyperparameters to /Users/manuelbolz/Documents/git/for_work/company_success_prediction/models/experiment_A/best_hyperparameters.pkl\n",
      "Saved best features to /Users/manuelbolz/Documents/git/for_work/company_success_prediction/models/experiment_A/best_features.pkl\n"
     ]
    }
   ],
   "source": [
    "# 1. Load data for experiment A\n",
    "base_df = all_feature_df[[col for col in all_feature_df.columns if col not in WEBSITE_FEATURE_COLS]]\n",
    "\n",
    "# 2. Initialize model evaluation with targets and model specs\n",
    "meval = ModelEvaluation(TARGET_COLS, MODEL_SPECS, random_state=RANDOM_STATE)\n",
    "meval.load_data(base_df)\n",
    "\n",
    "# 3. Training procedure on all features for the baseline reproduction\n",
    "out_folder = MODELS_DIR / 'experiment_A'\n",
    "meval.nested_cv_with_hyperparam_search(out_folder=out_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "START CONDUCTING EXPERIMENT B FOR: founding_base\n",
      "Starting nested CV with hyperparameter search...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3cd8962b4544feab927ee76d88bd609",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Models:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58b9161d1ab24c05a79878b1098b2083",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "xgb targets:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[STARTED] Model: xgb | Target: target_inv_exit\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7873e4625d94029b786e370f76e2e91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Outer folds:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FINISHED] Model: xgb | Target: target_inv_exit | Mean ROC-AUC: 0.6690 | Mean PR-AUC: 0.1099\n",
      "[STARTED] Model: xgb | Target: target_acquisition\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "336a3aa450b9488aabb53f28af43d799",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Outer folds:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FINISHED] Model: xgb | Target: target_acquisition | Mean ROC-AUC: 0.8067 | Mean PR-AUC: 0.0727\n",
      "[STARTED] Model: xgb | Target: target_non_gov_investment\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d312000798864cc88d788eb090a11bcd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Outer folds:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FINISHED] Model: xgb | Target: target_non_gov_investment | Mean ROC-AUC: 0.9174 | Mean PR-AUC: 0.2501\n",
      "[STARTED] Model: xgb | Target: target_inno_subsidy\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c59cea8eaa0d42fcb583393bec8ff4c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Outer folds:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FINISHED] Model: xgb | Target: target_inno_subsidy | Mean ROC-AUC: 0.8575 | Mean PR-AUC: 0.1544\n",
      "Saved model for xgb/target_inv_exit to /Users/manuelbolz/Documents/git/for_work/company_success_prediction/models/experiment_B/founding_base/trained_models/xgb_target_inv_exit.joblib\n",
      "Saved model for xgb/target_acquisition to /Users/manuelbolz/Documents/git/for_work/company_success_prediction/models/experiment_B/founding_base/trained_models/xgb_target_acquisition.joblib\n",
      "Saved model for xgb/target_non_gov_investment to /Users/manuelbolz/Documents/git/for_work/company_success_prediction/models/experiment_B/founding_base/trained_models/xgb_target_non_gov_investment.joblib\n",
      "Saved model for xgb/target_inno_subsidy to /Users/manuelbolz/Documents/git/for_work/company_success_prediction/models/experiment_B/founding_base/trained_models/xgb_target_inno_subsidy.joblib\n",
      "Saved metrics summary to /Users/manuelbolz/Documents/git/for_work/company_success_prediction/models/experiment_B/founding_base/cv_metrics_report.csv\n",
      "Saved best hyperparameters to /Users/manuelbolz/Documents/git/for_work/company_success_prediction/models/experiment_B/founding_base/best_hyperparameters.pkl\n",
      "Saved best features to /Users/manuelbolz/Documents/git/for_work/company_success_prediction/models/experiment_B/founding_base/best_features.pkl\n",
      "START CONDUCTING EXPERIMENT B FOR: founding_doc2vec\n",
      "Starting nested CV with hyperparameter search...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae280b204211464d83f5a247ff279807",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Models:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da0cb383b7784f82bb82028b0cf243d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "xgb targets:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[STARTED] Model: xgb | Target: target_inv_exit\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc4221a715c845279a5bbeec26d7a632",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Outer folds:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FINISHED] Model: xgb | Target: target_inv_exit | Mean ROC-AUC: 0.6719 | Mean PR-AUC: 0.1106\n",
      "[STARTED] Model: xgb | Target: target_acquisition\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7a627316cf441379cf96a4727fb20fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Outer folds:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FINISHED] Model: xgb | Target: target_acquisition | Mean ROC-AUC: 0.8248 | Mean PR-AUC: 0.0665\n",
      "[STARTED] Model: xgb | Target: target_non_gov_investment\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ee9aafcd12749dea618f7f4561c7f9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Outer folds:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FINISHED] Model: xgb | Target: target_non_gov_investment | Mean ROC-AUC: 0.9369 | Mean PR-AUC: 0.2849\n",
      "[STARTED] Model: xgb | Target: target_inno_subsidy\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae3b2fa80a974ca3b3756a2ece9a09e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Outer folds:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FINISHED] Model: xgb | Target: target_inno_subsidy | Mean ROC-AUC: 0.8643 | Mean PR-AUC: 0.1823\n",
      "Saved model for xgb/target_inv_exit to /Users/manuelbolz/Documents/git/for_work/company_success_prediction/models/experiment_B/founding_doc2vec/trained_models/xgb_target_inv_exit.joblib\n",
      "Saved model for xgb/target_acquisition to /Users/manuelbolz/Documents/git/for_work/company_success_prediction/models/experiment_B/founding_doc2vec/trained_models/xgb_target_acquisition.joblib\n",
      "Saved model for xgb/target_non_gov_investment to /Users/manuelbolz/Documents/git/for_work/company_success_prediction/models/experiment_B/founding_doc2vec/trained_models/xgb_target_non_gov_investment.joblib\n",
      "Saved model for xgb/target_inno_subsidy to /Users/manuelbolz/Documents/git/for_work/company_success_prediction/models/experiment_B/founding_doc2vec/trained_models/xgb_target_inno_subsidy.joblib\n",
      "Saved metrics summary to /Users/manuelbolz/Documents/git/for_work/company_success_prediction/models/experiment_B/founding_doc2vec/cv_metrics_report.csv\n",
      "Saved best hyperparameters to /Users/manuelbolz/Documents/git/for_work/company_success_prediction/models/experiment_B/founding_doc2vec/best_hyperparameters.pkl\n",
      "Saved best features to /Users/manuelbolz/Documents/git/for_work/company_success_prediction/models/experiment_B/founding_doc2vec/best_features.pkl\n",
      "START CONDUCTING EXPERIMENT B FOR: founding_dim768\n",
      "Starting nested CV with hyperparameter search...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5d157243a3447ddb5577893c1b0d4c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Models:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f7b5c621b5b4893a5bad5488f6affbc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "xgb targets:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[STARTED] Model: xgb | Target: target_inv_exit\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6a9698a09354f9d988e5656fb29ad1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Outer folds:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FINISHED] Model: xgb | Target: target_inv_exit | Mean ROC-AUC: 0.6682 | Mean PR-AUC: 0.1086\n",
      "[STARTED] Model: xgb | Target: target_acquisition\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b930ad6ab0824e48838df1018950af9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Outer folds:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FINISHED] Model: xgb | Target: target_acquisition | Mean ROC-AUC: 0.7972 | Mean PR-AUC: 0.0722\n",
      "[STARTED] Model: xgb | Target: target_non_gov_investment\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a8b0f6acb71414db37ea86fc00e0b91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Outer folds:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FINISHED] Model: xgb | Target: target_non_gov_investment | Mean ROC-AUC: 0.9298 | Mean PR-AUC: 0.2799\n",
      "[STARTED] Model: xgb | Target: target_inno_subsidy\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "edc6f6e5e16e442fbcd37d700e0c4fc0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Outer folds:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FINISHED] Model: xgb | Target: target_inno_subsidy | Mean ROC-AUC: 0.8669 | Mean PR-AUC: 0.1780\n",
      "Saved model for xgb/target_inv_exit to /Users/manuelbolz/Documents/git/for_work/company_success_prediction/models/experiment_B/founding_dim768/trained_models/xgb_target_inv_exit.joblib\n",
      "Saved model for xgb/target_acquisition to /Users/manuelbolz/Documents/git/for_work/company_success_prediction/models/experiment_B/founding_dim768/trained_models/xgb_target_acquisition.joblib\n",
      "Saved model for xgb/target_non_gov_investment to /Users/manuelbolz/Documents/git/for_work/company_success_prediction/models/experiment_B/founding_dim768/trained_models/xgb_target_non_gov_investment.joblib\n",
      "Saved model for xgb/target_inno_subsidy to /Users/manuelbolz/Documents/git/for_work/company_success_prediction/models/experiment_B/founding_dim768/trained_models/xgb_target_inno_subsidy.joblib\n",
      "Saved metrics summary to /Users/manuelbolz/Documents/git/for_work/company_success_prediction/models/experiment_B/founding_dim768/cv_metrics_report.csv\n",
      "Saved best hyperparameters to /Users/manuelbolz/Documents/git/for_work/company_success_prediction/models/experiment_B/founding_dim768/best_hyperparameters.pkl\n",
      "Saved best features to /Users/manuelbolz/Documents/git/for_work/company_success_prediction/models/experiment_B/founding_dim768/best_features.pkl\n",
      "START CONDUCTING EXPERIMENT B FOR: founding_dim768_w\n",
      "Starting nested CV with hyperparameter search...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e1ffbfaf6234f53b7fdfe24ec2113c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Models:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3a3998316aa4604883d0ad2e2c2c771",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "xgb targets:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[STARTED] Model: xgb | Target: target_inv_exit\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "286c58c641c84d3ca7d3912bdfb9b40b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Outer folds:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FINISHED] Model: xgb | Target: target_inv_exit | Mean ROC-AUC: 0.6710 | Mean PR-AUC: 0.1091\n",
      "[STARTED] Model: xgb | Target: target_acquisition\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17f55b9807f04522becc3d938cc217cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Outer folds:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FINISHED] Model: xgb | Target: target_acquisition | Mean ROC-AUC: 0.8144 | Mean PR-AUC: 0.0600\n",
      "[STARTED] Model: xgb | Target: target_non_gov_investment\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb08002489d74c60a7aac240accdf32d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Outer folds:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FINISHED] Model: xgb | Target: target_non_gov_investment | Mean ROC-AUC: 0.9411 | Mean PR-AUC: 0.2866\n",
      "[STARTED] Model: xgb | Target: target_inno_subsidy\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c58bb8e07cd244438235c8a6cd7b94a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Outer folds:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FINISHED] Model: xgb | Target: target_inno_subsidy | Mean ROC-AUC: 0.8663 | Mean PR-AUC: 0.1790\n",
      "Saved model for xgb/target_inv_exit to /Users/manuelbolz/Documents/git/for_work/company_success_prediction/models/experiment_B/founding_dim768_w/trained_models/xgb_target_inv_exit.joblib\n",
      "Saved model for xgb/target_acquisition to /Users/manuelbolz/Documents/git/for_work/company_success_prediction/models/experiment_B/founding_dim768_w/trained_models/xgb_target_acquisition.joblib\n",
      "Saved model for xgb/target_non_gov_investment to /Users/manuelbolz/Documents/git/for_work/company_success_prediction/models/experiment_B/founding_dim768_w/trained_models/xgb_target_non_gov_investment.joblib\n",
      "Saved model for xgb/target_inno_subsidy to /Users/manuelbolz/Documents/git/for_work/company_success_prediction/models/experiment_B/founding_dim768_w/trained_models/xgb_target_inno_subsidy.joblib\n",
      "Saved metrics summary to /Users/manuelbolz/Documents/git/for_work/company_success_prediction/models/experiment_B/founding_dim768_w/cv_metrics_report.csv\n",
      "Saved best hyperparameters to /Users/manuelbolz/Documents/git/for_work/company_success_prediction/models/experiment_B/founding_dim768_w/best_hyperparameters.pkl\n",
      "Saved best features to /Users/manuelbolz/Documents/git/for_work/company_success_prediction/models/experiment_B/founding_dim768_w/best_features.pkl\n",
      "START CONDUCTING EXPERIMENT B FOR: founding_dim300_w\n",
      "Starting nested CV with hyperparameter search...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db3a6769602b4f3d9ce154f10d89cd65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Models:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32771b72ac30436982ab8e415cb56970",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "xgb targets:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[STARTED] Model: xgb | Target: target_inv_exit\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20ec602e27cf4972aa69cd11153d41fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Outer folds:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FINISHED] Model: xgb | Target: target_inv_exit | Mean ROC-AUC: 0.6707 | Mean PR-AUC: 0.1102\n",
      "[STARTED] Model: xgb | Target: target_acquisition\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d46729cfc2ee49028fdcb80801b4f855",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Outer folds:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FINISHED] Model: xgb | Target: target_acquisition | Mean ROC-AUC: 0.8063 | Mean PR-AUC: 0.0625\n",
      "[STARTED] Model: xgb | Target: target_non_gov_investment\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07c5265c48f14736909ef74942499dd0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Outer folds:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FINISHED] Model: xgb | Target: target_non_gov_investment | Mean ROC-AUC: 0.9323 | Mean PR-AUC: 0.2776\n",
      "[STARTED] Model: xgb | Target: target_inno_subsidy\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e37c6a82c923405eba7f9619cfd74a8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Outer folds:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FINISHED] Model: xgb | Target: target_inno_subsidy | Mean ROC-AUC: 0.8684 | Mean PR-AUC: 0.1916\n",
      "Saved model for xgb/target_inv_exit to /Users/manuelbolz/Documents/git/for_work/company_success_prediction/models/experiment_B/founding_dim300_w/trained_models/xgb_target_inv_exit.joblib\n",
      "Saved model for xgb/target_acquisition to /Users/manuelbolz/Documents/git/for_work/company_success_prediction/models/experiment_B/founding_dim300_w/trained_models/xgb_target_acquisition.joblib\n",
      "Saved model for xgb/target_non_gov_investment to /Users/manuelbolz/Documents/git/for_work/company_success_prediction/models/experiment_B/founding_dim300_w/trained_models/xgb_target_non_gov_investment.joblib\n",
      "Saved model for xgb/target_inno_subsidy to /Users/manuelbolz/Documents/git/for_work/company_success_prediction/models/experiment_B/founding_dim300_w/trained_models/xgb_target_inno_subsidy.joblib\n",
      "Saved metrics summary to /Users/manuelbolz/Documents/git/for_work/company_success_prediction/models/experiment_B/founding_dim300_w/cv_metrics_report.csv\n",
      "Saved best hyperparameters to /Users/manuelbolz/Documents/git/for_work/company_success_prediction/models/experiment_B/founding_dim300_w/best_hyperparameters.pkl\n",
      "Saved best features to /Users/manuelbolz/Documents/git/for_work/company_success_prediction/models/experiment_B/founding_dim300_w/best_features.pkl\n",
      "START CONDUCTING EXPERIMENT B FOR: current_base\n",
      "Starting nested CV with hyperparameter search...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ac53fc44b814958a2400e695c4b0a22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Models:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c63413b3e54048b4b9dbc452133aaf4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "xgb targets:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[STARTED] Model: xgb | Target: target_inv_exit\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f799f7d7043c4a9b83c4e5e411815291",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Outer folds:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FINISHED] Model: xgb | Target: target_inv_exit | Mean ROC-AUC: 0.6810 | Mean PR-AUC: 0.0630\n",
      "[STARTED] Model: xgb | Target: target_acquisition\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "231cc059e1c24ba1bdd7f50975d46932",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Outer folds:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FINISHED] Model: xgb | Target: target_acquisition | Mean ROC-AUC: 0.8124 | Mean PR-AUC: 0.0599\n",
      "[STARTED] Model: xgb | Target: target_non_gov_investment\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "535f97c4abd44b3bb5431ebf5ddc9c26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Outer folds:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FINISHED] Model: xgb | Target: target_non_gov_investment | Mean ROC-AUC: 0.9175 | Mean PR-AUC: 0.2447\n",
      "[STARTED] Model: xgb | Target: target_inno_subsidy\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "540afb557654418f856813417fb81b51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Outer folds:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FINISHED] Model: xgb | Target: target_inno_subsidy | Mean ROC-AUC: 0.8715 | Mean PR-AUC: 0.1765\n",
      "Saved model for xgb/target_inv_exit to /Users/manuelbolz/Documents/git/for_work/company_success_prediction/models/experiment_B/current_base/trained_models/xgb_target_inv_exit.joblib\n",
      "Saved model for xgb/target_acquisition to /Users/manuelbolz/Documents/git/for_work/company_success_prediction/models/experiment_B/current_base/trained_models/xgb_target_acquisition.joblib\n",
      "Saved model for xgb/target_non_gov_investment to /Users/manuelbolz/Documents/git/for_work/company_success_prediction/models/experiment_B/current_base/trained_models/xgb_target_non_gov_investment.joblib\n",
      "Saved model for xgb/target_inno_subsidy to /Users/manuelbolz/Documents/git/for_work/company_success_prediction/models/experiment_B/current_base/trained_models/xgb_target_inno_subsidy.joblib\n",
      "Saved metrics summary to /Users/manuelbolz/Documents/git/for_work/company_success_prediction/models/experiment_B/current_base/cv_metrics_report.csv\n",
      "Saved best hyperparameters to /Users/manuelbolz/Documents/git/for_work/company_success_prediction/models/experiment_B/current_base/best_hyperparameters.pkl\n",
      "Saved best features to /Users/manuelbolz/Documents/git/for_work/company_success_prediction/models/experiment_B/current_base/best_features.pkl\n",
      "START CONDUCTING EXPERIMENT B FOR: current_doc2vec\n",
      "Starting nested CV with hyperparameter search...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0387025a06e4aaaa9e748c79fbd4df6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Models:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b33d7beaec2420bbd11ccdcd4bfdbab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "xgb targets:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[STARTED] Model: xgb | Target: target_inv_exit\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97d36f49119744e7b752404a7ff6f00f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Outer folds:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FINISHED] Model: xgb | Target: target_inv_exit | Mean ROC-AUC: 0.7052 | Mean PR-AUC: 0.0745\n",
      "[STARTED] Model: xgb | Target: target_acquisition\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2657235e904743a19b3406dc9ccfdbe8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Outer folds:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FINISHED] Model: xgb | Target: target_acquisition | Mean ROC-AUC: 0.8034 | Mean PR-AUC: 0.0523\n",
      "[STARTED] Model: xgb | Target: target_non_gov_investment\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd6987491db6493a9f806848e08f28f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Outer folds:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FINISHED] Model: xgb | Target: target_non_gov_investment | Mean ROC-AUC: 0.9444 | Mean PR-AUC: 0.2998\n",
      "[STARTED] Model: xgb | Target: target_inno_subsidy\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b4bc82ebfab463a9b4ff36f3c827e1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Outer folds:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FINISHED] Model: xgb | Target: target_inno_subsidy | Mean ROC-AUC: 0.8831 | Mean PR-AUC: 0.2022\n",
      "Saved model for xgb/target_inv_exit to /Users/manuelbolz/Documents/git/for_work/company_success_prediction/models/experiment_B/current_doc2vec/trained_models/xgb_target_inv_exit.joblib\n",
      "Saved model for xgb/target_acquisition to /Users/manuelbolz/Documents/git/for_work/company_success_prediction/models/experiment_B/current_doc2vec/trained_models/xgb_target_acquisition.joblib\n",
      "Saved model for xgb/target_non_gov_investment to /Users/manuelbolz/Documents/git/for_work/company_success_prediction/models/experiment_B/current_doc2vec/trained_models/xgb_target_non_gov_investment.joblib\n",
      "Saved model for xgb/target_inno_subsidy to /Users/manuelbolz/Documents/git/for_work/company_success_prediction/models/experiment_B/current_doc2vec/trained_models/xgb_target_inno_subsidy.joblib\n",
      "Saved metrics summary to /Users/manuelbolz/Documents/git/for_work/company_success_prediction/models/experiment_B/current_doc2vec/cv_metrics_report.csv\n",
      "Saved best hyperparameters to /Users/manuelbolz/Documents/git/for_work/company_success_prediction/models/experiment_B/current_doc2vec/best_hyperparameters.pkl\n",
      "Saved best features to /Users/manuelbolz/Documents/git/for_work/company_success_prediction/models/experiment_B/current_doc2vec/best_features.pkl\n",
      "START CONDUCTING EXPERIMENT B FOR: current_dim768\n",
      "Starting nested CV with hyperparameter search...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a47a16a00954101841480b0bda31cdd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Models:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6ad8052ceee4c86a3bda63ed0938526",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "xgb targets:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[STARTED] Model: xgb | Target: target_inv_exit\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99b74fe0cde449f0b78181cc9c3be728",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Outer folds:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FINISHED] Model: xgb | Target: target_inv_exit | Mean ROC-AUC: 0.7051 | Mean PR-AUC: 0.0797\n",
      "[STARTED] Model: xgb | Target: target_acquisition\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a7817f5db644cf6823a72d7c44e8f9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Outer folds:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FINISHED] Model: xgb | Target: target_acquisition | Mean ROC-AUC: 0.8086 | Mean PR-AUC: 0.0611\n",
      "[STARTED] Model: xgb | Target: target_non_gov_investment\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d88926f9986744a8af00aeefdf1dadb3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Outer folds:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FINISHED] Model: xgb | Target: target_non_gov_investment | Mean ROC-AUC: 0.9441 | Mean PR-AUC: 0.3048\n",
      "[STARTED] Model: xgb | Target: target_inno_subsidy\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "404d3fa0c33943808f71279a51008873",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Outer folds:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FINISHED] Model: xgb | Target: target_inno_subsidy | Mean ROC-AUC: 0.8870 | Mean PR-AUC: 0.2101\n",
      "Saved model for xgb/target_inv_exit to /Users/manuelbolz/Documents/git/for_work/company_success_prediction/models/experiment_B/current_dim768/trained_models/xgb_target_inv_exit.joblib\n",
      "Saved model for xgb/target_acquisition to /Users/manuelbolz/Documents/git/for_work/company_success_prediction/models/experiment_B/current_dim768/trained_models/xgb_target_acquisition.joblib\n",
      "Saved model for xgb/target_non_gov_investment to /Users/manuelbolz/Documents/git/for_work/company_success_prediction/models/experiment_B/current_dim768/trained_models/xgb_target_non_gov_investment.joblib\n",
      "Saved model for xgb/target_inno_subsidy to /Users/manuelbolz/Documents/git/for_work/company_success_prediction/models/experiment_B/current_dim768/trained_models/xgb_target_inno_subsidy.joblib\n",
      "Saved metrics summary to /Users/manuelbolz/Documents/git/for_work/company_success_prediction/models/experiment_B/current_dim768/cv_metrics_report.csv\n",
      "Saved best hyperparameters to /Users/manuelbolz/Documents/git/for_work/company_success_prediction/models/experiment_B/current_dim768/best_hyperparameters.pkl\n",
      "Saved best features to /Users/manuelbolz/Documents/git/for_work/company_success_prediction/models/experiment_B/current_dim768/best_features.pkl\n",
      "START CONDUCTING EXPERIMENT B FOR: current_dim768_w\n",
      "Starting nested CV with hyperparameter search...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "134ed39d6bc142b582ed3431df4bdd3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Models:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f938d23a02f24cb5a5fd096088a2455c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "xgb targets:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[STARTED] Model: xgb | Target: target_inv_exit\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b44c63cc833463b88bcfdf61ad47730",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Outer folds:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FINISHED] Model: xgb | Target: target_inv_exit | Mean ROC-AUC: 0.7107 | Mean PR-AUC: 0.0839\n",
      "[STARTED] Model: xgb | Target: target_acquisition\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05d1f39323f14545b56a7037a7c81ad4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Outer folds:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FINISHED] Model: xgb | Target: target_acquisition | Mean ROC-AUC: 0.8109 | Mean PR-AUC: 0.0676\n",
      "[STARTED] Model: xgb | Target: target_non_gov_investment\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65a5329548a444a491668cefd306b0f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Outer folds:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FINISHED] Model: xgb | Target: target_non_gov_investment | Mean ROC-AUC: 0.9446 | Mean PR-AUC: 0.3100\n",
      "[STARTED] Model: xgb | Target: target_inno_subsidy\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c20f651ee0e4c7e87f54ea8437a00e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Outer folds:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FINISHED] Model: xgb | Target: target_inno_subsidy | Mean ROC-AUC: 0.8856 | Mean PR-AUC: 0.2020\n",
      "Saved model for xgb/target_inv_exit to /Users/manuelbolz/Documents/git/for_work/company_success_prediction/models/experiment_B/current_dim768_w/trained_models/xgb_target_inv_exit.joblib\n",
      "Saved model for xgb/target_acquisition to /Users/manuelbolz/Documents/git/for_work/company_success_prediction/models/experiment_B/current_dim768_w/trained_models/xgb_target_acquisition.joblib\n",
      "Saved model for xgb/target_non_gov_investment to /Users/manuelbolz/Documents/git/for_work/company_success_prediction/models/experiment_B/current_dim768_w/trained_models/xgb_target_non_gov_investment.joblib\n",
      "Saved model for xgb/target_inno_subsidy to /Users/manuelbolz/Documents/git/for_work/company_success_prediction/models/experiment_B/current_dim768_w/trained_models/xgb_target_inno_subsidy.joblib\n",
      "Saved metrics summary to /Users/manuelbolz/Documents/git/for_work/company_success_prediction/models/experiment_B/current_dim768_w/cv_metrics_report.csv\n",
      "Saved best hyperparameters to /Users/manuelbolz/Documents/git/for_work/company_success_prediction/models/experiment_B/current_dim768_w/best_hyperparameters.pkl\n",
      "Saved best features to /Users/manuelbolz/Documents/git/for_work/company_success_prediction/models/experiment_B/current_dim768_w/best_features.pkl\n",
      "START CONDUCTING EXPERIMENT B FOR: current_dim300_w\n",
      "Starting nested CV with hyperparameter search...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6ed943d791d48029c16556b24e55dc0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Models:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1b4ba9375164afea2ef13a81c14575c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "xgb targets:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[STARTED] Model: xgb | Target: target_inv_exit\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4070dc327134ac0a1d0120fd33e41b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Outer folds:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FINISHED] Model: xgb | Target: target_inv_exit | Mean ROC-AUC: 0.7113 | Mean PR-AUC: 0.0821\n",
      "[STARTED] Model: xgb | Target: target_acquisition\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f4a8c6865ba43abad1298fde7bd5167",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Outer folds:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FINISHED] Model: xgb | Target: target_acquisition | Mean ROC-AUC: 0.8071 | Mean PR-AUC: 0.0627\n",
      "[STARTED] Model: xgb | Target: target_non_gov_investment\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db956cbaa1bd4ff8bf436dd6276f7371",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Outer folds:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FINISHED] Model: xgb | Target: target_non_gov_investment | Mean ROC-AUC: 0.9441 | Mean PR-AUC: 0.3101\n",
      "[STARTED] Model: xgb | Target: target_inno_subsidy\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4ef221c026d426d87e84c12e36b59f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Outer folds:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FINISHED] Model: xgb | Target: target_inno_subsidy | Mean ROC-AUC: 0.8870 | Mean PR-AUC: 0.2046\n",
      "Saved model for xgb/target_inv_exit to /Users/manuelbolz/Documents/git/for_work/company_success_prediction/models/experiment_B/current_dim300_w/trained_models/xgb_target_inv_exit.joblib\n",
      "Saved model for xgb/target_acquisition to /Users/manuelbolz/Documents/git/for_work/company_success_prediction/models/experiment_B/current_dim300_w/trained_models/xgb_target_acquisition.joblib\n",
      "Saved model for xgb/target_non_gov_investment to /Users/manuelbolz/Documents/git/for_work/company_success_prediction/models/experiment_B/current_dim300_w/trained_models/xgb_target_non_gov_investment.joblib\n",
      "Saved model for xgb/target_inno_subsidy to /Users/manuelbolz/Documents/git/for_work/company_success_prediction/models/experiment_B/current_dim300_w/trained_models/xgb_target_inno_subsidy.joblib\n",
      "Saved metrics summary to /Users/manuelbolz/Documents/git/for_work/company_success_prediction/models/experiment_B/current_dim300_w/cv_metrics_report.csv\n",
      "Saved best hyperparameters to /Users/manuelbolz/Documents/git/for_work/company_success_prediction/models/experiment_B/current_dim300_w/best_hyperparameters.pkl\n",
      "Saved best features to /Users/manuelbolz/Documents/git/for_work/company_success_prediction/models/experiment_B/current_dim300_w/best_features.pkl\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Experiment B: Performance difference between Doc2vec and my implementation\n",
    "\"\"\"\n",
    "\n",
    "BEST_MODEL = 'xgb'\n",
    "\n",
    "MODELS = {\n",
    "    'logreg': LogisticRegression,\n",
    "    'rf': RandomForestClassifier,\n",
    "    'xgb': XGBClassifier,\n",
    "}\n",
    "\n",
    "FOUNDING_WEBSITE_STATS = [\n",
    "    'founding_mean_text_len',\n",
    "    'founding_n_internal_links_mean',\n",
    "    'founding_n_external_links_mean',\n",
    "    'founding_n_languages',\n",
    "]\n",
    "CURRENT_WEBSITE_STATS = [\n",
    "    'current_mean_text_len',\n",
    "    'current_n_internal_links_mean',\n",
    "    'current_n_external_links_mean',\n",
    "    'current_n_languages',\n",
    "]\n",
    "BINARY_BASE = [f for f in XGB_BINARY_FEATURES if f not in WEBSITE_FEATURE_COLS]\n",
    "LOW_CAT_BASE = [f for f in XGB_LOW_CAT_FEATURES if f not in WEBSITE_FEATURE_COLS]\n",
    "HIGH_CAT_BASE = [f for f in XGB_HIGH_CAT_FEATURES if f not in WEBSITE_FEATURE_COLS]\n",
    "CONTINUOUS_BASE = [f for f in XGB_CONTINUOUS_FEATURES if f not in WEBSITE_FEATURE_COLS]\n",
    "\n",
    "FEATURE_CONFIGS = {\n",
    "    'founding_base': {\n",
    "        'cont': [],\n",
    "        'low_cat': []\n",
    "    },\n",
    "    'founding_doc2vec': {\n",
    "        'cont': ['founding_doc2vec_diff'] + FOUNDING_WEBSITE_STATS,\n",
    "        'low_cat': ['founding_dominant_language']\n",
    "    },\n",
    "    'founding_dim768': {\n",
    "        'cont': ['founding_pr_sdg_similarity', 'founding_lp', 'founding_vp'] + FOUNDING_WEBSITE_STATS,\n",
    "        'low_cat': ['founding_dominant_language']\n",
    "    },\n",
    "    'founding_dim768_w': {\n",
    "        'cont': ['founding_pr_w_sdg_similarity', 'founding_lp_w', 'founding_vp_w'] + FOUNDING_WEBSITE_STATS,\n",
    "        'low_cat': ['founding_dominant_language']\n",
    "    },\n",
    "    'founding_dim300_w': {\n",
    "        'cont': ['founding_pr_w_red_sdg_similarity', 'founding_lp_w_red', 'founding_vp_w_red'] + FOUNDING_WEBSITE_STATS,\n",
    "        'low_cat': ['founding_dominant_language']\n",
    "    },\n",
    "    'current_base': {\n",
    "        'cont': [],\n",
    "        'low_cat': []\n",
    "    },\n",
    "    'current_doc2vec': {\n",
    "        'cont': ['current_doc2vec_diff'] + CURRENT_WEBSITE_STATS,\n",
    "        'low_cat': ['current_dominant_language']\n",
    "    },\n",
    "    'current_dim768': {\n",
    "        'cont': ['current_pr_sdg_similarity', 'current_lp', 'current_vp'] + CURRENT_WEBSITE_STATS,\n",
    "        'low_cat': ['current_dominant_language']\n",
    "    },\n",
    "    'current_dim768_w': {\n",
    "        'cont': ['current_pr_w_sdg_similarity', 'current_lp_w', 'current_vp_w'] + CURRENT_WEBSITE_STATS,\n",
    "        'low_cat': ['current_dominant_language']\n",
    "    },\n",
    "    'current_dim300_w': {\n",
    "        'cont': ['current_pr_w_red_sdg_similarity', 'current_lp_w_red', 'current_vp_w_red'] + CURRENT_WEBSITE_STATS,\n",
    "        'low_cat': ['current_dominant_language']\n",
    "    },\n",
    "}\n",
    "\n",
    "# 1. Load data for experiment B\n",
    "for experiment_config, website_features in FEATURE_CONFIGS.items():\n",
    "    print(f'START CONDUCTING EXPERIMENT B FOR: {experiment_config}')\n",
    "\n",
    "    # Set model specs\n",
    "    MODEL_SPECS = {\n",
    "        'xgb': {\n",
    "            'model': XGBClassifier,\n",
    "            'preprocessor_steps': [\n",
    "                ('categorical_low_card', OneHotEncoder(drop='first', sparse_output=False, handle_unknown='ignore')),\n",
    "                ('categorical_high_card', OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)),\n",
    "                ('continuous', 'passthrough'),\n",
    "                ('binary', 'passthrough'),\n",
    "            ],\n",
    "            'features': {\n",
    "                'binary': BINARY_BASE,\n",
    "                'categorical_low_card': LOW_CAT_BASE + website_features['low_cat'],\n",
    "                'categorical_high_card': HIGH_CAT_BASE,\n",
    "                'continuous': CONTINUOUS_BASE + website_features['cont'],\n",
    "            },\n",
    "            'fit_params': {\n",
    "                'random_state': RANDOM_STATE,\n",
    "                'n_jobs': 1,\n",
    "                'objective': 'binary:logistic',\n",
    "                'verbosity': 0,\n",
    "                'booster': 'gbtree',\n",
    "                'tree_method': 'hist',\n",
    "                'use_label_encoder': False,\n",
    "                'eval_metric': 'aucpr',\n",
    "            },\n",
    "            'param_grid': {\n",
    "                'max_depth': IntDistribution(3, 10),\n",
    "                'min_child_weight': IntDistribution(1, 10),\n",
    "                'gamma': FloatDistribution(0, 5.0),\n",
    "                'subsample': FloatDistribution(0.5, 1.0),\n",
    "                'colsample_bytree': FloatDistribution(0.5, 1.0),\n",
    "                'learning_rate': FloatDistribution(0.005, 0.1, log=True),\n",
    "                'n_estimators': IntDistribution(100, 400, step=50),\n",
    "                'reg_alpha': FloatDistribution(0, 5.0),  # L1 regularization\n",
    "                'reg_lambda': FloatDistribution(1.0, 10.0),  # L2 regularization\n",
    "                'max_delta_step': IntDistribution(0, 10),\n",
    "            },\n",
    "            'search_type': 'optuna',\n",
    "            'account_for_class_weights': True\n",
    "        }\n",
    "    }\n",
    "\n",
    "    # 1. Load data for experiment A\n",
    "    if 'current' in experiment_config:\n",
    "        website_df = all_feature_df[~all_feature_df['current_vp'].isna()][[col for col in all_feature_df.columns if col not in FOUNDING_WEBSITE_FEATURE_COLS]].copy()\n",
    "\n",
    "    elif 'founding' in experiment_config:\n",
    "        website_df = all_feature_df[~all_feature_df['founding_vp'].isna()][[col for col in all_feature_df.columns if col not in CURRENT_WEBSITE_FEATURE_COLS]].copy()\n",
    "\n",
    "    targets = TARGET_COLS\n",
    "\n",
    "    # 2. Initialize model evaluation with targets and model specs\n",
    "    meval = ModelEvaluation(targets, MODEL_SPECS, random_state=RANDOM_STATE)\n",
    "    meval.load_data(website_df)\n",
    "    \n",
    "    # 3. Evaluate with doc2vec scores\n",
    "    out_folder = MODELS_DIR / 'experiment_B' / experiment_config\n",
    "    meval.nested_cv_with_hyperparam_search(out_folder=out_folder, k_outer=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['founding_base', 'founding_doc2vec', 'founding_dim768', 'founding_dim768_w', 'founding_dim300_w', 'current_base', 'current_doc2vec', 'current_dim768', 'current_dim768_w', 'current_dim300_w'])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FEATURE_CONFIGS.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURE_CONFIGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_per_fold_metric(df, target, metric_col):\n",
    "    \"\"\"Return list of per-fold metric values for given target.\"\"\"\n",
    "    values = df[df['target'] == target][metric_col].values\n",
    "    return ast.literal_eval(values[0]) if len(values) > 0 else None\n",
    "\n",
    "results = []\n",
    "\n",
    "for kind in ['founding', 'current']:\n",
    "    \n",
    "    exp_B_base_df = pd.read_csv(MODELS_DIR / 'experiment_B' / f'{kind}_base' / 'cv_metrics_report.csv')\n",
    "\n",
    "    for report_dir in [col for col in FEATURE_CONFIGS.keys() if kind in col]:\n",
    "\n",
    "        for target in TARGET_COLS:\n",
    "            \n",
    "            comp_df = pd.read_csv(MODELS_DIR / 'experiment_B' / report_dir / 'cv_metrics_report.csv')\n",
    "\n",
    "            for metric in [\"all_roc_auc\", \"all_pr_auc\"]:\n",
    "            # Get per-fold AP for website and base\n",
    "                web_ap = get_per_fold_metric(comp_df, target, metric)\n",
    "                base_ap = get_per_fold_metric(exp_B_base_df, target, metric)\n",
    "                web_ap, base_ap = np.array(web_ap), np.array(base_ap)\n",
    "                \n",
    "                mean_web, mean_base = np.mean(web_ap), np.mean(base_ap)\n",
    "                std_web, std_base = np.std(web_ap, ddof=1), np.std(base_ap, ddof=1)\n",
    "                n_web, n_base = len(web_ap), len(base_ap)\n",
    "\n",
    "                # Welch's SE and df\n",
    "                se_diff = np.sqrt(std_web**2/n_web + std_base**2/n_base)\n",
    "                degrees_of_freedom = (std_web**2 / n_web + std_base**2 / n_base)**2 / ((std_web**2 / n_web)**2 / (n_web-1) + (std_base**2 / n_base)**2 / (n_base-1))\n",
    "\n",
    "                diff = mean_web - mean_base\n",
    "                diff_pct = diff / mean_base * 100\n",
    "\n",
    "                t_stat = diff / se_diff if se_diff > 0 else 0\n",
    "                p_value = 2 * t.sf(np.abs(t_stat), degrees_of_freedom)\n",
    "                \n",
    "                ci = {}\n",
    "                for alpha, label in zip([0.01, 0.05, 0.1], ['99', '95', '90']):\n",
    "                    t_crit = t.ppf(1 - alpha/2, degrees_of_freedom)\n",
    "                    ci[f\"ci_lower_{label}\"] = diff - t_crit * se_diff\n",
    "                    ci[f\"ci_upper_{label}\"] = diff + t_crit * se_diff\n",
    "\n",
    "                results.append({\n",
    "                    'model': report_dir,\n",
    "                    'metric': metric,\n",
    "                    'metric_value': mean_web,\n",
    "                    'target': target,\n",
    "                    'mean_ap_website': mean_web,\n",
    "                    'mean_ap_base': mean_base,\n",
    "                    'p_value': p_value,\n",
    "                    **ci,\n",
    "                })\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df.to_csv(MODELS_DIR / 'experiment_B' / 'individual_significance_report.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "for kind in ['founding', 'current']:\n",
    "    \n",
    "    base_df = pd.read_csv(MODELS_DIR / 'experiment_B' / f'{kind}_base' / 'cv_metrics_report.csv')\n",
    "\n",
    "    # For each target, for each metric, pool differences from all website models\n",
    "    for target in TARGET_COLS:\n",
    "        for metric in [\"all_roc_auc\", \"all_pr_auc\"]:\n",
    "            all_diffs = []\n",
    "            for report_dir in [col for col in FEATURE_CONFIGS.keys() if kind in col and col != f'{kind}_base']:\n",
    "                comp_df = pd.read_csv(MODELS_DIR / 'experiment_B' / report_dir / 'cv_metrics_report.csv')\n",
    "                web_scores = get_per_fold_metric(comp_df, target, metric)\n",
    "                base_scores = get_per_fold_metric(base_df, target, metric)\n",
    "                if web_scores is None or base_scores is None:\n",
    "                    continue\n",
    "                diffs = np.array(web_scores) - np.array(base_scores)\n",
    "                all_diffs.extend(diffs)\n",
    "\n",
    "            all_diffs = np.array(all_diffs)\n",
    "            if len(all_diffs) == 0:\n",
    "                continue\n",
    "            mean_diff = np.mean(all_diffs)\n",
    "            mean_diff_pct = np.round(mean_diff / np.mean(base_scores) * 100, decimals=1)\n",
    "            std_diff = np.std(all_diffs, ddof=1)\n",
    "            n = len(all_diffs)\n",
    "            se = std_diff / np.sqrt(n)\n",
    "\n",
    "            # t-test and p-value\n",
    "            t_stat, p_value = ttest_1samp(all_diffs, 0.0)\n",
    "\n",
    "            # Confidence intervals\n",
    "            ci_99 = t.ppf(0.995, n-1) * se\n",
    "            ci_95 = t.ppf(0.975, n-1) * se\n",
    "            ci_90 = t.ppf(0.95, n-1) * se\n",
    "\n",
    "            results.append({\n",
    "                'kind': kind,\n",
    "                'target': target,\n",
    "                'metric': metric,\n",
    "                'mean_improvement': mean_diff,\n",
    "                'mean_improvement_pct': mean_diff_pct,\n",
    "                'std': std_diff,\n",
    "                'n': n,\n",
    "                'p_value': p_value,\n",
    "                'ci_lower_99': mean_diff - ci_99,\n",
    "                'ci_upper_99': mean_diff + ci_99,\n",
    "                'ci_lower_95': mean_diff - ci_95,\n",
    "                'ci_upper_95': mean_diff + ci_95,\n",
    "                'ci_lower_90': mean_diff - ci_90,\n",
    "                'ci_upper_90': mean_diff + ci_90,\n",
    "            })\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df.to_csv(MODELS_DIR / 'experiment_B' / 'average_significance_report.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Significant at *** (0.01):\n",
      "founding_dim768_w, all_roc_auc, target_non_gov_investment, =0.0237, p=0.941\n",
      "current_doc2vec, all_roc_auc, target_non_gov_investment, =0.0269, p=0.944\n",
      "current_dim768, all_roc_auc, target_non_gov_investment, =0.0266, p=0.944\n",
      "current_dim768_w, all_roc_auc, target_inv_exit, =0.0297, p=0.711\n",
      "current_dim768_w, all_pr_auc, target_inv_exit, =0.0209, p=0.0839\n",
      "current_dim768_w, all_roc_auc, target_non_gov_investment, =0.0271, p=0.945\n",
      "current_dim300_w, all_roc_auc, target_inv_exit, =0.0303, p=0.711\n",
      "current_dim300_w, all_pr_auc, target_inv_exit, =0.0191, p=0.0821\n",
      "current_dim300_w, all_roc_auc, target_non_gov_investment, =0.0266, p=0.944\n",
      "\n",
      "Significant at ** (0.05):\n",
      "founding_doc2vec, all_roc_auc, target_non_gov_investment, =0.0195, p=0.937\n",
      "founding_dim300_w, all_roc_auc, target_non_gov_investment, =0.0149, p=0.932\n",
      "founding_dim300_w, all_pr_auc, target_inno_subsidy, =0.0372, p=0.192\n",
      "current_doc2vec, all_roc_auc, target_inv_exit, =0.0243, p=0.705\n",
      "current_doc2vec, all_pr_auc, target_inv_exit, =0.0115, p=0.0745\n",
      "current_dim768, all_roc_auc, target_inv_exit, =0.0241, p=0.705\n",
      "current_dim768, all_pr_auc, target_inv_exit, =0.0167, p=0.0797\n",
      "current_dim768, all_roc_auc, target_inno_subsidy, =0.0155, p=0.887\n",
      "current_dim768_w, all_pr_auc, target_non_gov_investment, =0.0653, p=0.31\n",
      "current_dim300_w, all_roc_auc, target_inno_subsidy, =0.0155, p=0.887\n",
      "\n",
      "Significant at * (0.1):\n",
      "founding_doc2vec, all_pr_auc, target_inno_subsidy, =0.0279, p=0.182\n",
      "founding_dim768, all_roc_auc, target_non_gov_investment, =0.0124, p=0.93\n",
      "current_dim768, all_pr_auc, target_non_gov_investment, =0.0600, p=0.305\n",
      "current_dim768, all_pr_auc, target_inno_subsidy, =0.0336, p=0.21\n",
      "current_dim768_w, all_roc_auc, target_inno_subsidy, =0.0141, p=0.886\n",
      "current_dim300_w, all_pr_auc, target_non_gov_investment, =0.0654, p=0.31\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(MODELS_DIR / 'experiment_B' / 'individual_significance_report.csv')\n",
    "for level, cutoff, previous in [('***', 0.01, 0.0), ('**', 0.05, 0.01), ('*', 0.10, 0.05)]:\n",
    "    sig = df[(df['p_value'] < cutoff) & (df['p_value'] >= previous)]\n",
    "    print(f\"\\nSignificant at {level} ({cutoff}):\")\n",
    "    for _, row in sig.iterrows():\n",
    "        print(f\"{row['model']}, {row['metric']}, {row['target']}, ={row['mean_ap_website'] - row['mean_ap_base']:.4f}, p={row['mean_ap_website']:.3g}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base data:\n",
      "target_inv_exit 0.16533611014693972\n",
      "Founding website data:\n",
      "target_inv_exit 0.056830514306890074\n",
      "Current website data:\n",
      "target_inv_exit 0.029797745870001544\n",
      "Base data:\n",
      "target_acquisition 0.00648630970766184\n",
      "Founding website data:\n",
      "target_acquisition 0.004452942212382701\n",
      "Current website data:\n",
      "target_acquisition 0.0031332247148765507\n",
      "Base data:\n",
      "target_non_gov_investment 0.005153142691246915\n",
      "Founding website data:\n",
      "target_non_gov_investment 0.009455906148867314\n",
      "Current website data:\n",
      "target_non_gov_investment 0.010019433157509527\n",
      "Base data:\n",
      "target_inno_subsidy 0.008244908359572648\n",
      "Founding website data:\n",
      "target_inno_subsidy 0.015102206854469643\n",
      "Current website data:\n",
      "target_inno_subsidy 0.014886009180128319\n"
     ]
    }
   ],
   "source": [
    "founding_website_df = all_feature_df[~all_feature_df['founding_vp'].isna()][[col for col in all_feature_df.columns if col not in FOUNDING_WEBSITE_FEATURE_COLS]].copy()\n",
    "current_website_df = all_feature_df[~all_feature_df['current_vp'].isna()][[col for col in all_feature_df.columns if col not in FOUNDING_WEBSITE_FEATURE_COLS]].copy()\n",
    "\n",
    "for target in TARGET_COLS:\n",
    "    print('Base data:')\n",
    "    print(target, len(base_df[base_df[target] == 1]) / len(base_df[base_df[target] == 0]))\n",
    "    print('Founding website data:')\n",
    "    print(target, len(founding_website_df[founding_website_df[target] == 1]) / len(founding_website_df[founding_website_df[target] == 0]))\n",
    "    print('Current website data:')\n",
    "    print(target, len(current_website_df[current_website_df[target] == 1]) / len(current_website_df[current_website_df[target] == 0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['target_inv_exit',\n",
       " 'target_acquisition',\n",
       " 'target_non_gov_investment',\n",
       " 'target_inno_subsidy']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TARGET_COLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Experiment C: Regression analysis of Embedding Scores\n",
    "\"\"\"\n",
    "\n",
    "query_green = \"\"\" \n",
    "    SELECT * FROM zefix.green_binary WHERE is_green;\n",
    "\"\"\"\n",
    "\n",
    "with connect_database() as con:\n",
    "    df_green = read_from_database(connection=con, query=query_green)\n",
    "\n",
    "company_sample = company_sample[['ehraid', 'uid'] + TARGET_COLS + ALL_BINARY_FEATURE_COLS + ALL_CATEGORICAL_FEATURE_COLS + ALL_CONTINUOUS_FEATURE_COLS + ['founding_year']]\n",
    "company_sample = company_sample.merge(df_green, on='uid', how='left')\n",
    "company_sample['is_green'] = company_sample['is_green'].fillna(0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CoefficientAnalyser:\n",
    "    def __init__(self, df: pd.DataFrame, experiment_dir: str, scale: bool = True):\n",
    "        self.df = df\n",
    "        self.experiment_dir = Path(experiment_dir)\n",
    "        self.experiment_dir.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "    @staticmethod\n",
    "    def drop_perfect_separation(df, target, col):\n",
    "        keep = df.groupby(col)[target].nunique()\n",
    "        keep = keep[keep > 1].index  # only keep categories that have both 0 and 1\n",
    "        return df[df[col].isin(keep)]\n",
    "\n",
    "    def analyse(\n",
    "        self,\n",
    "        targets: list[str | tuple[str, str]],\n",
    "        score_cols,\n",
    "        controls,\n",
    "        interaction_terms: list[tuple[str, str]],\n",
    "        save_full_summary=True,\n",
    "        subfolder='reg_results'\n",
    "    ):\n",
    "        \"\"\"\n",
    "        targets: list of target column names (binary outcome)\n",
    "        score_cols: list of column names (strings) OR list of list of strings (for multi-score models)\n",
    "            e.g., ['current_vp', 'current_lp']\n",
    "               or [ ['current_vp'], ['current_lp'], ['current_vp', 'current_lp'] ]\n",
    "        controls: list of categorical control variable names (for fixed effects)\n",
    "        \"\"\"\n",
    "        summary_rows = []\n",
    "        auc_rows = []\n",
    "        out_folder = self.experiment_dir / subfolder\n",
    "        summary_folder = out_folder / 'summaries'\n",
    "        out_folder.mkdir(exist_ok=True, parents=True)\n",
    "        summary_folder.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "        # Ensure score_cols is a list of lists\n",
    "        if score_cols and isinstance(score_cols[0], str):\n",
    "            score_cols = [[col] for col in score_cols]\n",
    "\n",
    "        for target_col in targets:\n",
    "\n",
    "            if isinstance(target_col, tuple):\n",
    "                target = '_or_'.join(target_col)\n",
    "                self.df[target] = self.df[list(target_col)].max(axis=1)\n",
    "            else:\n",
    "                target = target_col\n",
    "\n",
    "            for score_set in score_cols:\n",
    "                cols_needed = [target] + list(score_set) + controls\n",
    "                reg_df = self.df.replace([np.inf, -np.inf], np.nan)\\\n",
    "                                .dropna(subset=cols_needed).copy()\n",
    "                reg_df[target] = reg_df[target].astype(int)\n",
    "\n",
    "                # Drop perfect separation categories\n",
    "                for control in controls:\n",
    "                    reg_df = self.drop_perfect_separation(reg_df, target, control)\n",
    "\n",
    "                # Build formula\n",
    "                score_formula = \" + \".join(score_set)\n",
    "                control_formula = \" + \".join([f'C({c})' for c in controls])\n",
    "                if interaction_terms:\n",
    "                    interaction_formula = \" + \".join([f'C({c1}):C({c2})' for c1, c2 in interaction_terms])\n",
    "                    formula = f\"{target} ~ {score_formula} + {control_formula} + {interaction_formula}\"\n",
    "                else:\n",
    "                    formula = f\"{target} ~ {score_formula} + {control_formula}\"\n",
    "                print(f\"Fitting: {formula} (n={len(reg_df)})\")\n",
    "\n",
    "                try:\n",
    "                    result = smf.logit(formula=formula, data=reg_df).fit(disp=0, cov_type='HC1')\n",
    "                    y_pred = result.predict(reg_df)\n",
    "                    auc = roc_auc_score(reg_df[target], y_pred)\n",
    "                    pr_auc = average_precision_score(reg_df[target], y_pred)\n",
    "                    pseudo_r2 = 1 - result.llf/result.llnull\n",
    "\n",
    "                    # Save all score coefs\n",
    "                    for score in score_set:\n",
    "                        summary_rows.append({\n",
    "                            'target': target,\n",
    "                            'score': '+'.join(score_set),\n",
    "                            'coef_name': score,\n",
    "                            'coef': result.params.get(score, np.nan),\n",
    "                            'std_err': result.bse.get(score, np.nan),\n",
    "                            'pval': result.pvalues.get(score, np.nan),\n",
    "                            'pseudo_r2': pseudo_r2,\n",
    "                            'n_obs': len(reg_df)\n",
    "                        })\n",
    "                    auc_rows.append({\n",
    "                        'target': target,\n",
    "                        'score': '+'.join(score_set),\n",
    "                        'auc': auc,\n",
    "                        'pr_auc': pr_auc,\n",
    "                        'n_obs': len(reg_df)\n",
    "                    })\n",
    "                    if save_full_summary:\n",
    "\n",
    "                        fname = summary_folder / f\"reg_summary_{target}_{'+'.join(score_set)}.txt\"\n",
    "                        with open(fname, 'w') as f:\n",
    "                            f.write(result.summary().as_text())\n",
    "                except Exception as e:\n",
    "                    print(f\"Error with {target}, {score_set}: {e}\")\n",
    "\n",
    "        pd.DataFrame(summary_rows).to_csv(out_folder / 'report_regression_results.csv', index=False)\n",
    "        pd.DataFrame(auc_rows).to_csv(out_folder / 'report_auc_scores.csv', index=False)\n",
    "        print(f\"\\nSaved regression summaries and AUC scores to {out_folder}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting: target_inno_subsidy_or_target_non_gov_investment_or_target_acquisition ~ founding_pr_sdg_similarity + C(founding_year) (n=39927)\n",
      "Fitting: target_inno_subsidy_or_target_non_gov_investment_or_target_acquisition ~ founding_pr_w_sdg_similarity + C(founding_year) (n=39927)\n",
      "Fitting: target_inno_subsidy_or_target_non_gov_investment_or_target_acquisition ~ founding_pr_w_red_sdg_similarity + C(founding_year) (n=39927)\n",
      "Fitting: target_inno_subsidy_or_target_non_gov_investment_or_target_acquisition ~ founding_doc2vec_diff + C(founding_year) (n=39700)\n",
      "Fitting: target_inno_subsidy_or_target_non_gov_investment_or_target_acquisition ~ founding_lp + C(founding_year) (n=39927)\n",
      "Fitting: target_inno_subsidy_or_target_non_gov_investment_or_target_acquisition ~ founding_lp_w + C(founding_year) (n=39927)\n",
      "Fitting: target_inno_subsidy_or_target_non_gov_investment_or_target_acquisition ~ founding_lp_w_red + C(founding_year) (n=39927)\n",
      "Fitting: target_inno_subsidy_or_target_non_gov_investment_or_target_acquisition ~ founding_vp + C(founding_year) (n=39927)\n",
      "Fitting: target_inno_subsidy_or_target_non_gov_investment_or_target_acquisition ~ founding_vp_w + C(founding_year) (n=39927)\n",
      "Fitting: target_inno_subsidy_or_target_non_gov_investment_or_target_acquisition ~ founding_vp_w_red + C(founding_year) (n=39927)\n",
      "Fitting: target_inno_subsidy_or_target_non_gov_investment_or_target_acquisition ~ current_pr_sdg_similarity + C(founding_year) (n=40021)\n",
      "Fitting: target_inno_subsidy_or_target_non_gov_investment_or_target_acquisition ~ current_pr_w_sdg_similarity + C(founding_year) (n=40021)\n",
      "Fitting: target_inno_subsidy_or_target_non_gov_investment_or_target_acquisition ~ current_pr_w_red_sdg_similarity + C(founding_year) (n=40021)\n",
      "Fitting: target_inno_subsidy_or_target_non_gov_investment_or_target_acquisition ~ current_doc2vec_diff + C(founding_year) (n=39892)\n",
      "Fitting: target_inno_subsidy_or_target_non_gov_investment_or_target_acquisition ~ current_lp + C(founding_year) (n=40021)\n",
      "Fitting: target_inno_subsidy_or_target_non_gov_investment_or_target_acquisition ~ current_lp_w + C(founding_year) (n=40021)\n",
      "Fitting: target_inno_subsidy_or_target_non_gov_investment_or_target_acquisition ~ current_lp_w_red + C(founding_year) (n=40021)\n",
      "Fitting: target_inno_subsidy_or_target_non_gov_investment_or_target_acquisition ~ current_vp + C(founding_year) (n=40021)\n",
      "Fitting: target_inno_subsidy_or_target_non_gov_investment_or_target_acquisition ~ current_vp_w + C(founding_year) (n=40021)\n",
      "Fitting: target_inno_subsidy_or_target_non_gov_investment_or_target_acquisition ~ current_vp_w_red + C(founding_year) (n=40021)\n",
      "Fitting: target_inno_subsidy_or_target_non_gov_investment ~ founding_pr_sdg_similarity + C(founding_year) (n=39927)\n",
      "Fitting: target_inno_subsidy_or_target_non_gov_investment ~ founding_pr_w_sdg_similarity + C(founding_year) (n=39927)\n",
      "Fitting: target_inno_subsidy_or_target_non_gov_investment ~ founding_pr_w_red_sdg_similarity + C(founding_year) (n=39927)\n",
      "Fitting: target_inno_subsidy_or_target_non_gov_investment ~ founding_doc2vec_diff + C(founding_year) (n=39700)\n",
      "Fitting: target_inno_subsidy_or_target_non_gov_investment ~ founding_lp + C(founding_year) (n=39927)\n",
      "Fitting: target_inno_subsidy_or_target_non_gov_investment ~ founding_lp_w + C(founding_year) (n=39927)\n",
      "Fitting: target_inno_subsidy_or_target_non_gov_investment ~ founding_lp_w_red + C(founding_year) (n=39927)\n",
      "Fitting: target_inno_subsidy_or_target_non_gov_investment ~ founding_vp + C(founding_year) (n=39927)\n",
      "Fitting: target_inno_subsidy_or_target_non_gov_investment ~ founding_vp_w + C(founding_year) (n=39927)\n",
      "Fitting: target_inno_subsidy_or_target_non_gov_investment ~ founding_vp_w_red + C(founding_year) (n=39927)\n",
      "Fitting: target_inno_subsidy_or_target_non_gov_investment ~ current_pr_sdg_similarity + C(founding_year) (n=40021)\n",
      "Fitting: target_inno_subsidy_or_target_non_gov_investment ~ current_pr_w_sdg_similarity + C(founding_year) (n=40021)\n",
      "Fitting: target_inno_subsidy_or_target_non_gov_investment ~ current_pr_w_red_sdg_similarity + C(founding_year) (n=40021)\n",
      "Fitting: target_inno_subsidy_or_target_non_gov_investment ~ current_doc2vec_diff + C(founding_year) (n=39892)\n",
      "Fitting: target_inno_subsidy_or_target_non_gov_investment ~ current_lp + C(founding_year) (n=40021)\n",
      "Fitting: target_inno_subsidy_or_target_non_gov_investment ~ current_lp_w + C(founding_year) (n=40021)\n",
      "Fitting: target_inno_subsidy_or_target_non_gov_investment ~ current_lp_w_red + C(founding_year) (n=40021)\n",
      "Fitting: target_inno_subsidy_or_target_non_gov_investment ~ current_vp + C(founding_year) (n=40021)\n",
      "Fitting: target_inno_subsidy_or_target_non_gov_investment ~ current_vp_w + C(founding_year) (n=40021)\n",
      "Fitting: target_inno_subsidy_or_target_non_gov_investment ~ current_vp_w_red + C(founding_year) (n=40021)\n",
      "\n",
      "Saved regression summaries and AUC scores to /Users/manuelbolz/Documents/git/for_work/company_success_prediction/models/experiment_C/Year FEs\n",
      "Fitting: target_inno_subsidy_or_target_non_gov_investment_or_target_acquisition ~ founding_pr_sdg_similarity + C(founding_year) + C(division_1_label) (n=39328)\n",
      "Fitting: target_inno_subsidy_or_target_non_gov_investment_or_target_acquisition ~ founding_pr_w_sdg_similarity + C(founding_year) + C(division_1_label) (n=39328)\n",
      "Fitting: target_inno_subsidy_or_target_non_gov_investment_or_target_acquisition ~ founding_pr_w_red_sdg_similarity + C(founding_year) + C(division_1_label) (n=39328)\n",
      "Fitting: target_inno_subsidy_or_target_non_gov_investment_or_target_acquisition ~ founding_doc2vec_diff + C(founding_year) + C(division_1_label) (n=39102)\n",
      "Fitting: target_inno_subsidy_or_target_non_gov_investment_or_target_acquisition ~ founding_lp + C(founding_year) + C(division_1_label) (n=39328)\n",
      "Fitting: target_inno_subsidy_or_target_non_gov_investment_or_target_acquisition ~ founding_lp_w + C(founding_year) + C(division_1_label) (n=39328)\n",
      "Fitting: target_inno_subsidy_or_target_non_gov_investment_or_target_acquisition ~ founding_lp_w_red + C(founding_year) + C(division_1_label) (n=39328)\n",
      "Fitting: target_inno_subsidy_or_target_non_gov_investment_or_target_acquisition ~ founding_vp + C(founding_year) + C(division_1_label) (n=39328)\n",
      "Fitting: target_inno_subsidy_or_target_non_gov_investment_or_target_acquisition ~ founding_vp_w + C(founding_year) + C(division_1_label) (n=39328)\n",
      "Fitting: target_inno_subsidy_or_target_non_gov_investment_or_target_acquisition ~ founding_vp_w_red + C(founding_year) + C(division_1_label) (n=39328)\n",
      "Fitting: target_inno_subsidy_or_target_non_gov_investment_or_target_acquisition ~ current_pr_sdg_similarity + C(founding_year) + C(division_1_label) (n=39035)\n",
      "Fitting: target_inno_subsidy_or_target_non_gov_investment_or_target_acquisition ~ current_pr_w_sdg_similarity + C(founding_year) + C(division_1_label) (n=39035)\n",
      "Fitting: target_inno_subsidy_or_target_non_gov_investment_or_target_acquisition ~ current_pr_w_red_sdg_similarity + C(founding_year) + C(division_1_label) (n=39035)\n",
      "Fitting: target_inno_subsidy_or_target_non_gov_investment_or_target_acquisition ~ current_doc2vec_diff + C(founding_year) + C(division_1_label) (n=38906)\n",
      "Fitting: target_inno_subsidy_or_target_non_gov_investment_or_target_acquisition ~ current_lp + C(founding_year) + C(division_1_label) (n=39035)\n",
      "Fitting: target_inno_subsidy_or_target_non_gov_investment_or_target_acquisition ~ current_lp_w + C(founding_year) + C(division_1_label) (n=39035)\n",
      "Fitting: target_inno_subsidy_or_target_non_gov_investment_or_target_acquisition ~ current_lp_w_red + C(founding_year) + C(division_1_label) (n=39035)\n",
      "Fitting: target_inno_subsidy_or_target_non_gov_investment_or_target_acquisition ~ current_vp + C(founding_year) + C(division_1_label) (n=39035)\n",
      "Fitting: target_inno_subsidy_or_target_non_gov_investment_or_target_acquisition ~ current_vp_w + C(founding_year) + C(division_1_label) (n=39035)\n",
      "Fitting: target_inno_subsidy_or_target_non_gov_investment_or_target_acquisition ~ current_vp_w_red + C(founding_year) + C(division_1_label) (n=39035)\n",
      "Fitting: target_inno_subsidy_or_target_non_gov_investment ~ founding_pr_sdg_similarity + C(founding_year) + C(division_1_label) (n=38713)\n",
      "Fitting: target_inno_subsidy_or_target_non_gov_investment ~ founding_pr_w_sdg_similarity + C(founding_year) + C(division_1_label) (n=38713)\n",
      "Fitting: target_inno_subsidy_or_target_non_gov_investment ~ founding_pr_w_red_sdg_similarity + C(founding_year) + C(division_1_label) (n=38713)\n",
      "Fitting: target_inno_subsidy_or_target_non_gov_investment ~ founding_doc2vec_diff + C(founding_year) + C(division_1_label) (n=38491)\n",
      "Fitting: target_inno_subsidy_or_target_non_gov_investment ~ founding_lp + C(founding_year) + C(division_1_label) (n=38713)\n",
      "Fitting: target_inno_subsidy_or_target_non_gov_investment ~ founding_lp_w + C(founding_year) + C(division_1_label) (n=38713)\n",
      "Fitting: target_inno_subsidy_or_target_non_gov_investment ~ founding_lp_w_red + C(founding_year) + C(division_1_label) (n=38713)\n",
      "Fitting: target_inno_subsidy_or_target_non_gov_investment ~ founding_vp + C(founding_year) + C(division_1_label) (n=38713)\n",
      "Fitting: target_inno_subsidy_or_target_non_gov_investment ~ founding_vp_w + C(founding_year) + C(division_1_label) (n=38713)\n",
      "Fitting: target_inno_subsidy_or_target_non_gov_investment ~ founding_vp_w_red + C(founding_year) + C(division_1_label) (n=38713)\n",
      "Fitting: target_inno_subsidy_or_target_non_gov_investment ~ current_pr_sdg_similarity + C(founding_year) + C(division_1_label) (n=38440)\n",
      "Fitting: target_inno_subsidy_or_target_non_gov_investment ~ current_pr_w_sdg_similarity + C(founding_year) + C(division_1_label) (n=38440)\n",
      "Fitting: target_inno_subsidy_or_target_non_gov_investment ~ current_pr_w_red_sdg_similarity + C(founding_year) + C(division_1_label) (n=38440)\n",
      "Fitting: target_inno_subsidy_or_target_non_gov_investment ~ current_doc2vec_diff + C(founding_year) + C(division_1_label) (n=38314)\n",
      "Fitting: target_inno_subsidy_or_target_non_gov_investment ~ current_lp + C(founding_year) + C(division_1_label) (n=38440)\n",
      "Fitting: target_inno_subsidy_or_target_non_gov_investment ~ current_lp_w + C(founding_year) + C(division_1_label) (n=38440)\n",
      "Fitting: target_inno_subsidy_or_target_non_gov_investment ~ current_lp_w_red + C(founding_year) + C(division_1_label) (n=38440)\n",
      "Fitting: target_inno_subsidy_or_target_non_gov_investment ~ current_vp + C(founding_year) + C(division_1_label) (n=38440)\n",
      "Fitting: target_inno_subsidy_or_target_non_gov_investment ~ current_vp_w + C(founding_year) + C(division_1_label) (n=38440)\n",
      "Fitting: target_inno_subsidy_or_target_non_gov_investment ~ current_vp_w_red + C(founding_year) + C(division_1_label) (n=38440)\n",
      "Fitting: target_inno_subsidy ~ founding_pr_sdg_similarity + C(founding_year) + C(division_1_label) (n=38186)\n",
      "Fitting: target_inno_subsidy ~ founding_pr_w_sdg_similarity + C(founding_year) + C(division_1_label) (n=38186)\n",
      "Fitting: target_inno_subsidy ~ founding_pr_w_red_sdg_similarity + C(founding_year) + C(division_1_label) (n=38186)\n",
      "Fitting: target_inno_subsidy ~ founding_doc2vec_diff + C(founding_year) + C(division_1_label) (n=37968)\n",
      "Fitting: target_inno_subsidy ~ founding_lp + C(founding_year) + C(division_1_label) (n=38186)\n",
      "Fitting: target_inno_subsidy ~ founding_lp_w + C(founding_year) + C(division_1_label) (n=38186)\n",
      "Fitting: target_inno_subsidy ~ founding_lp_w_red + C(founding_year) + C(division_1_label) (n=38186)\n",
      "Fitting: target_inno_subsidy ~ founding_vp + C(founding_year) + C(division_1_label) (n=38186)\n",
      "Fitting: target_inno_subsidy ~ founding_vp_w + C(founding_year) + C(division_1_label) (n=38186)\n",
      "Fitting: target_inno_subsidy ~ founding_vp_w_red + C(founding_year) + C(division_1_label) (n=38186)\n",
      "Fitting: target_inno_subsidy ~ current_pr_sdg_similarity + C(founding_year) + C(division_1_label) (n=37701)\n",
      "Fitting: target_inno_subsidy ~ current_pr_w_sdg_similarity + C(founding_year) + C(division_1_label) (n=37701)\n",
      "Fitting: target_inno_subsidy ~ current_pr_w_red_sdg_similarity + C(founding_year) + C(division_1_label) (n=37701)\n",
      "Fitting: target_inno_subsidy ~ current_doc2vec_diff + C(founding_year) + C(division_1_label) (n=37576)\n",
      "Fitting: target_inno_subsidy ~ current_lp + C(founding_year) + C(division_1_label) (n=37701)\n",
      "Fitting: target_inno_subsidy ~ current_lp_w + C(founding_year) + C(division_1_label) (n=37701)\n",
      "Fitting: target_inno_subsidy ~ current_lp_w_red + C(founding_year) + C(division_1_label) (n=37701)\n",
      "Fitting: target_inno_subsidy ~ current_vp + C(founding_year) + C(division_1_label) (n=37701)\n",
      "Fitting: target_inno_subsidy ~ current_vp_w + C(founding_year) + C(division_1_label) (n=37701)\n",
      "Fitting: target_inno_subsidy ~ current_vp_w_red + C(founding_year) + C(division_1_label) (n=37701)\n",
      "Fitting: target_non_gov_investment ~ founding_pr_sdg_similarity + C(founding_year) + C(division_1_label) (n=34321)\n",
      "Fitting: target_non_gov_investment ~ founding_pr_w_sdg_similarity + C(founding_year) + C(division_1_label) (n=34321)\n",
      "Fitting: target_non_gov_investment ~ founding_pr_w_red_sdg_similarity + C(founding_year) + C(division_1_label) (n=34321)\n",
      "Fitting: target_non_gov_investment ~ founding_doc2vec_diff + C(founding_year) + C(division_1_label) (n=34125)\n",
      "Fitting: target_non_gov_investment ~ founding_lp + C(founding_year) + C(division_1_label) (n=34321)\n",
      "Fitting: target_non_gov_investment ~ founding_lp_w + C(founding_year) + C(division_1_label) (n=34321)\n",
      "Fitting: target_non_gov_investment ~ founding_lp_w_red + C(founding_year) + C(division_1_label) (n=34321)\n",
      "Fitting: target_non_gov_investment ~ founding_vp + C(founding_year) + C(division_1_label) (n=34321)\n",
      "Fitting: target_non_gov_investment ~ founding_vp_w + C(founding_year) + C(division_1_label) (n=34321)\n",
      "Fitting: target_non_gov_investment ~ founding_vp_w_red + C(founding_year) + C(division_1_label) (n=34321)\n",
      "Fitting: target_non_gov_investment ~ current_pr_sdg_similarity + C(founding_year) + C(division_1_label) (n=33899)\n",
      "Fitting: target_non_gov_investment ~ current_pr_w_sdg_similarity + C(founding_year) + C(division_1_label) (n=33899)\n",
      "Fitting: target_non_gov_investment ~ current_pr_w_red_sdg_similarity + C(founding_year) + C(division_1_label) (n=33899)\n",
      "Fitting: target_non_gov_investment ~ current_doc2vec_diff + C(founding_year) + C(division_1_label) (n=33586)\n",
      "Fitting: target_non_gov_investment ~ current_lp + C(founding_year) + C(division_1_label) (n=33899)\n",
      "Fitting: target_non_gov_investment ~ current_lp_w + C(founding_year) + C(division_1_label) (n=33899)\n",
      "Fitting: target_non_gov_investment ~ current_lp_w_red + C(founding_year) + C(division_1_label) (n=33899)\n",
      "Fitting: target_non_gov_investment ~ current_vp + C(founding_year) + C(division_1_label) (n=33899)\n",
      "Fitting: target_non_gov_investment ~ current_vp_w + C(founding_year) + C(division_1_label) (n=33899)\n",
      "Fitting: target_non_gov_investment ~ current_vp_w_red + C(founding_year) + C(division_1_label) (n=33899)\n",
      "Fitting: target_acquisition ~ founding_pr_sdg_similarity + C(founding_year) + C(division_1_label) (n=36361)\n",
      "Fitting: target_acquisition ~ founding_pr_w_sdg_similarity + C(founding_year) + C(division_1_label) (n=36361)\n",
      "Fitting: target_acquisition ~ founding_pr_w_red_sdg_similarity + C(founding_year) + C(division_1_label) (n=36361)\n",
      "Fitting: target_acquisition ~ founding_doc2vec_diff + C(founding_year) + C(division_1_label) (n=36143)\n",
      "Fitting: target_acquisition ~ founding_lp + C(founding_year) + C(division_1_label) (n=36361)\n",
      "Fitting: target_acquisition ~ founding_lp_w + C(founding_year) + C(division_1_label) (n=36361)\n",
      "Fitting: target_acquisition ~ founding_lp_w_red + C(founding_year) + C(division_1_label) (n=36361)\n",
      "Fitting: target_acquisition ~ founding_vp + C(founding_year) + C(division_1_label) (n=36361)\n",
      "Fitting: target_acquisition ~ founding_vp_w + C(founding_year) + C(division_1_label) (n=36361)\n",
      "Fitting: target_acquisition ~ founding_vp_w_red + C(founding_year) + C(division_1_label) (n=36361)\n",
      "Fitting: target_acquisition ~ current_pr_sdg_similarity + C(founding_year) + C(division_1_label) (n=34334)\n",
      "Fitting: target_acquisition ~ current_pr_w_sdg_similarity + C(founding_year) + C(division_1_label) (n=34334)\n",
      "Fitting: target_acquisition ~ current_pr_w_red_sdg_similarity + C(founding_year) + C(division_1_label) (n=34334)\n",
      "Fitting: target_acquisition ~ current_doc2vec_diff + C(founding_year) + C(division_1_label) (n=34217)\n",
      "Fitting: target_acquisition ~ current_lp + C(founding_year) + C(division_1_label) (n=34334)\n",
      "Fitting: target_acquisition ~ current_lp_w + C(founding_year) + C(division_1_label) (n=34334)\n",
      "Fitting: target_acquisition ~ current_lp_w_red + C(founding_year) + C(division_1_label) (n=34334)\n",
      "Fitting: target_acquisition ~ current_vp + C(founding_year) + C(division_1_label) (n=34334)\n",
      "Fitting: target_acquisition ~ current_vp_w + C(founding_year) + C(division_1_label) (n=34334)\n",
      "Fitting: target_acquisition ~ current_vp_w_red + C(founding_year) + C(division_1_label) (n=34334)\n",
      "\n",
      "Saved regression summaries and AUC scores to /Users/manuelbolz/Documents/git/for_work/company_success_prediction/models/experiment_C/Year + Industry FEs\n",
      "Fitting: target_inno_subsidy_or_target_non_gov_investment_or_target_acquisition ~ founding_pr_sdg_similarity + C(division_1_label) + C(founding_bfs_code):C(canton_id) (n=39328)\n"
     ]
    }
   ],
   "source": [
    "score_cols = [\n",
    "    'founding_pr_sdg_similarity', 'founding_pr_w_sdg_similarity', 'founding_pr_w_red_sdg_similarity',\n",
    "    'founding_doc2vec_diff', 'founding_lp', 'founding_lp_w', 'founding_lp_w_red', 'founding_vp', 'founding_vp_w',\n",
    "    'founding_vp_w_red', 'current_pr_sdg_similarity', 'current_pr_w_sdg_similarity', 'current_pr_w_red_sdg_similarity',\n",
    "    'current_doc2vec_diff', 'current_lp', 'current_lp_w', 'current_lp_w_red', 'current_vp', 'current_vp_w', 'current_vp_w_red'\n",
    "]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "company_sample[score_cols] = scaler.fit_transform(company_sample[score_cols])\n",
    "\n",
    "analyser = CoefficientAnalyser(company_sample, experiment_dir=MODELS_DIR / 'experiment_C')\n",
    "\n",
    "experiment_setups = [\n",
    "    {\n",
    "        'title': 'Year FEs', \n",
    "        'targets': [('target_inno_subsidy', 'target_non_gov_investment', 'target_acquisition'), ('target_inno_subsidy', 'target_non_gov_investment')],\n",
    "        'score_cols': score_cols,\n",
    "        'controls': ['founding_year'], \n",
    "        'interaction_terms': None\n",
    "    },\n",
    "    {\n",
    "        'title': 'Year + Industry FEs', \n",
    "        'targets': [('target_inno_subsidy', 'target_non_gov_investment', 'target_acquisition'), ('target_inno_subsidy', 'target_non_gov_investment'), 'target_inno_subsidy', 'target_non_gov_investment', 'target_acquisition'],\n",
    "        'score_cols': score_cols,\n",
    "        'controls': ['founding_year', 'division_1_label'], \n",
    "        'interaction_terms': None\n",
    "    },\n",
    "    {\n",
    "        'title': 'Industry + Year x Canton + Municipality FEs', \n",
    "        'targets': [('target_inno_subsidy', 'target_non_gov_investment', 'target_acquisition'), ('target_inno_subsidy', 'target_non_gov_investment')],\n",
    "        'score_cols': score_cols,\n",
    "        'controls': ['division_1_label'], \n",
    "        'interaction_terms': [('founding_bfs_code', 'canton_id')]\n",
    "    },\n",
    "    {\n",
    "        'title': 'Green - Year + Industry FEs', \n",
    "        'targets': ['is_green'],\n",
    "        'score_cols': ['founding_pr_sdg_similarity','founding_pr_w_sdg_similarity','founding_pr_w_red_sdg_similarity', 'current_pr_sdg_similarity','current_pr_w_sdg_similarity','current_pr_w_red_sdg_similarity'],\n",
    "        'controls': ['founding_year', 'division_1_label'], \n",
    "        'interaction_terms': None\n",
    "    },\n",
    "]\n",
    "\n",
    "for experiment in experiment_setups:\n",
    "    analyser.analyse(\n",
    "        targets=experiment.get('targets'),\n",
    "        score_cols=experiment.get('score_cols'),\n",
    "        controls=experiment.get('controls'),\n",
    "        interaction_terms=experiment.get('interaction_terms'),\n",
    "        subfolder=experiment.get('title'),\n",
    "        save_full_summary=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
